
-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2025-06-06 17:41:33.621]  Checkpoint path: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt
[2025-06-06 17:41:33.621]  Loading training data from: E:/newtacotron/tacotron/training/train.txt
[2025-06-06 17:41:33.621]  Using model: tacotron
[2025-06-06 17:41:33.621]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: transliteration_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 300
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: False
[2025-06-06 17:41:33.628]  Loaded metadata for 2064 examples (2.80 hours)
[2025-06-06 17:41:35.303]  Initialized Tacotron model. Dimensions: 
[2025-06-06 17:41:35.303]    embedding:               256
[2025-06-06 17:41:35.303]    prenet out:              128
[2025-06-06 17:41:35.303]    encoder out:             256
[2025-06-06 17:41:35.303]    attention out:           256
[2025-06-06 17:41:35.303]    concat attn & out:       512
[2025-06-06 17:41:35.303]    decoder cell out:        256
[2025-06-06 17:41:35.303]    decoder out (5 frames):  400
[2025-06-06 17:41:35.303]    decoder out (1 frame):   80
[2025-06-06 17:41:35.303]    postnet out:             256
[2025-06-06 17:41:35.303]    linear out:              1025
[2025-06-06 17:41:41.442]  Starting new training run at commit: None
[2025-06-06 17:41:44.958]  Generated 32 batches of size 32 in 3.513 sec
[2025-06-06 17:41:56.788]  Step 1       [15.335 sec/step, loss=0.90629, avg_loss=0.90629]
[2025-06-06 17:42:01.394]  Step 2       [9.968 sec/step, loss=0.87946, avg_loss=0.89287]
[2025-06-06 17:42:09.238]  Step 3       [9.258 sec/step, loss=0.90261, avg_loss=0.89612]
[2025-06-06 17:42:12.216]  Step 4       [7.687 sec/step, loss=0.85450, avg_loss=0.88571]
[2025-06-06 17:42:15.029]  Step 5       [6.713 sec/step, loss=0.86183, avg_loss=0.88094]
[2025-06-06 17:42:18.731]  Step 6       [6.211 sec/step, loss=0.87293, avg_loss=0.87960]
[2025-06-06 17:42:20.048]  Step 7       [5.511 sec/step, loss=0.68540, avg_loss=0.85186]
[2025-06-06 17:42:27.352]  Step 8       [5.735 sec/step, loss=0.89852, avg_loss=0.85769]
[2025-06-06 17:42:32.223]  Step 9       [5.639 sec/step, loss=0.87047, avg_loss=0.85911]
[2025-06-06 17:42:35.713]  Step 10      [5.424 sec/step, loss=0.87329, avg_loss=0.86053]
[2025-06-06 17:42:52.663]  Step 11      [6.471 sec/step, loss=0.78682, avg_loss=0.85383]
[2025-06-06 17:42:57.100]  Step 12      [6.301 sec/step, loss=0.85709, avg_loss=0.85410]
[2025-06-06 17:42:59.523]  Step 13      [6.003 sec/step, loss=0.82070, avg_loss=0.85153]
[2025-06-06 17:43:05.645]  Step 14      [6.011 sec/step, loss=0.85001, avg_loss=0.85142]
[2025-06-06 17:43:09.361]  Step 15      [5.858 sec/step, loss=0.85831, avg_loss=0.85188]
[2025-06-06 17:43:11.054]  Step 16      [5.598 sec/step, loss=0.73796, avg_loss=0.84476]
[2025-06-06 17:43:13.403]  Step 17      [5.406 sec/step, loss=0.79040, avg_loss=0.84156]
[2025-06-06 17:43:15.845]  Step 18      [5.241 sec/step, loss=0.81023, avg_loss=0.83982]
[2025-06-06 17:43:20.502]  Step 19      [5.211 sec/step, loss=0.83778, avg_loss=0.83972]
[2025-06-06 17:43:22.548]  Step 20      [5.052 sec/step, loss=0.75247, avg_loss=0.83535]
[2025-06-06 17:43:27.773]  Step 21      [5.061 sec/step, loss=0.83608, avg_loss=0.83539]
[2025-06-06 17:43:29.262]  Step 22      [4.898 sec/step, loss=0.70023, avg_loss=0.82925]
[2025-06-06 17:43:32.441]  Step 23      [4.824 sec/step, loss=0.82071, avg_loss=0.82887]
[2025-06-06 17:43:39.249]  Generated 32 batches of size 32 in 6.251 sec
[2025-06-06 17:43:42.595]  Step 24      [5.046 sec/step, loss=0.83761, avg_loss=0.82924]
[2025-06-06 17:43:44.639]  Step 25      [4.926 sec/step, loss=0.74566, avg_loss=0.82590]
[2025-06-06 17:44:03.546]  Step 26      [5.463 sec/step, loss=0.82801, avg_loss=0.82598]
[2025-06-06 17:44:09.183]  Step 27      [5.469 sec/step, loss=0.79003, avg_loss=0.82465]
[2025-06-06 17:44:12.526]  Step 28      [5.393 sec/step, loss=0.80485, avg_loss=0.82394]
[2025-06-06 17:44:27.672]  Step 29      [5.729 sec/step, loss=0.79114, avg_loss=0.82281]
[2025-06-06 17:44:30.965]  Step 30      [5.648 sec/step, loss=0.79689, avg_loss=0.82194]
[2025-06-06 17:44:33.900]  Step 31      [5.560 sec/step, loss=0.74405, avg_loss=0.81943]
[2025-06-06 17:44:40.363]  Step 32      [5.589 sec/step, loss=0.79854, avg_loss=0.81878]
[2025-06-06 17:44:43.440]  Step 33      [5.513 sec/step, loss=0.72777, avg_loss=0.81602]
[2025-06-06 17:44:45.104]  Step 34      [5.399 sec/step, loss=0.71356, avg_loss=0.81301]
[2025-06-06 17:44:52.434]  Step 35      [5.454 sec/step, loss=0.73623, avg_loss=0.81081]
[2025-06-06 17:44:54.393]  Step 36      [5.357 sec/step, loss=0.71064, avg_loss=0.80803]
[2025-06-06 17:44:58.426]  Step 37      [5.322 sec/step, loss=0.73599, avg_loss=0.80608]
[2025-06-06 17:45:02.085]  Step 38      [5.278 sec/step, loss=0.72439, avg_loss=0.80393]
[2025-06-06 17:45:04.551]  Step 39      [5.206 sec/step, loss=0.70170, avg_loss=0.80131]
[2025-06-06 17:45:14.254]  Step 40      [5.318 sec/step, loss=0.71678, avg_loss=0.79920]
[2025-06-06 17:45:19.266]  Step 41      [5.310 sec/step, loss=0.71525, avg_loss=0.79715]
[2025-06-06 17:45:22.874]  Step 42      [5.270 sec/step, loss=0.69796, avg_loss=0.79479]
[2025-06-06 17:45:27.701]  Step 43      [5.260 sec/step, loss=0.70768, avg_loss=0.79276]
[2025-06-06 17:45:30.029]  Step 44      [5.193 sec/step, loss=0.69397, avg_loss=0.79052]
[2025-06-06 17:45:33.948]  Step 45      [5.165 sec/step, loss=0.69475, avg_loss=0.78839]
[2025-06-06 17:45:36.965]  Step 46      [5.118 sec/step, loss=0.68936, avg_loss=0.78624]
[2025-06-06 17:45:44.938]  Step 47      [5.179 sec/step, loss=0.69102, avg_loss=0.78421]
[2025-06-06 17:45:48.870]  Step 48      [5.153 sec/step, loss=0.68538, avg_loss=0.78215]
[2025-06-06 17:45:51.653]  Step 49      [5.104 sec/step, loss=0.66189, avg_loss=0.77970]
[2025-06-06 17:45:56.819]  Step 50      [5.105 sec/step, loss=0.67321, avg_loss=0.77757]
[2025-06-06 17:45:56.819]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-50
[2025-06-06 17:45:58.795]  Saving audio and alignment...
[2025-06-06 17:46:02.560]  Input: phraanselii gnntntrko biisaun raassttrpti~___________
[2025-06-06 17:46:03.962]  Step 51      [5.033 sec/step, loss=0.61890, avg_loss=0.77446]
[2025-06-06 17:46:11.303]  Step 52      [5.077 sec/step, loss=0.67257, avg_loss=0.77250]
[2025-06-06 17:46:13.765]  Step 53      [5.028 sec/step, loss=0.65183, avg_loss=0.77022]
[2025-06-06 17:46:16.540]  Step 54      [4.986 sec/step, loss=0.63359, avg_loss=0.76769]
[2025-06-06 17:46:19.615]  Step 55      [4.951 sec/step, loss=0.64822, avg_loss=0.76552]
[2025-06-06 17:46:21.306]  Step 56      [4.893 sec/step, loss=0.63422, avg_loss=0.76317]
[2025-06-06 17:46:21.358]  Generated 32 batches of size 32 in 4.487 sec
[2025-06-06 17:46:23.329]  Step 57      [4.843 sec/step, loss=0.62982, avg_loss=0.76083]
[2025-06-06 17:46:25.578]  Step 58      [4.798 sec/step, loss=0.62978, avg_loss=0.75858]
[2025-06-06 17:46:28.392]  Step 59      [4.764 sec/step, loss=0.62488, avg_loss=0.75631]
[2025-06-06 17:47:00.301]  Step 60      [5.217 sec/step, loss=0.57938, avg_loss=0.75336]
[2025-06-06 17:47:04.157]  Step 61      [5.194 sec/step, loss=0.61595, avg_loss=0.75111]
[2025-06-06 17:47:08.026]  Step 62      [5.173 sec/step, loss=0.61891, avg_loss=0.74898]
[2025-06-06 17:47:13.731]  Step 63      [5.181 sec/step, loss=0.60992, avg_loss=0.74677]
[2025-06-06 17:47:15.338]  Step 64      [5.125 sec/step, loss=0.58798, avg_loss=0.74429]
[2025-06-06 17:47:23.158]  Step 65      [5.167 sec/step, loss=0.62522, avg_loss=0.74246]
[2025-06-06 17:47:25.742]  Step 66      [5.128 sec/step, loss=0.59543, avg_loss=0.74023]
[2025-06-06 17:47:29.893]  Step 67      [5.113 sec/step, loss=0.59589, avg_loss=0.73807]
[2025-06-06 17:47:31.952]  Step 68      [5.068 sec/step, loss=0.55926, avg_loss=0.73544]
[2025-06-06 17:47:35.283]  Step 69      [5.043 sec/step, loss=0.58529, avg_loss=0.73327]
[2025-06-06 17:47:37.716]  Step 70      [5.006 sec/step, loss=0.56507, avg_loss=0.73087]
[2025-06-06 17:47:42.288]  Step 71      [5.000 sec/step, loss=0.56745, avg_loss=0.72856]
[2025-06-06 17:47:47.708]  Step 72      [5.005 sec/step, loss=0.57812, avg_loss=0.72647]
[2025-06-06 17:47:52.615]  Step 73      [5.004 sec/step, loss=0.56078, avg_loss=0.72420]
[2025-06-06 17:47:54.082]  Step 74      [4.956 sec/step, loss=0.53133, avg_loss=0.72160]
[2025-06-06 17:47:57.759]  Step 75      [4.939 sec/step, loss=0.54215, avg_loss=0.71920]
[2025-06-06 17:47:59.609]  Step 76      [4.899 sec/step, loss=0.51615, avg_loss=0.71653]
[2025-06-06 17:48:01.725]  Step 77      [4.862 sec/step, loss=0.51136, avg_loss=0.71387]
[2025-06-06 17:48:07.795]  Step 78      [4.878 sec/step, loss=0.54031, avg_loss=0.71164]
[2025-06-06 17:48:09.641]  Step 79      [4.839 sec/step, loss=0.50358, avg_loss=0.70901]
[2025-06-06 17:48:14.697]  Step 80      [4.842 sec/step, loss=0.51125, avg_loss=0.70654]
[2025-06-06 17:48:18.244]  Step 81      [4.826 sec/step, loss=0.50384, avg_loss=0.70404]
[2025-06-06 17:48:20.891]  Step 82      [4.800 sec/step, loss=0.48903, avg_loss=0.70141]
[2025-06-06 17:48:23.816]  Step 83      [4.777 sec/step, loss=0.49644, avg_loss=0.69894]
[2025-06-06 17:48:28.120]  Step 84      [4.771 sec/step, loss=0.48348, avg_loss=0.69638]
[2025-06-06 17:48:30.927]  Step 85      [4.748 sec/step, loss=0.46938, avg_loss=0.69371]
[2025-06-06 17:48:33.224]  Step 86      [4.720 sec/step, loss=0.45806, avg_loss=0.69097]
[2025-06-06 17:48:38.120]  Generated 32 batches of size 32 in 4.550 sec
[2025-06-06 17:48:42.079]  Step 87      [4.767 sec/step, loss=0.47809, avg_loss=0.68852]
[2025-06-06 17:49:10.773]  Step 88      [5.039 sec/step, loss=0.43880, avg_loss=0.68568]
[2025-06-06 17:49:14.698]  Step 89      [5.026 sec/step, loss=0.45088, avg_loss=0.68305]
[2025-06-06 17:49:17.185]  Step 90      [4.998 sec/step, loss=0.43661, avg_loss=0.68031]
[2025-06-06 17:49:20.220]  Step 91      [4.977 sec/step, loss=0.43783, avg_loss=0.67764]
[2025-06-06 17:49:23.675]  Step 92      [4.960 sec/step, loss=0.44481, avg_loss=0.67511]
[2025-06-06 17:49:30.211]  Step 93      [4.977 sec/step, loss=0.42867, avg_loss=0.67246]
[2025-06-06 17:49:37.615]  Step 94      [5.003 sec/step, loss=0.42706, avg_loss=0.66985]
[2025-06-06 17:49:39.034]  Step 95      [4.965 sec/step, loss=0.39968, avg_loss=0.66701]
[2025-06-06 17:49:41.486]  Step 96      [4.939 sec/step, loss=0.41059, avg_loss=0.66434]
[2025-06-06 17:49:47.600]  Step 97      [4.951 sec/step, loss=0.39753, avg_loss=0.66159]
[2025-06-06 17:49:52.408]  Step 98      [4.950 sec/step, loss=0.39476, avg_loss=0.65886]
[2025-06-06 17:49:56.649]  Step 99      [4.942 sec/step, loss=0.39007, avg_loss=0.65615]
[2025-06-06 17:50:01.458]  Step 100     [4.941 sec/step, loss=0.38410, avg_loss=0.65343]
[2025-06-06 17:50:01.458]  Writing summary at step: 100
[2025-06-06 17:50:13.232]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-100
[2025-06-06 17:50:14.082]  Saving audio and alignment...
[2025-06-06 17:50:17.058]  Input: spenii vyaavsaayik phuttbl khelaaddii~
[2025-06-06 17:50:19.588]  Step 101     [4.813 sec/step, loss=0.37240, avg_loss=0.64809]
[2025-06-06 17:50:21.702]  Step 102     [4.788 sec/step, loss=0.37408, avg_loss=0.64303]
[2025-06-06 17:50:23.626]  Step 103     [4.729 sec/step, loss=0.36787, avg_loss=0.63769]
[2025-06-06 17:50:27.375]  Step 104     [4.737 sec/step, loss=0.36067, avg_loss=0.63275]
[2025-06-06 17:50:30.241]  Step 105     [4.737 sec/step, loss=0.35268, avg_loss=0.62766]
[2025-06-06 17:50:32.082]  Step 106     [4.719 sec/step, loss=0.34891, avg_loss=0.62242]
[2025-06-06 17:50:35.977]  Step 107     [4.744 sec/step, loss=0.33825, avg_loss=0.61895]
[2025-06-06 17:50:38.941]  Step 108     [4.701 sec/step, loss=0.33785, avg_loss=0.61334]
[2025-06-06 17:50:47.908]  Step 109     [4.742 sec/step, loss=0.34305, avg_loss=0.60806]
[2025-06-06 17:50:50.872]  Step 110     [4.737 sec/step, loss=0.33109, avg_loss=0.60264]
[2025-06-06 17:50:53.998]  Step 111     [4.598 sec/step, loss=0.32986, avg_loss=0.59807]
[2025-06-06 17:51:00.945]  Step 112     [4.624 sec/step, loss=0.32818, avg_loss=0.59278]
[2025-06-06 17:51:03.165]  Step 113     [4.622 sec/step, loss=0.32846, avg_loss=0.58786]
[2025-06-06 17:51:06.708]  Step 114     [4.596 sec/step, loss=0.31506, avg_loss=0.58251]
[2025-06-06 17:51:13.693]  Step 115     [4.629 sec/step, loss=0.31265, avg_loss=0.57706]
[2025-06-06 17:51:15.808]  Step 116     [4.633 sec/step, loss=0.31940, avg_loss=0.57287]
[2025-06-06 17:52:00.734]  Generated 32 batches of size 32 in 44.485 sec
[2025-06-06 17:52:11.443]  Step 117     [5.166 sec/step, loss=0.30780, avg_loss=0.56804]
[2025-06-06 17:52:15.182]  Step 118     [5.179 sec/step, loss=0.29353, avg_loss=0.56288]
[2025-06-06 17:52:19.321]  Step 119     [5.173 sec/step, loss=0.30272, avg_loss=0.55753]
[2025-06-06 17:52:20.746]  Step 120     [5.167 sec/step, loss=0.30024, avg_loss=0.55300]
[2025-06-06 17:52:24.183]  Step 121     [5.149 sec/step, loss=0.29266, avg_loss=0.54757]
[2025-06-06 17:52:29.788]  Step 122     [5.190 sec/step, loss=0.28727, avg_loss=0.54344]
[2025-06-06 17:52:35.921]  Step 123     [5.220 sec/step, loss=0.29093, avg_loss=0.53814]
[2025-06-06 17:52:38.524]  Step 124     [5.145 sec/step, loss=0.28502, avg_loss=0.53262]
[2025-06-06 17:52:41.314]  Step 125     [5.152 sec/step, loss=0.28882, avg_loss=0.52805]
[2025-06-06 17:52:48.857]  Step 126     [5.038 sec/step, loss=0.28909, avg_loss=0.52266]
[2025-06-06 17:52:51.417]  Step 127     [5.008 sec/step, loss=0.27623, avg_loss=0.51752]
[2025-06-06 17:52:53.607]  Step 128     [4.996 sec/step, loss=0.28250, avg_loss=0.51230]
[2025-06-06 17:52:57.279]  Step 129     [4.882 sec/step, loss=0.26805, avg_loss=0.50707]
[2025-06-06 17:53:02.554]  Step 130     [4.901 sec/step, loss=0.27134, avg_loss=0.50181]
[2025-06-06 17:53:12.463]  Step 131     [4.971 sec/step, loss=0.27694, avg_loss=0.49714]
[2025-06-06 17:53:16.453]  Step 132     [4.946 sec/step, loss=0.26807, avg_loss=0.49184]
[2025-06-06 17:53:18.033]  Step 133     [4.931 sec/step, loss=0.28445, avg_loss=0.48740]
[2025-06-06 17:53:21.309]  Step 134     [4.948 sec/step, loss=0.26754, avg_loss=0.48294]
[2025-06-06 17:53:23.014]  Step 135     [4.891 sec/step, loss=0.27815, avg_loss=0.47836]
[2025-06-06 17:53:26.322]  Step 136     [4.905 sec/step, loss=0.26201, avg_loss=0.47387]
[2025-06-06 17:53:30.497]  Step 137     [4.906 sec/step, loss=0.26208, avg_loss=0.46914]
[2025-06-06 17:53:35.422]  Step 138     [4.919 sec/step, loss=0.26228, avg_loss=0.46451]
[2025-06-06 17:53:38.208]  Step 139     [4.922 sec/step, loss=0.26866, avg_loss=0.46018]
[2025-06-06 17:53:42.769]  Step 140     [4.871 sec/step, loss=0.26194, avg_loss=0.45564]
[2025-06-06 17:53:51.919]  Step 141     [4.912 sec/step, loss=0.26330, avg_loss=0.45112]
[2025-06-06 17:53:54.974]  Step 142     [4.907 sec/step, loss=0.26357, avg_loss=0.44677]
[2025-06-06 17:53:56.934]  Step 143     [4.878 sec/step, loss=0.26739, avg_loss=0.44237]
[2025-06-06 17:54:00.441]  Step 144     [4.890 sec/step, loss=0.25835, avg_loss=0.43801]
[2025-06-06 17:54:06.047]  Step 145     [4.907 sec/step, loss=0.25807, avg_loss=0.43365]
[2025-06-06 17:54:11.283]  Step 146     [4.929 sec/step, loss=0.25461, avg_loss=0.42930]
[2025-06-06 17:54:18.023]  Step 147     [4.916 sec/step, loss=0.25218, avg_loss=0.42491]
[2025-06-06 17:54:23.982]  Step 148     [4.937 sec/step, loss=0.25227, avg_loss=0.42058]
[2025-06-06 17:54:27.060]  Step 149     [4.940 sec/step, loss=0.26033, avg_loss=0.41656]
[2025-06-06 17:54:28.844]  Generated 32 batches of size 32 in 4.573 sec
[2025-06-06 17:54:35.177]  Step 150     [4.969 sec/step, loss=0.24985, avg_loss=0.41233]
[2025-06-06 17:54:35.178]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-150
[2025-06-06 17:54:36.308]  Saving audio and alignment...
[2025-06-06 17:54:41.412]  Input: jibro restto r baarmaa paaine khaanaa any sthaanko bhndaa mittho ch~____________
[2025-06-06 17:54:43.961]  Step 151     [4.981 sec/step, loss=0.25859, avg_loss=0.40873]
[2025-06-06 17:54:46.158]  Step 152     [4.929 sec/step, loss=0.25762, avg_loss=0.40458]
[2025-06-06 17:54:47.604]  Step 153     [4.919 sec/step, loss=0.26216, avg_loss=0.40068]
[2025-06-06 17:55:19.898]  Step 154     [5.214 sec/step, loss=0.26032, avg_loss=0.39695]
[2025-06-06 17:55:21.752]  Step 155     [5.202 sec/step, loss=0.26659, avg_loss=0.39313]
[2025-06-06 17:55:24.777]  Step 156     [5.215 sec/step, loss=0.25057, avg_loss=0.38930]
[2025-06-06 17:55:26.855]  Step 157     [5.216 sec/step, loss=0.25734, avg_loss=0.38557]
[2025-06-06 17:55:29.088]  Step 158     [5.216 sec/step, loss=0.26177, avg_loss=0.38189]
[2025-06-06 17:55:31.559]  Step 159     [5.212 sec/step, loss=0.25085, avg_loss=0.37815]
[2025-06-06 17:55:37.131]  Step 160     [4.949 sec/step, loss=0.24802, avg_loss=0.37484]
[2025-06-06 17:55:42.379]  Step 161     [4.963 sec/step, loss=0.25181, avg_loss=0.37120]
[2025-06-06 17:55:46.291]  Step 162     [4.963 sec/step, loss=0.25310, avg_loss=0.36754]
[2025-06-06 17:55:52.678]  Step 163     [4.970 sec/step, loss=0.25689, avg_loss=0.36401]
[2025-06-06 17:55:54.812]  Step 164     [4.975 sec/step, loss=0.25500, avg_loss=0.36068]
[2025-06-06 17:55:58.445]  Step 165     [4.934 sec/step, loss=0.24564, avg_loss=0.35688]
[2025-06-06 17:56:03.989]  Step 166     [4.963 sec/step, loss=0.24995, avg_loss=0.35343]
[2025-06-06 17:56:07.327]  Step 167     [4.955 sec/step, loss=0.24617, avg_loss=0.34993]
[2025-06-06 17:56:15.464]  Step 168     [5.016 sec/step, loss=0.25636, avg_loss=0.34690]
[2025-06-06 17:56:18.137]  Step 169     [5.009 sec/step, loss=0.25046, avg_loss=0.34355]
[2025-06-06 17:56:19.963]  Step 170     [5.003 sec/step, loss=0.25041, avg_loss=0.34041]
[2025-06-06 17:56:39.397]  Step 171     [5.152 sec/step, loss=0.25000, avg_loss=0.33723]
[2025-06-06 17:56:43.725]  Step 172     [5.141 sec/step, loss=0.25180, avg_loss=0.33397]
[2025-06-06 17:56:46.227]  Step 173     [5.117 sec/step, loss=0.25056, avg_loss=0.33087]
[2025-06-06 17:56:49.371]  Step 174     [5.133 sec/step, loss=0.25123, avg_loss=0.32806]
[2025-06-06 17:56:51.443]  Step 175     [5.117 sec/step, loss=0.24838, avg_loss=0.32513]
[2025-06-06 17:56:54.296]  Step 176     [5.127 sec/step, loss=0.25079, avg_loss=0.32247]
[2025-06-06 17:56:59.178]  Step 177     [5.155 sec/step, loss=0.24385, avg_loss=0.31980]
[2025-06-06 17:57:02.177]  Step 178     [5.124 sec/step, loss=0.24576, avg_loss=0.31685]
[2025-06-06 17:57:05.850]  Step 179     [5.143 sec/step, loss=0.24194, avg_loss=0.31424]
[2025-06-06 17:57:11.031]  Generated 32 batches of size 32 in 4.836 sec
[2025-06-06 17:57:12.233]  Step 180     [5.156 sec/step, loss=0.24100, avg_loss=0.31153]
[2025-06-06 17:57:16.857]  Step 181     [5.167 sec/step, loss=0.23751, avg_loss=0.30887]
[2025-06-06 17:57:18.660]  Step 182     [5.158 sec/step, loss=0.24519, avg_loss=0.30643]
[2025-06-06 17:57:26.293]  Step 183     [5.205 sec/step, loss=0.24222, avg_loss=0.30389]
[2025-06-06 17:57:28.054]  Step 184     [5.180 sec/step, loss=0.24875, avg_loss=0.30154]
[2025-06-06 17:57:29.680]  Step 185     [5.168 sec/step, loss=0.24373, avg_loss=0.29929]
[2025-06-06 17:57:36.427]  Step 186     [5.213 sec/step, loss=0.25040, avg_loss=0.29721]
[2025-06-06 17:57:40.072]  Step 187     [5.161 sec/step, loss=0.24262, avg_loss=0.29485]
[2025-06-06 17:57:43.106]  Step 188     [4.904 sec/step, loss=0.24167, avg_loss=0.29288]
[2025-06-06 17:57:46.183]  Step 189     [4.896 sec/step, loss=0.24757, avg_loss=0.29085]
[2025-06-06 17:57:52.924]  Step 190     [4.938 sec/step, loss=0.24202, avg_loss=0.28890]
[2025-06-06 17:57:54.868]  Step 191     [4.927 sec/step, loss=0.24278, avg_loss=0.28695]
[2025-06-06 17:57:58.865]  Step 192     [4.933 sec/step, loss=0.24057, avg_loss=0.28491]
[2025-06-06 17:58:01.228]  Step 193     [4.891 sec/step, loss=0.24235, avg_loss=0.28305]
[2025-06-06 17:58:08.766]  Step 194     [4.892 sec/step, loss=0.24900, avg_loss=0.28127]
[2025-06-06 17:58:14.759]  Step 195     [4.938 sec/step, loss=0.24046, avg_loss=0.27968]
[2025-06-06 17:58:16.666]  Step 196     [4.933 sec/step, loss=0.24329, avg_loss=0.27800]
[2025-06-06 17:58:21.753]  Step 197     [4.922 sec/step, loss=0.23490, avg_loss=0.27638]
[2025-06-06 17:58:26.678]  Step 198     [4.923 sec/step, loss=0.23856, avg_loss=0.27481]
[2025-06-06 17:58:30.806]  Step 199     [4.922 sec/step, loss=0.23775, avg_loss=0.27329]
[2025-06-06 17:58:37.339]  Step 200     [4.940 sec/step, loss=0.23742, avg_loss=0.27182]
[2025-06-06 17:58:37.340]  Writing summary at step: 200
[2025-06-06 17:58:39.034]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-200
[2025-06-06 17:58:39.965]  Saving audio and alignment...
[2025-06-06 17:58:46.437]  Input: khaastte taal nepaalmaa kaaskii jillaabhitr lekhnaath ngrpaalikaakaa saat taalmdhye euttaa taal ho~__________
[2025-06-06 17:58:49.502]  Step 201     [4.945 sec/step, loss=0.24026, avg_loss=0.27050]
[2025-06-06 17:58:51.690]  Step 202     [4.946 sec/step, loss=0.24151, avg_loss=0.26918]
[2025-06-06 17:58:55.319]  Step 203     [4.963 sec/step, loss=0.23569, avg_loss=0.26786]
[2025-06-06 17:58:58.853]  Step 204     [4.961 sec/step, loss=0.23290, avg_loss=0.26658]
[2025-06-06 17:59:03.196]  Step 205     [4.975 sec/step, loss=0.23363, avg_loss=0.26539]
[2025-06-06 17:59:06.369]  Step 206     [4.989 sec/step, loss=0.23594, avg_loss=0.26426]
[2025-06-06 17:59:17.664]  Step 207     [5.063 sec/step, loss=0.23552, avg_loss=0.26323]
[2025-06-06 17:59:19.176]  Step 208     [5.048 sec/step, loss=0.23772, avg_loss=0.26223]
[2025-06-06 17:59:27.419]  Step 209     [5.041 sec/step, loss=0.24258, avg_loss=0.26122]
[2025-06-06 17:59:30.626]  Step 210     [5.043 sec/step, loss=0.23834, avg_loss=0.26030]
[2025-06-06 17:59:31.898]  Generated 32 batches of size 32 in 4.146 sec
[2025-06-06 17:59:33.541]  Step 211     [5.041 sec/step, loss=0.23674, avg_loss=0.25937]
[2025-06-06 17:59:39.150]  Step 212     [5.028 sec/step, loss=0.23092, avg_loss=0.25839]
[2025-06-06 17:59:41.226]  Step 213     [5.026 sec/step, loss=0.23880, avg_loss=0.25750]
[2025-06-06 17:59:43.544]  Step 214     [5.014 sec/step, loss=0.23741, avg_loss=0.25672]
[2025-06-06 17:59:47.319]  Step 215     [4.982 sec/step, loss=0.22851, avg_loss=0.25588]
[2025-06-06 18:00:24.047]  Step 216     [5.328 sec/step, loss=0.23782, avg_loss=0.25506]
[2025-06-06 18:00:25.921]  Step 217     [4.790 sec/step, loss=0.23965, avg_loss=0.25438]
[2025-06-06 18:00:29.903]  Step 218     [4.793 sec/step, loss=0.24060, avg_loss=0.25385]
[2025-06-06 18:00:34.539]  Step 219     [4.798 sec/step, loss=0.24405, avg_loss=0.25327]
[2025-06-06 18:00:37.787]  Step 220     [4.816 sec/step, loss=0.23840, avg_loss=0.25265]
[2025-06-06 18:00:45.358]  Step 221     [4.857 sec/step, loss=0.24361, avg_loss=0.25216]
[2025-06-06 18:00:51.147]  Step 222     [4.859 sec/step, loss=0.23928, avg_loss=0.25168]
[2025-06-06 18:00:53.701]  Step 223     [4.823 sec/step, loss=0.23853, avg_loss=0.25115]
[2025-06-06 18:00:55.608]  Step 224     [4.816 sec/step, loss=0.24226, avg_loss=0.25072]
[2025-06-06 18:00:57.653]  Step 225     [4.809 sec/step, loss=0.23499, avg_loss=0.25019]
[2025-06-06 18:01:00.193]  Step 226     [4.759 sec/step, loss=0.22840, avg_loss=0.24958]
[2025-06-06 18:01:01.805]  Step 227     [4.749 sec/step, loss=0.23967, avg_loss=0.24921]
[2025-06-06 18:01:08.328]  Step 228     [4.793 sec/step, loss=0.23482, avg_loss=0.24874]
[2025-06-06 18:01:11.414]  Step 229     [4.787 sec/step, loss=0.23078, avg_loss=0.24836]
[2025-06-06 18:01:16.487]  Step 230     [4.785 sec/step, loss=0.23545, avg_loss=0.24801]
[2025-06-06 18:01:21.297]  Step 231     [4.734 sec/step, loss=0.23139, avg_loss=0.24755]
[2025-06-06 18:01:28.543]  Step 232     [4.766 sec/step, loss=0.23582, avg_loss=0.24723]
[2025-06-06 18:01:31.214]  Step 233     [4.777 sec/step, loss=0.23444, avg_loss=0.24673]
[2025-06-06 18:01:36.779]  Step 234     [4.800 sec/step, loss=0.23342, avg_loss=0.24639]
[2025-06-06 18:01:39.362]  Step 235     [4.809 sec/step, loss=0.23588, avg_loss=0.24596]
[2025-06-06 18:01:42.683]  Step 236     [4.809 sec/step, loss=0.22672, avg_loss=0.24561]
[2025-06-06 18:01:51.538]  Step 237     [4.856 sec/step, loss=0.23588, avg_loss=0.24535]
[2025-06-06 18:01:54.633]  Step 238     [4.838 sec/step, loss=0.22735, avg_loss=0.24500]
[2025-06-06 18:01:57.600]  Step 239     [4.839 sec/step, loss=0.23167, avg_loss=0.24463]
[2025-06-06 18:02:01.080]  Step 240     [4.829 sec/step, loss=0.22593, avg_loss=0.24427]
[2025-06-06 18:02:04.654]  Step 241     [4.773 sec/step, loss=0.22503, avg_loss=0.24389]
[2025-06-06 18:02:06.362]  Step 242     [4.759 sec/step, loss=0.22645, avg_loss=0.24352]
[2025-06-06 18:02:08.985]  Step 243     [4.766 sec/step, loss=0.23292, avg_loss=0.24317]
[2025-06-06 18:02:09.451]  Generated 32 batches of size 32 in 4.453 sec
[2025-06-06 18:02:13.614]  Step 244     [4.777 sec/step, loss=0.23013, avg_loss=0.24289]
[2025-06-06 18:02:19.394]  Step 245     [4.779 sec/step, loss=0.22853, avg_loss=0.24259]
[2025-06-06 18:02:30.974]  Step 246     [4.842 sec/step, loss=0.23200, avg_loss=0.24237]
[2025-06-06 18:02:33.305]  Step 247     [4.798 sec/step, loss=0.23194, avg_loss=0.24216]
[2025-06-06 18:02:35.069]  Step 248     [4.756 sec/step, loss=0.22667, avg_loss=0.24191]
[2025-06-06 18:02:38.928]  Step 249     [4.764 sec/step, loss=0.23563, avg_loss=0.24166]
[2025-06-06 18:02:43.446]  Step 250     [4.728 sec/step, loss=0.22936, avg_loss=0.24146]
[2025-06-06 18:02:43.446]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-250
[2025-06-06 18:02:44.395]  Saving audio and alignment...
[2025-06-06 18:02:52.462]  Input: moddl tthaa kaarykrm prstotaa surj girii r saahnaa bjraacaary pheri ekpttk prhriiko phndaamaa prekaa chn~__________________________________
[2025-06-06 18:02:55.093]  Step 251     [4.729 sec/step, loss=0.23112, avg_loss=0.24118]
[2025-06-06 18:02:56.945]  Step 252     [4.725 sec/step, loss=0.23220, avg_loss=0.24093]
[2025-06-06 18:03:03.468]  Step 253     [4.776 sec/step, loss=0.23099, avg_loss=0.24062]
[2025-06-06 18:03:04.932]  Step 254     [4.468 sec/step, loss=0.21906, avg_loss=0.24020]
[2025-06-06 18:03:09.032]  Step 255     [4.491 sec/step, loss=0.23133, avg_loss=0.23985]
[2025-06-06 18:03:40.789]  Step 256     [4.778 sec/step, loss=0.21883, avg_loss=0.23953]
[2025-06-06 18:03:42.592]  Step 257     [4.775 sec/step, loss=0.22674, avg_loss=0.23923]
[2025-06-06 18:03:49.567]  Step 258     [4.822 sec/step, loss=0.24042, avg_loss=0.23901]
[2025-06-06 18:03:54.040]  Step 259     [4.842 sec/step, loss=0.23057, avg_loss=0.23881]
[2025-06-06 18:03:57.260]  Step 260     [4.819 sec/step, loss=0.22921, avg_loss=0.23862]
[2025-06-06 18:04:01.012]  Step 261     [4.804 sec/step, loss=0.23292, avg_loss=0.23843]
[2025-06-06 18:04:06.786]  Step 262     [4.823 sec/step, loss=0.23292, avg_loss=0.23823]
[2025-06-06 18:04:09.087]  Step 263     [4.782 sec/step, loss=0.22875, avg_loss=0.23795]
[2025-06-06 18:04:11.101]  Step 264     [4.781 sec/step, loss=0.22877, avg_loss=0.23769]
[2025-06-06 18:04:14.865]  Step 265     [4.782 sec/step, loss=0.22311, avg_loss=0.23746]
[2025-06-06 18:04:16.442]  Step 266     [4.742 sec/step, loss=0.23074, avg_loss=0.23727]
[2025-06-06 18:04:18.586]  Step 267     [4.730 sec/step, loss=0.22366, avg_loss=0.23705]
[2025-06-06 18:04:23.403]  Step 268     [4.697 sec/step, loss=0.22705, avg_loss=0.23675]
[2025-06-06 18:04:25.987]  Step 269     [4.696 sec/step, loss=0.22601, avg_loss=0.23651]
[2025-06-06 18:04:30.636]  Step 270     [4.724 sec/step, loss=0.22568, avg_loss=0.23626]
[2025-06-06 18:04:32.669]  Step 271     [4.550 sec/step, loss=0.22578, avg_loss=0.23602]
[2025-06-06 18:04:37.991]  Step 272     [4.560 sec/step, loss=0.22409, avg_loss=0.23574]
[2025-06-06 18:04:42.378]  Generated 32 batches of size 32 in 3.989 sec
[2025-06-06 18:04:46.643]  Step 273     [4.622 sec/step, loss=0.22496, avg_loss=0.23549]
[2025-06-06 18:04:51.443]  Step 274     [4.638 sec/step, loss=0.22291, avg_loss=0.23520]
[2025-06-06 18:04:55.238]  Step 275     [4.656 sec/step, loss=0.22050, avg_loss=0.23492]
[2025-06-06 18:05:13.431]  Step 276     [4.809 sec/step, loss=0.22851, avg_loss=0.23470]
[2025-06-06 18:05:17.168]  Step 277     [4.798 sec/step, loss=0.22331, avg_loss=0.23450]
[2025-06-06 18:05:20.251]  Step 278     [4.798 sec/step, loss=0.22439, avg_loss=0.23428]
[2025-06-06 18:05:23.531]  Step 279     [4.794 sec/step, loss=0.22503, avg_loss=0.23411]
[2025-06-06 18:05:26.762]  Step 280     [4.763 sec/step, loss=0.22541, avg_loss=0.23396]
[2025-06-06 18:05:29.417]  Step 281     [4.743 sec/step, loss=0.21960, avg_loss=0.23378]
[2025-06-06 18:05:32.851]  Step 282     [4.760 sec/step, loss=0.22269, avg_loss=0.23355]
[2025-06-06 18:05:36.516]  Step 283     [4.720 sec/step, loss=0.22067, avg_loss=0.23334]
[2025-06-06 18:05:46.211]  Step 284     [4.799 sec/step, loss=0.22045, avg_loss=0.23305]
[2025-06-06 18:05:49.535]  Step 285     [4.816 sec/step, loss=0.21864, avg_loss=0.23280]
[2025-06-06 18:05:51.484]  Step 286     [4.768 sec/step, loss=0.22602, avg_loss=0.23256]
[2025-06-06 18:05:54.320]  Step 287     [4.760 sec/step, loss=0.22139, avg_loss=0.23235]
[2025-06-06 18:05:56.628]  Step 288     [4.753 sec/step, loss=0.22035, avg_loss=0.23213]
[2025-06-06 18:06:01.719]  Step 289     [4.773 sec/step, loss=0.22644, avg_loss=0.23192]
[2025-06-06 18:06:08.051]  Step 290     [4.769 sec/step, loss=0.22223, avg_loss=0.23172]
[2025-06-06 18:06:11.173]  Step 291     [4.781 sec/step, loss=0.22244, avg_loss=0.23152]
[2025-06-06 18:06:14.434]  Step 292     [4.773 sec/step, loss=0.22457, avg_loss=0.23136]
[2025-06-06 18:06:19.637]  Step 293     [4.802 sec/step, loss=0.22283, avg_loss=0.23117]
[2025-06-06 18:06:25.508]  Step 294     [4.785 sec/step, loss=0.22284, avg_loss=0.23090]
[2025-06-06 18:06:28.377]  Step 295     [4.754 sec/step, loss=0.22037, avg_loss=0.23070]
[2025-06-06 18:06:35.130]  Step 296     [4.802 sec/step, loss=0.22015, avg_loss=0.23047]
[2025-06-06 18:06:59.044]  Step 297     [4.990 sec/step, loss=0.21327, avg_loss=0.23026]
[2025-06-06 18:07:03.624]  Step 298     [4.987 sec/step, loss=0.22618, avg_loss=0.23013]
[2025-06-06 18:07:05.518]  Step 299     [4.965 sec/step, loss=0.21799, avg_loss=0.22993]
[2025-06-06 18:07:07.128]  Step 300     [4.915 sec/step, loss=0.21393, avg_loss=0.22970]
[2025-06-06 18:07:07.128]  Writing summary at step: 300
[2025-06-06 18:07:09.656]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-300
[2025-06-06 18:07:12.105]  Saving audio and alignment...
[2025-06-06 18:07:17.460]  Input: maile ksailaaii shikssaa dien aaphno rng thoprne duraagrh raakheko chain~____________
[2025-06-06 18:07:21.174]  Step 301     [4.922 sec/step, loss=0.22243, avg_loss=0.22952]
[2025-06-06 18:07:27.178]  Step 302     [4.960 sec/step, loss=0.22378, avg_loss=0.22934]
[2025-06-06 18:07:30.298]  Step 303     [4.955 sec/step, loss=0.22138, avg_loss=0.22920]
[2025-06-06 18:07:32.008]  Generated 32 batches of size 32 in 4.426 sec
[2025-06-06 18:07:36.672]  Step 304     [4.983 sec/step, loss=0.22070, avg_loss=0.22908]
[2025-06-06 18:07:40.938]  Step 305     [4.983 sec/step, loss=0.22062, avg_loss=0.22895]
[2025-06-06 18:07:48.484]  Step 306     [5.026 sec/step, loss=0.22600, avg_loss=0.22885]
[2025-06-06 18:07:50.465]  Step 307     [4.933 sec/step, loss=0.21502, avg_loss=0.22864]
[2025-06-06 18:07:58.302]  Step 308     [4.996 sec/step, loss=0.22893, avg_loss=0.22856]
[2025-06-06 18:07:59.917]  Step 309     [4.930 sec/step, loss=0.21598, avg_loss=0.22829]
[2025-06-06 18:08:02.528]  Step 310     [4.924 sec/step, loss=0.21808, avg_loss=0.22809]
[2025-06-06 18:08:06.390]  Step 311     [4.934 sec/step, loss=0.21975, avg_loss=0.22792]
[2025-06-06 18:08:11.332]  Step 312     [4.927 sec/step, loss=0.21958, avg_loss=0.22780]
[2025-06-06 18:08:14.382]  Step 313     [4.937 sec/step, loss=0.21622, avg_loss=0.22758]
[2025-06-06 18:08:16.979]  Step 314     [4.939 sec/step, loss=0.22149, avg_loss=0.22742]
[2025-06-06 18:08:21.292]  Step 315     [4.945 sec/step, loss=0.21796, avg_loss=0.22731]
[2025-06-06 18:08:25.242]  Step 316     [4.617 sec/step, loss=0.22293, avg_loss=0.22717]
[2025-06-06 18:08:28.409]  Step 317     [4.630 sec/step, loss=0.21528, avg_loss=0.22692]
[2025-06-06 18:08:34.781]  Step 318     [4.654 sec/step, loss=0.21984, avg_loss=0.22671]
[2025-06-06 18:08:40.356]  Step 319     [4.663 sec/step, loss=0.21894, avg_loss=0.22646]
[2025-06-06 18:08:45.142]  Step 320     [4.679 sec/step, loss=0.21618, avg_loss=0.22624]
[2025-06-06 18:08:46.965]  Step 321     [4.621 sec/step, loss=0.21536, avg_loss=0.22596]
[2025-06-06 18:08:50.075]  Step 322     [4.595 sec/step, loss=0.21836, avg_loss=0.22575]
[2025-06-06 18:08:53.614]  Step 323     [4.604 sec/step, loss=0.21388, avg_loss=0.22550]
[2025-06-06 18:08:56.389]  Step 324     [4.613 sec/step, loss=0.21564, avg_loss=0.22524]
[2025-06-06 18:08:58.599]  Step 325     [4.615 sec/step, loss=0.21570, avg_loss=0.22504]
[2025-06-06 18:09:02.162]  Step 326     [4.625 sec/step, loss=0.21061, avg_loss=0.22487]
[2025-06-06 18:09:07.692]  Step 327     [4.664 sec/step, loss=0.21450, avg_loss=0.22461]
[2025-06-06 18:09:09.734]  Step 328     [4.619 sec/step, loss=0.21026, avg_loss=0.22437]
[2025-06-06 18:09:13.630]  Step 329     [4.627 sec/step, loss=0.20802, avg_loss=0.22414]
[2025-06-06 18:09:17.012]  Step 330     [4.611 sec/step, loss=0.21052, avg_loss=0.22389]
[2025-06-06 18:09:24.180]  Step 331     [4.634 sec/step, loss=0.22015, avg_loss=0.22378]
[2025-06-06 18:09:37.390]  Step 332     [4.694 sec/step, loss=0.21133, avg_loss=0.22353]
[2025-06-06 18:09:39.948]  Step 333     [4.693 sec/step, loss=0.21356, avg_loss=0.22333]
[2025-06-06 18:09:42.504]  Step 334     [4.662 sec/step, loss=0.21166, avg_loss=0.22311]
[2025-06-06 18:09:44.722]  Step 335     [4.659 sec/step, loss=0.21061, avg_loss=0.22286]
[2025-06-06 18:09:47.332]  Generated 32 batches of size 32 in 4.405 sec
[2025-06-06 18:09:51.309]  Step 336     [4.691 sec/step, loss=0.21424, avg_loss=0.22273]
[2025-06-06 18:09:52.966]  Step 337     [4.620 sec/step, loss=0.20328, avg_loss=0.22240]
[2025-06-06 18:09:57.191]  Step 338     [4.631 sec/step, loss=0.21479, avg_loss=0.22228]
[2025-06-06 18:10:05.811]  Step 339     [4.687 sec/step, loss=0.22224, avg_loss=0.22218]
[2025-06-06 18:10:08.016]  Step 340     [4.675 sec/step, loss=0.21334, avg_loss=0.22206]
[2025-06-06 18:10:16.901]  Step 341     [4.728 sec/step, loss=0.22049, avg_loss=0.22201]
[2025-06-06 18:10:18.383]  Step 342     [4.725 sec/step, loss=0.20118, avg_loss=0.22176]
[2025-06-06 18:10:25.516]  Step 343     [4.770 sec/step, loss=0.22547, avg_loss=0.22169]
[2025-06-06 18:10:27.766]  Step 344     [4.747 sec/step, loss=0.21332, avg_loss=0.22152]
[2025-06-06 18:10:32.281]  Step 345     [4.734 sec/step, loss=0.21864, avg_loss=0.22142]
[2025-06-06 18:10:37.590]  Step 346     [4.671 sec/step, loss=0.21717, avg_loss=0.22127]
[2025-06-06 18:10:39.077]  Step 347     [4.663 sec/step, loss=0.20313, avg_loss=0.22098]
[2025-06-06 18:10:42.220]  Step 348     [4.677 sec/step, loss=0.21650, avg_loss=0.22088]
[2025-06-06 18:10:45.649]  Step 349     [4.672 sec/step, loss=0.21669, avg_loss=0.22069]
[2025-06-06 18:10:51.218]  Step 350     [4.683 sec/step, loss=0.21575, avg_loss=0.22056]
[2025-06-06 18:10:51.218]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-350
[2025-06-06 18:10:52.300]  Saving audio and alignment...
[2025-06-06 18:10:57.505]  Input: inttrnesnl bijines mesinle aaphno vyvsaay vishvbhr phailaaeko ch~_________
[2025-06-06 18:11:01.891]  Step 351     [4.700 sec/step, loss=0.21779, avg_loss=0.22042]
[2025-06-06 18:11:04.109]  Step 352     [4.704 sec/step, loss=0.21352, avg_loss=0.22024]
[2025-06-06 18:11:09.104]  Step 353     [4.689 sec/step, loss=0.21731, avg_loss=0.22010]
[2025-06-06 18:11:11.063]  Step 354     [4.694 sec/step, loss=0.20708, avg_loss=0.21998]
[2025-06-06 18:11:15.115]  Step 355     [4.693 sec/step, loss=0.21482, avg_loss=0.21981]
[2025-06-06 18:11:18.119]  Step 356     [4.406 sec/step, loss=0.21325, avg_loss=0.21976]
[2025-06-06 18:11:23.104]  Step 357     [4.438 sec/step, loss=0.21395, avg_loss=0.21963]
[2025-06-06 18:11:26.051]  Step 358     [4.397 sec/step, loss=0.21506, avg_loss=0.21938]
[2025-06-06 18:11:29.463]  Step 359     [4.387 sec/step, loss=0.21157, avg_loss=0.21919]
[2025-06-06 18:11:36.368]  Step 360     [4.424 sec/step, loss=0.21568, avg_loss=0.21905]
[2025-06-06 18:11:40.089]  Step 361     [4.423 sec/step, loss=0.20920, avg_loss=0.21881]
[2025-06-06 18:11:41.971]  Step 362     [4.384 sec/step, loss=0.21038, avg_loss=0.21859]
[2025-06-06 18:11:43.736]  Step 363     [4.379 sec/step, loss=0.20558, avg_loss=0.21836]
[2025-06-06 18:11:47.599]  Step 364     [4.398 sec/step, loss=0.21126, avg_loss=0.21818]
[2025-06-06 18:11:55.980]  Step 365     [4.444 sec/step, loss=0.21550, avg_loss=0.21810]
[2025-06-06 18:11:59.309]  Step 366     [4.461 sec/step, loss=0.21205, avg_loss=0.21792]
[2025-06-06 18:12:00.768]  Generated 32 batches of size 32 in 4.370 sec
[2025-06-06 18:12:02.639]  Step 367     [4.473 sec/step, loss=0.21087, avg_loss=0.21779]
[2025-06-06 18:12:10.459]  Step 368     [4.503 sec/step, loss=0.21445, avg_loss=0.21766]
[2025-06-06 18:12:13.192]  Step 369     [4.504 sec/step, loss=0.21092, avg_loss=0.21751]
[2025-06-06 18:12:48.864]  Step 370     [4.815 sec/step, loss=0.19509, avg_loss=0.21721]
[2025-06-06 18:12:55.122]  Step 371     [4.857 sec/step, loss=0.21588, avg_loss=0.21711]
[2025-06-06 18:13:04.528]  Step 372     [4.898 sec/step, loss=0.21051, avg_loss=0.21697]
[2025-06-06 18:13:07.027]  Step 373     [4.836 sec/step, loss=0.20801, avg_loss=0.21680]
[2025-06-06 18:13:08.742]  Step 374     [4.805 sec/step, loss=0.20968, avg_loss=0.21667]
[2025-06-06 18:13:15.082]  Step 375     [4.831 sec/step, loss=0.21525, avg_loss=0.21662]
[2025-06-06 18:13:20.948]  Step 376     [4.707 sec/step, loss=0.21392, avg_loss=0.21647]
[2025-06-06 18:13:22.570]  Step 377     [4.686 sec/step, loss=0.20691, avg_loss=0.21631]
[2025-06-06 18:13:29.034]  Step 378     [4.720 sec/step, loss=0.20863, avg_loss=0.21615]
[2025-06-06 18:13:37.521]  Step 379     [4.772 sec/step, loss=0.21723, avg_loss=0.21607]
[2025-06-06 18:13:53.546]  Step 380     [4.900 sec/step, loss=0.18647, avg_loss=0.21568]
[2025-06-06 18:13:59.147]  Step 381     [4.930 sec/step, loss=0.21387, avg_loss=0.21563]
[2025-06-06 18:14:01.518]  Step 382     [4.919 sec/step, loss=0.20569, avg_loss=0.21546]
[2025-06-06 18:14:03.009]  Step 383     [4.897 sec/step, loss=0.19037, avg_loss=0.21515]
[2025-06-06 18:14:05.180]  Step 384     [4.822 sec/step, loss=0.20567, avg_loss=0.21501]
[2025-06-06 18:14:09.493]  Step 385     [4.832 sec/step, loss=0.21053, avg_loss=0.21492]
[2025-06-06 18:14:16.933]  Step 386     [4.887 sec/step, loss=0.21612, avg_loss=0.21483]
[2025-06-06 18:14:19.552]  Step 387     [4.885 sec/step, loss=0.20530, avg_loss=0.21466]
[2025-06-06 18:14:27.613]  Step 388     [4.942 sec/step, loss=0.21550, avg_loss=0.21462]
[2025-06-06 18:14:30.751]  Step 389     [4.923 sec/step, loss=0.20742, avg_loss=0.21443]
[2025-06-06 18:14:34.284]  Step 390     [4.895 sec/step, loss=0.20760, avg_loss=0.21428]
[2025-06-06 18:14:36.843]  Step 391     [4.889 sec/step, loss=0.21173, avg_loss=0.21417]
[2025-06-06 18:14:38.654]  Step 392     [4.874 sec/step, loss=0.20462, avg_loss=0.21397]
[2025-06-06 18:14:41.956]  Step 393     [4.855 sec/step, loss=0.20579, avg_loss=0.21380]
[2025-06-06 18:14:46.832]  Step 394     [4.845 sec/step, loss=0.21318, avg_loss=0.21371]
[2025-06-06 18:14:50.194]  Step 395     [4.850 sec/step, loss=0.20916, avg_loss=0.21359]
[2025-06-06 18:14:54.499]  Step 396     [4.826 sec/step, loss=0.21235, avg_loss=0.21352]
[2025-06-06 18:14:59.787]  Step 397     [4.640 sec/step, loss=0.20914, avg_loss=0.21347]
[2025-06-06 18:15:05.108]  Generated 32 batches of size 32 in 4.832 sec
[2025-06-06 18:15:06.521]  Step 398     [4.661 sec/step, loss=0.21187, avg_loss=0.21333]
[2025-06-06 18:15:10.640]  Step 399     [4.684 sec/step, loss=0.20492, avg_loss=0.21320]
[2025-06-06 18:15:12.790]  Step 400     [4.689 sec/step, loss=0.20602, avg_loss=0.21312]
[2025-06-06 18:15:12.791]  Writing summary at step: 400
[2025-06-06 18:15:16.962]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-400
[2025-06-06 18:15:18.012]  Saving audio and alignment...
[2025-06-06 18:15:22.911]  Input: mrraakes euttaa snsaarkai vicitrko shr ho~_____________________________
[2025-06-06 18:15:25.102]  Step 401     [4.674 sec/step, loss=0.20358, avg_loss=0.21293]
[2025-06-06 18:15:28.194]  Step 402     [4.645 sec/step, loss=0.20764, avg_loss=0.21277]
[2025-06-06 18:15:30.017]  Step 403     [4.632 sec/step, loss=0.20056, avg_loss=0.21256]
[2025-06-06 18:15:32.738]  Step 404     [4.595 sec/step, loss=0.20507, avg_loss=0.21241]
[2025-06-06 18:15:39.537]  Step 405     [4.620 sec/step, loss=0.20695, avg_loss=0.21227]
[2025-06-06 18:15:41.928]  Step 406     [4.569 sec/step, loss=0.20972, avg_loss=0.21211]
[2025-06-06 18:15:43.904]  Step 407     [4.569 sec/step, loss=0.19599, avg_loss=0.21192]
[2025-06-06 18:15:46.562]  Step 408     [4.517 sec/step, loss=0.20178, avg_loss=0.21165]
[2025-06-06 18:15:48.815]  Step 409     [4.524 sec/step, loss=0.20101, avg_loss=0.21150]
[2025-06-06 18:15:51.540]  Step 410     [4.525 sec/step, loss=0.20375, avg_loss=0.21135]
[2025-06-06 18:15:56.975]  Step 411     [4.540 sec/step, loss=0.21061, avg_loss=0.21126]
[2025-06-06 18:16:05.191]  Step 412     [4.573 sec/step, loss=0.21368, avg_loss=0.21120]
[2025-06-06 18:16:09.852]  Step 413     [4.589 sec/step, loss=0.20440, avg_loss=0.21108]
[2025-06-06 18:16:13.253]  Step 414     [4.597 sec/step, loss=0.20530, avg_loss=0.21092]
[2025-06-06 18:16:18.306]  Step 415     [4.605 sec/step, loss=0.20553, avg_loss=0.21080]
[2025-06-06 18:16:22.378]  Step 416     [4.606 sec/step, loss=0.20759, avg_loss=0.21064]
[2025-06-06 18:16:24.154]  Step 417     [4.592 sec/step, loss=0.20092, avg_loss=0.21050]
[2025-06-06 18:16:27.270]  Step 418     [4.559 sec/step, loss=0.20135, avg_loss=0.21032]
[2025-06-06 18:16:34.270]  Step 419     [4.574 sec/step, loss=0.20752, avg_loss=0.21020]
[2025-06-06 18:16:35.925]  Step 420     [4.542 sec/step, loss=0.18852, avg_loss=0.20993]
[2025-06-06 18:16:57.272]  Step 421     [4.738 sec/step, loss=0.19612, avg_loss=0.20973]
[2025-06-06 18:17:01.183]  Step 422     [4.745 sec/step, loss=0.20928, avg_loss=0.20964]
[2025-06-06 18:17:11.408]  Step 423     [4.812 sec/step, loss=0.20321, avg_loss=0.20954]
[2025-06-06 18:17:16.743]  Step 424     [4.838 sec/step, loss=0.20551, avg_loss=0.20943]
[2025-06-06 18:17:19.805]  Step 425     [4.846 sec/step, loss=0.20645, avg_loss=0.20934]
[2025-06-06 18:17:27.761]  Step 426     [4.890 sec/step, loss=0.21504, avg_loss=0.20939]
[2025-06-06 18:17:31.333]  Step 427     [4.871 sec/step, loss=0.20507, avg_loss=0.20929]
[2025-06-06 18:17:35.936]  Step 428     [4.896 sec/step, loss=0.20239, avg_loss=0.20921]
[2025-06-06 18:17:36.369]  Generated 32 batches of size 32 in 4.598 sec
[2025-06-06 18:17:42.408]  Step 429     [4.922 sec/step, loss=0.21069, avg_loss=0.20924]
[2025-06-06 18:17:49.411]  Step 430     [4.958 sec/step, loss=0.21110, avg_loss=0.20924]
[2025-06-06 18:17:51.821]  Step 431     [4.911 sec/step, loss=0.20318, avg_loss=0.20908]
[2025-06-06 18:17:55.760]  Step 432     [4.818 sec/step, loss=0.20180, avg_loss=0.20898]
[2025-06-06 18:17:57.722]  Step 433     [4.812 sec/step, loss=0.20006, avg_loss=0.20884]
[2025-06-06 18:18:00.400]  Step 434     [4.813 sec/step, loss=0.20287, avg_loss=0.20876]
[2025-06-06 18:18:03.621]  Step 435     [4.823 sec/step, loss=0.21012, avg_loss=0.20875]
[2025-06-06 18:18:07.794]  Step 436     [4.799 sec/step, loss=0.20924, avg_loss=0.20870]
[2025-06-06 18:18:16.350]  Step 437     [4.868 sec/step, loss=0.21178, avg_loss=0.20879]
[2025-06-06 18:18:18.543]  Step 438     [4.848 sec/step, loss=0.20238, avg_loss=0.20866]
[2025-06-06 18:18:20.763]  Step 439     [4.784 sec/step, loss=0.20251, avg_loss=0.20847]
[2025-06-06 18:18:23.428]  Step 440     [4.789 sec/step, loss=0.19919, avg_loss=0.20832]
[2025-06-06 18:18:27.325]  Step 441     [4.739 sec/step, loss=0.20422, avg_loss=0.20816]
[2025-06-06 18:18:32.233]  Step 442     [4.773 sec/step, loss=0.20529, avg_loss=0.20820]
[2025-06-06 18:18:34.817]  Step 443     [4.728 sec/step, loss=0.20036, avg_loss=0.20795]
[2025-06-06 18:18:39.990]  Step 444     [4.757 sec/step, loss=0.20661, avg_loss=0.20788]
[2025-06-06 18:18:46.785]  Step 445     [4.780 sec/step, loss=0.20859, avg_loss=0.20778]
[2025-06-06 18:18:50.114]  Step 446     [4.760 sec/step, loss=0.20469, avg_loss=0.20766]
[2025-06-06 18:18:54.658]  Step 447     [4.791 sec/step, loss=0.20910, avg_loss=0.20772]
[2025-06-06 18:18:58.041]  Step 448     [4.793 sec/step, loss=0.20007, avg_loss=0.20755]
[2025-06-06 18:19:01.914]  Step 449     [4.797 sec/step, loss=0.20785, avg_loss=0.20747]
[2025-06-06 18:19:06.113]  Step 450     [4.784 sec/step, loss=0.20187, avg_loss=0.20733]
[2025-06-06 18:19:06.114]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-450
[2025-06-06 18:19:07.208]  Saving audio and alignment...
[2025-06-06 18:19:12.214]  Input: amerikii haasy abhinetaa abhinetaa r klaakaar~________________________________
[2025-06-06 18:19:13.870]  Step 451     [4.756 sec/step, loss=0.18562, avg_loss=0.20701]
[2025-06-06 18:19:17.275]  Step 452     [4.768 sec/step, loss=0.20318, avg_loss=0.20690]
[2025-06-06 18:19:24.127]  Step 453     [4.787 sec/step, loss=0.20760, avg_loss=0.20681]
[2025-06-06 18:19:33.617]  Step 454     [4.862 sec/step, loss=0.20526, avg_loss=0.20679]
[2025-06-06 18:19:39.106]  Step 455     [4.876 sec/step, loss=0.20488, avg_loss=0.20669]
[2025-06-06 18:19:41.987]  Step 456     [4.875 sec/step, loss=0.19872, avg_loss=0.20654]
[2025-06-06 18:19:43.944]  Step 457     [4.845 sec/step, loss=0.19720, avg_loss=0.20637]
[2025-06-06 18:19:49.575]  Step 458     [4.872 sec/step, loss=0.20750, avg_loss=0.20630]
[2025-06-06 18:19:54.285]  Generated 32 batches of size 32 in 4.200 sec
[2025-06-06 18:19:59.199]  Step 459     [4.934 sec/step, loss=0.20679, avg_loss=0.20625]
[2025-06-06 18:20:02.639]  Step 460     [4.899 sec/step, loss=0.20429, avg_loss=0.20614]
[2025-06-06 18:20:08.961]  Step 461     [4.925 sec/step, loss=0.20117, avg_loss=0.20606]
[2025-06-06 18:20:11.884]  Step 462     [4.936 sec/step, loss=0.20460, avg_loss=0.20600]
[2025-06-06 18:20:42.442]  Step 463     [5.223 sec/step, loss=0.18884, avg_loss=0.20583]
[2025-06-06 18:20:44.377]  Step 464     [5.204 sec/step, loss=0.19931, avg_loss=0.20571]
[2025-06-06 18:20:48.757]  Step 465     [5.164 sec/step, loss=0.20306, avg_loss=0.20559]
[2025-06-06 18:20:50.771]  Step 466     [5.151 sec/step, loss=0.19762, avg_loss=0.20544]
[2025-06-06 18:20:53.343]  Step 467     [5.143 sec/step, loss=0.20399, avg_loss=0.20538]
[2025-06-06 18:20:56.487]  Step 468     [5.097 sec/step, loss=0.20468, avg_loss=0.20528]
[2025-06-06 18:20:59.212]  Step 469     [5.097 sec/step, loss=0.19872, avg_loss=0.20516]
[2025-06-06 18:21:04.525]  Step 470     [4.793 sec/step, loss=0.20597, avg_loss=0.20526]
[2025-06-06 18:21:13.660]  Step 471     [4.822 sec/step, loss=0.20605, avg_loss=0.20517]
[2025-06-06 18:21:22.221]  Step 472     [4.814 sec/step, loss=0.20882, avg_loss=0.20515]
[2025-06-06 18:21:23.892]  Step 473     [4.805 sec/step, loss=0.18347, avg_loss=0.20490]
[2025-06-06 18:21:27.506]  Step 474     [4.824 sec/step, loss=0.20512, avg_loss=0.20486]
[2025-06-06 18:21:30.385]  Step 475     [4.790 sec/step, loss=0.20305, avg_loss=0.20474]
[2025-06-06 18:21:37.210]  Step 476     [4.799 sec/step, loss=0.20465, avg_loss=0.20464]
[2025-06-06 18:21:41.548]  Step 477     [4.826 sec/step, loss=0.20140, avg_loss=0.20459]
[2025-06-06 18:21:47.151]  Step 478     [4.818 sec/step, loss=0.20272, avg_loss=0.20453]
[2025-06-06 18:21:49.638]  Step 479     [4.758 sec/step, loss=0.19607, avg_loss=0.20432]
[2025-06-06 18:21:54.533]  Step 480     [4.647 sec/step, loss=0.20480, avg_loss=0.20450]
[2025-06-06 18:22:08.218]  Step 481     [4.727 sec/step, loss=0.19232, avg_loss=0.20429]
[2025-06-06 18:22:14.632]  Step 482     [4.768 sec/step, loss=0.20299, avg_loss=0.20426]
[2025-06-06 18:22:17.514]  Step 483     [4.782 sec/step, loss=0.19812, avg_loss=0.20434]
[2025-06-06 18:22:19.601]  Step 484     [4.781 sec/step, loss=0.19849, avg_loss=0.20426]
[2025-06-06 18:22:23.371]  Step 485     [4.775 sec/step, loss=0.19815, avg_loss=0.20414]
[2025-06-06 18:22:31.165]  Step 486     [4.779 sec/step, loss=0.20614, avg_loss=0.20404]
[2025-06-06 18:22:33.507]  Step 487     [4.776 sec/step, loss=0.19813, avg_loss=0.20397]
[2025-06-06 18:22:37.686]  Step 488     [4.737 sec/step, loss=0.19806, avg_loss=0.20379]
[2025-06-06 18:22:41.635]  Step 489     [4.745 sec/step, loss=0.20009, avg_loss=0.20372]
[2025-06-06 18:22:45.007]  Step 490     [4.744 sec/step, loss=0.19723, avg_loss=0.20362]
[2025-06-06 18:22:46.951]  Step 491     [4.738 sec/step, loss=0.18953, avg_loss=0.20340]
[2025-06-06 18:22:50.419]  Generated 32 batches of size 32 in 5.072 sec
[2025-06-06 18:22:55.407]  Step 492     [4.804 sec/step, loss=0.20655, avg_loss=0.20341]
[2025-06-06 18:23:01.375]  Step 493     [4.831 sec/step, loss=0.20109, avg_loss=0.20337]
[2025-06-06 18:23:04.655]  Step 494     [4.815 sec/step, loss=0.20095, avg_loss=0.20325]
[2025-06-06 18:23:06.726]  Step 495     [4.802 sec/step, loss=0.19438, avg_loss=0.20310]
[2025-06-06 18:23:08.610]  Step 496     [4.778 sec/step, loss=0.18997, avg_loss=0.20287]
[2025-06-06 18:23:11.524]  Step 497     [4.754 sec/step, loss=0.20057, avg_loss=0.20279]
[2025-06-06 18:23:16.095]  Step 498     [4.732 sec/step, loss=0.20080, avg_loss=0.20268]
[2025-06-06 18:23:20.347]  Step 499     [4.734 sec/step, loss=0.20339, avg_loss=0.20266]
[2025-06-06 18:23:24.672]  Step 500     [4.755 sec/step, loss=0.19929, avg_loss=0.20259]
[2025-06-06 18:23:24.672]  Writing summary at step: 500
[2025-06-06 18:23:26.406]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-500
[2025-06-06 18:23:27.531]  Saving audio and alignment...
[2025-06-06 18:23:31.192]  Input: puurvii esiyaamaa rheko puurv saamraajy~_________
[2025-06-06 18:23:34.008]  Step 501     [4.762 sec/step, loss=0.19679, avg_loss=0.20253]
[2025-06-06 18:23:39.419]  Step 502     [4.785 sec/step, loss=0.20307, avg_loss=0.20248]
[2025-06-06 18:24:03.682]  Step 503     [5.009 sec/step, loss=0.18101, avg_loss=0.20229]
[2025-06-06 18:24:06.830]  Step 504     [5.013 sec/step, loss=0.20085, avg_loss=0.20224]
[2025-06-06 18:24:10.426]  Step 505     [4.981 sec/step, loss=0.20139, avg_loss=0.20219]
[2025-06-06 18:24:13.066]  Step 506     [4.984 sec/step, loss=0.19745, avg_loss=0.20207]
[2025-06-06 18:24:16.918]  Step 507     [5.003 sec/step, loss=0.20333, avg_loss=0.20214]
[2025-06-06 18:24:18.584]  Step 508     [4.993 sec/step, loss=0.18613, avg_loss=0.20198]
[2025-06-06 18:24:23.843]  Step 509     [5.023 sec/step, loss=0.20283, avg_loss=0.20200]
[2025-06-06 18:24:32.948]  Step 510     [5.087 sec/step, loss=0.20262, avg_loss=0.20199]
[2025-06-06 18:24:35.357]  Step 511     [5.056 sec/step, loss=0.19905, avg_loss=0.20187]
[2025-06-06 18:24:40.674]  Step 512     [5.027 sec/step, loss=0.20102, avg_loss=0.20175]
[2025-06-06 18:24:44.001]  Step 513     [5.014 sec/step, loss=0.20360, avg_loss=0.20174]
[2025-06-06 18:24:47.161]  Step 514     [5.012 sec/step, loss=0.19892, avg_loss=0.20168]

-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2025-06-07 06:45:58.952]  Checkpoint path: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt
[2025-06-07 06:45:58.952]  Loading training data from: E:/newtacotron/tacotron/training/train.txt
[2025-06-07 06:45:58.953]  Using model: tacotron
[2025-06-07 06:45:58.953]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: transliteration_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 300
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: False
[2025-06-07 06:45:58.975]  Loaded metadata for 2064 examples (2.80 hours)
[2025-06-07 06:46:00.470]  Initialized Tacotron model. Dimensions: 
[2025-06-07 06:46:00.471]    embedding:               256
[2025-06-07 06:46:00.471]    prenet out:              128
[2025-06-07 06:46:00.471]    encoder out:             256
[2025-06-07 06:46:00.471]    attention out:           256
[2025-06-07 06:46:00.471]    concat attn & out:       512
[2025-06-07 06:46:00.471]    decoder cell out:        256
[2025-06-07 06:46:00.472]    decoder out (5 frames):  400
[2025-06-07 06:46:00.472]    decoder out (1 frame):   80
[2025-06-07 06:46:00.472]    postnet out:             256
[2025-06-07 06:46:00.472]    linear out:              1025
[2025-06-07 06:46:08.687]  Resuming from checkpoint: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75000 at commit: None
[2025-06-07 06:46:26.120]  Generated 32 batches of size 32 in 17.433 sec
[2025-06-07 06:46:30.767]  Step 75001   [22.072 sec/step, loss=0.08940, avg_loss=0.08940]
[2025-06-07 06:46:44.866]  Step 75002   [18.081 sec/step, loss=0.09670, avg_loss=0.09305]
[2025-06-07 06:46:47.116]  Step 75003   [12.803 sec/step, loss=0.08699, avg_loss=0.09103]
[2025-06-07 06:46:51.245]  Step 75004   [10.635 sec/step, loss=0.09039, avg_loss=0.09087]
[2025-06-07 06:46:57.823]  Step 75005   [9.823 sec/step, loss=0.09390, avg_loss=0.09148]
[2025-06-07 06:47:01.093]  Step 75006   [8.731 sec/step, loss=0.08690, avg_loss=0.09071]
[2025-06-07 06:47:09.075]  Step 75007   [8.624 sec/step, loss=0.09343, avg_loss=0.09110]
[2025-06-07 06:47:16.052]  Step 75008   [8.418 sec/step, loss=0.09452, avg_loss=0.09153]
[2025-06-07 06:47:19.719]  Step 75009   [7.890 sec/step, loss=0.08775, avg_loss=0.09111]
[2025-06-07 06:47:22.968]  Step 75010   [7.426 sec/step, loss=0.08603, avg_loss=0.09060]
[2025-06-07 06:47:28.575]  Step 75011   [7.261 sec/step, loss=0.08961, avg_loss=0.09051]
[2025-06-07 06:47:35.539]  Step 75012   [7.236 sec/step, loss=0.09379, avg_loss=0.09079]
[2025-06-07 06:47:36.822]  Step 75013   [6.778 sec/step, loss=0.06825, avg_loss=0.08905]
[2025-06-07 06:47:38.308]  Step 75014   [6.400 sec/step, loss=0.07647, avg_loss=0.08815]
[2025-06-07 06:47:40.725]  Step 75015   [6.134 sec/step, loss=0.08353, avg_loss=0.08784]
[2025-06-07 06:47:46.023]  Step 75016   [6.082 sec/step, loss=0.09169, avg_loss=0.08809]
[2025-06-07 06:47:50.911]  Step 75017   [6.012 sec/step, loss=0.09118, avg_loss=0.08827]
[2025-06-07 06:47:54.013]  Step 75018   [5.850 sec/step, loss=0.08538, avg_loss=0.08811]
[2025-06-07 06:47:57.120]  Step 75019   [5.706 sec/step, loss=0.08472, avg_loss=0.08793]
[2025-06-07 06:47:59.234]  Step 75020   [5.526 sec/step, loss=0.08342, avg_loss=0.08770]
[2025-06-07 06:52:59.714]  Step 75021   [19.571 sec/step, loss=0.08580, avg_loss=0.08761]
[2025-06-07 06:53:02.550]  Step 75022   [18.810 sec/step, loss=0.08008, avg_loss=0.08727]
[2025-06-07 06:53:05.120]  Step 75023   [18.104 sec/step, loss=0.07941, avg_loss=0.08693]
[2025-06-07 06:53:08.941]  Step 75024   [17.509 sec/step, loss=0.08379, avg_loss=0.08680]
[2025-06-07 06:53:12.244]  Step 75025   [16.940 sec/step, loss=0.08371, avg_loss=0.08667]
[2025-06-07 06:53:18.690]  Step 75026   [16.537 sec/step, loss=0.09100, avg_loss=0.08684]
[2025-06-07 06:53:20.247]  Step 75027   [15.982 sec/step, loss=0.07489, avg_loss=0.08640]
[2025-06-07 06:53:25.636]  Step 75028   [15.604 sec/step, loss=0.08823, avg_loss=0.08646]
[2025-06-07 06:53:27.694]  Step 75029   [15.136 sec/step, loss=0.07755, avg_loss=0.08616]
[2025-06-07 06:53:30.185]  Step 75030   [14.715 sec/step, loss=0.08051, avg_loss=0.08597]
[2025-06-07 06:53:34.810]  Generated 32 batches of size 32 in 28.895 sec
[2025-06-07 06:53:36.411]  Step 75031   [14.441 sec/step, loss=0.08780, avg_loss=0.08603]
[2025-06-07 06:54:06.094]  Step 75032   [14.917 sec/step, loss=0.08154, avg_loss=0.08589]
[2025-06-07 06:54:13.956]  Step 75033   [14.703 sec/step, loss=0.09077, avg_loss=0.08603]
[2025-06-07 06:54:18.069]  Step 75034   [14.392 sec/step, loss=0.08673, avg_loss=0.08606]
[2025-06-07 06:54:19.809]  Step 75035   [14.030 sec/step, loss=0.07883, avg_loss=0.08585]
[2025-06-07 06:54:36.420]  Step 75036   [14.101 sec/step, loss=0.08106, avg_loss=0.08572]
[2025-06-07 06:54:44.472]  Step 75037   [13.938 sec/step, loss=0.09076, avg_loss=0.08585]
[2025-06-07 06:54:47.322]  Step 75038   [13.646 sec/step, loss=0.08509, avg_loss=0.08583]
[2025-06-07 06:54:49.207]  Step 75039   [13.344 sec/step, loss=0.08236, avg_loss=0.08574]
[2025-06-07 06:54:50.858]  Step 75040   [13.052 sec/step, loss=0.08112, avg_loss=0.08563]
[2025-06-07 06:54:53.802]  Step 75041   [12.806 sec/step, loss=0.08626, avg_loss=0.08564]
[2025-06-07 06:54:58.455]  Step 75042   [12.611 sec/step, loss=0.08977, avg_loss=0.08574]
[2025-06-07 06:55:00.226]  Step 75043   [12.359 sec/step, loss=0.08284, avg_loss=0.08567]
[2025-06-07 06:55:01.750]  Step 75044   [12.113 sec/step, loss=0.07900, avg_loss=0.08552]
[2025-06-07 06:55:05.969]  Step 75045   [11.938 sec/step, loss=0.08897, avg_loss=0.08560]
[2025-06-07 06:55:09.611]  Step 75046   [11.757 sec/step, loss=0.08789, avg_loss=0.08565]
[2025-06-07 06:55:12.027]  Step 75047   [11.558 sec/step, loss=0.08606, avg_loss=0.08566]
[2025-06-07 06:55:13.445]  Step 75048   [11.347 sec/step, loss=0.07872, avg_loss=0.08551]
[2025-06-07 06:55:16.602]  Step 75049   [11.180 sec/step, loss=0.08651, avg_loss=0.08553]
[2025-06-07 06:55:18.796]  Step 75050   [11.000 sec/step, loss=0.08391, avg_loss=0.08550]
[2025-06-07 06:55:18.796]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75050
[2025-06-07 06:55:20.193]  Saving audio and alignment...
[2025-06-07 06:55:25.001]  Input: vesttrn tnduriile yskaa graahkhruulaaii raamro sevaa prdaan greko kuraa jaankaariimaa aaeko ch~___
[2025-06-07 06:55:28.606]  Step 75051   [10.855 sec/step, loss=0.08829, avg_loss=0.08556]
[2025-06-07 06:55:29.770]  Step 75052   [10.669 sec/step, loss=0.07388, avg_loss=0.08533]
[2025-06-07 06:55:31.627]  Step 75053   [10.503 sec/step, loss=0.08249, avg_loss=0.08528]
[2025-06-07 06:55:34.375]  Step 75054   [10.359 sec/step, loss=0.08641, avg_loss=0.08530]
[2025-06-07 06:55:37.618]  Step 75055   [10.230 sec/step, loss=0.08491, avg_loss=0.08529]
[2025-06-07 06:55:38.850]  Generated 32 batches of size 32 in 4.212 sec
[2025-06-07 06:55:40.245]  Step 75056   [10.094 sec/step, loss=0.08357, avg_loss=0.08526]
[2025-06-07 06:55:44.714]  Step 75057   [9.995 sec/step, loss=0.08766, avg_loss=0.08530]
[2025-06-07 06:55:46.950]  Step 75058   [9.861 sec/step, loss=0.08270, avg_loss=0.08526]
[2025-06-07 06:55:58.930]  Step 75059   [9.897 sec/step, loss=0.09064, avg_loss=0.08535]
[2025-06-07 06:56:01.520]  Step 75060   [9.775 sec/step, loss=0.08359, avg_loss=0.08532]
[2025-06-07 06:56:07.334]  Step 75061   [9.710 sec/step, loss=0.09010, avg_loss=0.08540]
[2025-06-07 06:56:10.131]  Step 75062   [9.599 sec/step, loss=0.08641, avg_loss=0.08541]
[2025-06-07 06:56:15.169]  Step 75063   [9.526 sec/step, loss=0.08970, avg_loss=0.08548]
[2025-06-07 06:56:18.715]  Step 75064   [9.433 sec/step, loss=0.08474, avg_loss=0.08547]

-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2025-06-07 07:04:21.645]  Checkpoint path: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt
[2025-06-07 07:04:21.645]  Loading training data from: E:/newtacotron/tacotron/training/train.txt
[2025-06-07 07:04:21.645]  Using model: tacotron
[2025-06-07 07:04:21.646]  Hyperparameters:
  adam_beta1: 0.9
  adam_beta2: 0.999
  attention_depth: 256
  batch_size: 32
  cleaners: transliteration_cleaners
  decay_learning_rate: True
  decoder_depth: 256
  embed_depth: 256
  encoder_depth: 256
  frame_length_ms: 50
  frame_shift_ms: 12.5
  griffin_lim_iters: 60
  initial_learning_rate: 0.002
  max_iters: 300
  min_level_db: -100
  num_freq: 1025
  num_mels: 80
  outputs_per_step: 5
  postnet_depth: 256
  power: 1.5
  preemphasis: 0.97
  prenet_depths: [256, 128]
  ref_level_db: 20
  sample_rate: 20000
  use_cmudict: False
[2025-06-07 07:04:21.670]  Loaded metadata for 2064 examples (2.80 hours)
[2025-06-07 07:04:23.088]  Initialized Tacotron model. Dimensions: 
[2025-06-07 07:04:23.088]    embedding:               256
[2025-06-07 07:04:23.088]    prenet out:              128
[2025-06-07 07:04:23.088]    encoder out:             256
[2025-06-07 07:04:23.089]    attention out:           256
[2025-06-07 07:04:23.089]    concat attn & out:       512
[2025-06-07 07:04:23.089]    decoder cell out:        256
[2025-06-07 07:04:23.089]    decoder out (5 frames):  400
[2025-06-07 07:04:23.089]    decoder out (1 frame):   80
[2025-06-07 07:04:23.089]    postnet out:             256
[2025-06-07 07:04:23.090]    linear out:              1025
[2025-06-07 07:04:30.736]  Resuming from checkpoint: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75000 at commit: None
[2025-06-07 07:04:56.334]  Generated 32 batches of size 32 in 25.596 sec
[2025-06-07 07:04:58.555]  Step 75001   [27.811 sec/step, loss=0.08236, avg_loss=0.08236]
[2025-06-07 07:05:10.189]  Step 75002   [19.717 sec/step, loss=0.09700, avg_loss=0.08968]
[2025-06-07 07:05:14.590]  Step 75003   [14.611 sec/step, loss=0.09370, avg_loss=0.09102]
[2025-06-07 07:05:17.150]  Step 75004   [11.598 sec/step, loss=0.08685, avg_loss=0.08998]
[2025-06-07 07:05:19.450]  Step 75005   [9.738 sec/step, loss=0.08423, avg_loss=0.08883]
[2025-06-07 07:05:22.066]  Step 75006   [8.551 sec/step, loss=0.08585, avg_loss=0.08833]
[2025-06-07 07:05:24.439]  Step 75007   [7.669 sec/step, loss=0.08487, avg_loss=0.08784]
[2025-06-07 07:05:27.715]  Step 75008   [7.120 sec/step, loss=0.08723, avg_loss=0.08776]
[2025-06-07 07:05:33.651]  Step 75009   [6.988 sec/step, loss=0.09456, avg_loss=0.08852]
[2025-06-07 07:05:36.185]  Step 75010   [6.543 sec/step, loss=0.08648, avg_loss=0.08831]
[2025-06-07 07:05:39.211]  Step 75011   [6.223 sec/step, loss=0.08759, avg_loss=0.08825]
[2025-06-07 07:05:41.026]  Step 75012   [5.856 sec/step, loss=0.08092, avg_loss=0.08764]
[2025-06-07 07:05:45.064]  Step 75013   [5.716 sec/step, loss=0.08977, avg_loss=0.08780]
[2025-06-07 07:06:11.461]  Step 75014   [7.192 sec/step, loss=0.08219, avg_loss=0.08740]
[2025-06-07 07:06:14.602]  Step 75015   [6.922 sec/step, loss=0.08629, avg_loss=0.08733]
[2025-06-07 07:06:22.063]  Step 75016   [6.956 sec/step, loss=0.09226, avg_loss=0.08763]
[2025-06-07 07:06:23.339]  Step 75017   [6.621 sec/step, loss=0.07523, avg_loss=0.08691]
[2025-06-07 07:06:25.012]  Step 75018   [6.347 sec/step, loss=0.07944, avg_loss=0.08649]
[2025-06-07 07:06:26.886]  Step 75019   [6.111 sec/step, loss=0.08024, avg_loss=0.08616]
[2025-06-07 07:06:30.813]  Step 75020   [6.002 sec/step, loss=0.08874, avg_loss=0.08629]
[2025-06-07 07:06:33.533]  Step 75021   [5.846 sec/step, loss=0.08384, avg_loss=0.08617]
[2025-06-07 07:06:38.491]  Step 75022   [5.805 sec/step, loss=0.09149, avg_loss=0.08642]
[2025-06-07 07:06:42.778]  Step 75023   [5.739 sec/step, loss=0.08825, avg_loss=0.08650]
[2025-06-07 07:06:45.761]  Step 75024   [5.624 sec/step, loss=0.08404, avg_loss=0.08639]
[2025-06-07 07:06:47.932]  Step 75025   [5.486 sec/step, loss=0.08312, avg_loss=0.08626]
[2025-06-07 07:06:53.811]  Step 75026   [5.501 sec/step, loss=0.09183, avg_loss=0.08648]
[2025-06-07 07:06:54.860]  Step 75027   [5.336 sec/step, loss=0.06824, avg_loss=0.08580]
[2025-06-07 07:06:59.186]  Step 75028   [5.300 sec/step, loss=0.08831, avg_loss=0.08589]
[2025-06-07 07:07:06.838]  Step 75029   [5.381 sec/step, loss=0.09342, avg_loss=0.08615]
[2025-06-07 07:07:12.292]  Generated 32 batches of size 32 in 29.183 sec
[2025-06-07 07:07:13.277]  Step 75030   [5.417 sec/step, loss=0.09304, avg_loss=0.08638]
[2025-06-07 07:07:14.635]  Step 75031   [5.286 sec/step, loss=0.07579, avg_loss=0.08604]
[2025-06-07 07:07:17.039]  Step 75032   [5.196 sec/step, loss=0.08434, avg_loss=0.08598]
[2025-06-07 07:07:20.086]  Step 75033   [5.130 sec/step, loss=0.08707, avg_loss=0.08602]
[2025-06-07 07:07:26.468]  Step 75034   [5.167 sec/step, loss=0.09111, avg_loss=0.08617]
[2025-06-07 07:07:30.129]  Step 75035   [5.124 sec/step, loss=0.08884, avg_loss=0.08624]
[2025-06-07 07:07:31.523]  Step 75036   [5.021 sec/step, loss=0.08018, avg_loss=0.08608]
[2025-06-07 07:07:35.228]  Step 75037   [4.985 sec/step, loss=0.08828, avg_loss=0.08613]
[2025-06-07 07:07:40.786]  Step 75038   [5.000 sec/step, loss=0.09060, avg_loss=0.08625]
[2025-06-07 07:07:43.287]  Step 75039   [4.936 sec/step, loss=0.08568, avg_loss=0.08624]
[2025-06-07 07:07:45.455]  Step 75040   [4.867 sec/step, loss=0.08415, avg_loss=0.08619]
[2025-06-07 07:07:47.484]  Step 75041   [4.798 sec/step, loss=0.08311, avg_loss=0.08611]
[2025-06-07 07:07:52.146]  Step 75042   [4.794 sec/step, loss=0.08970, avg_loss=0.08620]
[2025-06-07 07:07:54.462]  Step 75043   [4.737 sec/step, loss=0.08410, avg_loss=0.08615]
[2025-06-07 07:07:56.220]  Step 75044   [4.669 sec/step, loss=0.08289, avg_loss=0.08607]
[2025-06-07 07:07:58.702]  Step 75045   [4.620 sec/step, loss=0.08591, avg_loss=0.08607]
[2025-06-07 07:08:02.879]  Step 75046   [4.611 sec/step, loss=0.08910, avg_loss=0.08614]
[2025-06-07 07:08:04.566]  Step 75047   [4.548 sec/step, loss=0.08117, avg_loss=0.08603]
[2025-06-07 07:08:06.494]  Step 75048   [4.494 sec/step, loss=0.08222, avg_loss=0.08595]
[2025-06-07 07:08:08.376]  Step 75049   [4.441 sec/step, loss=0.08203, avg_loss=0.08587]
[2025-06-07 07:08:09.960]  Step 75050   [4.383 sec/step, loss=0.07890, avg_loss=0.08573]
[2025-06-07 07:08:09.960]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75050
[2025-06-07 07:08:11.264]  Saving audio and alignment...
[2025-06-07 07:08:15.668]  Input: nksstr ursaa mejrmaa spaairl aakaasgnggaa~______________________________
[2025-06-07 07:08:21.146]  Step 75051   [4.405 sec/step, loss=0.09026, avg_loss=0.08582]
[2025-06-07 07:08:22.508]  Step 75052   [4.346 sec/step, loss=0.07768, avg_loss=0.08566]
[2025-06-07 07:08:25.939]  Step 75053   [4.329 sec/step, loss=0.08694, avg_loss=0.08569]
[2025-06-07 07:08:27.203]  Step 75054   [4.272 sec/step, loss=0.07445, avg_loss=0.08548]
[2025-06-07 07:08:31.439]  Step 75055   [4.272 sec/step, loss=0.08627, avg_loss=0.08549]
[2025-06-07 07:08:32.342]  Generated 32 batches of size 32 in 4.921 sec
[2025-06-07 07:08:55.898]  Step 75056   [4.632 sec/step, loss=0.08092, avg_loss=0.08541]
[2025-06-07 07:08:59.960]  Step 75057   [4.622 sec/step, loss=0.08770, avg_loss=0.08545]
[2025-06-07 07:09:02.434]  Step 75058   [4.585 sec/step, loss=0.08481, avg_loss=0.08544]
[2025-06-07 07:09:06.940]  Step 75059   [4.584 sec/step, loss=0.08911, avg_loss=0.08550]
[2025-06-07 07:09:14.911]  Step 75060   [4.640 sec/step, loss=0.09062, avg_loss=0.08559]
[2025-06-07 07:09:17.812]  Step 75061   [4.611 sec/step, loss=0.08658, avg_loss=0.08560]
[2025-06-07 07:09:24.595]  Step 75062   [4.646 sec/step, loss=0.09001, avg_loss=0.08568]
[2025-06-07 07:09:27.117]  Step 75063   [4.613 sec/step, loss=0.08374, avg_loss=0.08565]
[2025-06-07 07:09:29.345]  Step 75064   [4.575 sec/step, loss=0.08020, avg_loss=0.08556]
[2025-06-07 07:09:33.956]  Step 75065   [4.576 sec/step, loss=0.08773, avg_loss=0.08559]
[2025-06-07 07:09:36.691]  Step 75066   [4.548 sec/step, loss=0.08423, avg_loss=0.08557]
[2025-06-07 07:09:41.733]  Step 75067   [4.555 sec/step, loss=0.08901, avg_loss=0.08562]
[2025-06-07 07:09:44.484]  Step 75068   [4.529 sec/step, loss=0.08374, avg_loss=0.08560]
[2025-06-07 07:09:46.394]  Step 75069   [4.491 sec/step, loss=0.07872, avg_loss=0.08550]
[2025-06-07 07:09:49.872]  Step 75070   [4.476 sec/step, loss=0.08524, avg_loss=0.08549]
[2025-06-07 07:09:55.138]  Step 75071   [4.488 sec/step, loss=0.08971, avg_loss=0.08555]
[2025-06-07 07:10:01.248]  Step 75072   [4.510 sec/step, loss=0.09115, avg_loss=0.08563]
[2025-06-07 07:10:02.836]  Step 75073   [4.470 sec/step, loss=0.07755, avg_loss=0.08552]
[2025-06-07 07:10:06.632]  Step 75074   [4.461 sec/step, loss=0.08624, avg_loss=0.08553]
[2025-06-07 07:10:15.234]  Step 75075   [4.516 sec/step, loss=0.09101, avg_loss=0.08560]
[2025-06-07 07:10:18.438]  Step 75076   [4.499 sec/step, loss=0.08614, avg_loss=0.08561]
[2025-06-07 07:10:20.834]  Step 75077   [4.472 sec/step, loss=0.08243, avg_loss=0.08557]
[2025-06-07 07:10:22.576]  Step 75078   [4.437 sec/step, loss=0.07736, avg_loss=0.08546]
[2025-06-07 07:10:24.879]  Step 75079   [4.410 sec/step, loss=0.08049, avg_loss=0.08540]
[2025-06-07 07:10:30.510]  Step 75080   [4.425 sec/step, loss=0.09056, avg_loss=0.08546]
[2025-06-07 07:10:33.404]  Step 75081   [4.406 sec/step, loss=0.08444, avg_loss=0.08545]
[2025-06-07 07:10:37.379]  Step 75082   [4.401 sec/step, loss=0.08822, avg_loss=0.08549]
[2025-06-07 07:10:39.784]  Step 75083   [4.377 sec/step, loss=0.08259, avg_loss=0.08545]
[2025-06-07 07:10:42.275]  Step 75084   [4.354 sec/step, loss=0.08408, avg_loss=0.08543]
[2025-06-07 07:10:46.073]  Step 75085   [4.348 sec/step, loss=0.08630, avg_loss=0.08544]
[2025-06-07 07:11:07.995]  Step 75086   [4.552 sec/step, loss=0.08648, avg_loss=0.08546]
[2025-06-07 07:11:10.582]  Step 75087   [4.529 sec/step, loss=0.08165, avg_loss=0.08541]
[2025-06-07 07:11:12.610]  Generated 32 batches of size 32 in 4.264 sec
[2025-06-07 07:11:14.811]  Step 75088   [4.526 sec/step, loss=0.08687, avg_loss=0.08543]
[2025-06-07 07:11:18.090]  Step 75089   [4.512 sec/step, loss=0.08457, avg_loss=0.08542]
[2025-06-07 07:11:19.535]  Step 75090   [4.478 sec/step, loss=0.07143, avg_loss=0.08526]
[2025-06-07 07:11:24.520]  Step 75091   [4.483 sec/step, loss=0.08915, avg_loss=0.08531]
[2025-06-07 07:11:27.651]  Step 75092   [4.469 sec/step, loss=0.08520, avg_loss=0.08531]
[2025-06-07 07:11:34.658]  Step 75093   [4.496 sec/step, loss=0.09046, avg_loss=0.08536]
[2025-06-07 07:11:37.701]  Step 75094   [4.480 sec/step, loss=0.08501, avg_loss=0.08536]
[2025-06-07 07:11:45.252]  Step 75095   [4.513 sec/step, loss=0.09391, avg_loss=0.08545]
[2025-06-07 07:11:51.438]  Step 75096   [4.530 sec/step, loss=0.09012, avg_loss=0.08550]
[2025-06-07 07:11:54.835]  Step 75097   [4.518 sec/step, loss=0.08417, avg_loss=0.08548]
[2025-06-07 07:11:58.004]  Step 75098   [4.505 sec/step, loss=0.08509, avg_loss=0.08548]
[2025-06-07 07:12:34.314]  Step 75099   [4.826 sec/step, loss=0.08135, avg_loss=0.08544]
[2025-06-07 07:12:42.063]  Step 75100   [4.855 sec/step, loss=0.09260, avg_loss=0.08551]
[2025-06-07 07:12:42.064]  Writing summary at step: 75100
[2025-06-07 07:12:53.229]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75100
[2025-06-07 07:12:54.060]  Saving audio and alignment...
[2025-06-07 07:13:00.161]  Input: msaaledaar khaanaa rucaaunehruule cilii baar endd bhojnaalymaa jaanu uttm hunch~______________________________
[2025-06-07 07:13:04.076]  Step 75101   [4.616 sec/step, loss=0.08717, avg_loss=0.08556]
[2025-06-07 07:13:06.083]  Step 75102   [4.520 sec/step, loss=0.08037, avg_loss=0.08539]
[2025-06-07 07:13:07.733]  Step 75103   [4.492 sec/step, loss=0.07804, avg_loss=0.08523]
[2025-06-07 07:13:10.478]  Step 75104   [4.494 sec/step, loss=0.08376, avg_loss=0.08520]
[2025-06-07 07:13:13.226]  Step 75105   [4.499 sec/step, loss=0.08557, avg_loss=0.08522]
[2025-06-07 07:13:15.438]  Step 75106   [4.495 sec/step, loss=0.08167, avg_loss=0.08517]
[2025-06-07 07:13:20.096]  Step 75107   [4.517 sec/step, loss=0.08880, avg_loss=0.08521]
[2025-06-07 07:13:24.892]  Step 75108   [4.533 sec/step, loss=0.08890, avg_loss=0.08523]
[2025-06-07 07:13:26.908]  Step 75109   [4.493 sec/step, loss=0.08005, avg_loss=0.08508]
[2025-06-07 07:13:33.207]  Step 75110   [4.531 sec/step, loss=0.09161, avg_loss=0.08514]
[2025-06-07 07:13:37.350]  Step 75111   [4.542 sec/step, loss=0.08825, avg_loss=0.08514]
[2025-06-07 07:13:43.935]  Step 75112   [4.590 sec/step, loss=0.09257, avg_loss=0.08526]
[2025-06-07 07:13:49.363]  Step 75113   [4.604 sec/step, loss=0.08974, avg_loss=0.08526]
[2025-06-07 07:13:50.782]  Step 75114   [4.354 sec/step, loss=0.06978, avg_loss=0.08513]
[2025-06-07 07:13:55.347]  Step 75115   [4.368 sec/step, loss=0.08926, avg_loss=0.08516]
[2025-06-07 07:13:57.238]  Step 75116   [4.313 sec/step, loss=0.07971, avg_loss=0.08504]
[2025-06-07 07:13:59.303]  Step 75117   [4.321 sec/step, loss=0.07778, avg_loss=0.08506]
[2025-06-07 07:14:01.811]  Generated 32 batches of size 32 in 4.237 sec
[2025-06-07 07:14:03.644]  Step 75118   [4.347 sec/step, loss=0.08567, avg_loss=0.08513]
[2025-06-07 07:14:06.338]  Step 75119   [4.356 sec/step, loss=0.08327, avg_loss=0.08516]
[2025-06-07 07:14:08.933]  Step 75120   [4.342 sec/step, loss=0.08226, avg_loss=0.08509]
[2025-06-07 07:14:12.888]  Step 75121   [4.355 sec/step, loss=0.08608, avg_loss=0.08511]
[2025-06-07 07:14:16.247]  Step 75122   [4.339 sec/step, loss=0.08578, avg_loss=0.08506]
[2025-06-07 07:14:17.723]  Step 75123   [4.310 sec/step, loss=0.07552, avg_loss=0.08493]
[2025-06-07 07:14:20.272]  Step 75124   [4.306 sec/step, loss=0.08351, avg_loss=0.08493]
[2025-06-07 07:14:23.209]  Step 75125   [4.314 sec/step, loss=0.08521, avg_loss=0.08495]
[2025-06-07 07:14:25.785]  Step 75126   [4.281 sec/step, loss=0.08376, avg_loss=0.08487]
[2025-06-07 07:14:29.628]  Step 75127   [4.309 sec/step, loss=0.08651, avg_loss=0.08505]
[2025-06-07 07:14:33.675]  Step 75128   [4.306 sec/step, loss=0.08641, avg_loss=0.08503]
[2025-06-07 07:14:35.391]  Step 75129   [4.247 sec/step, loss=0.07751, avg_loss=0.08487]
[2025-06-07 07:14:38.840]  Step 75130   [4.217 sec/step, loss=0.08551, avg_loss=0.08479]
[2025-06-07 07:14:42.084]  Step 75131   [4.235 sec/step, loss=0.08532, avg_loss=0.08489]
[2025-06-07 07:14:45.024]  Step 75132   [4.241 sec/step, loss=0.08320, avg_loss=0.08488]
[2025-06-07 07:14:52.488]  Step 75133   [4.285 sec/step, loss=0.09207, avg_loss=0.08493]
[2025-06-07 07:14:54.133]  Step 75134   [4.238 sec/step, loss=0.07794, avg_loss=0.08480]
[2025-06-07 07:14:56.494]  Step 75135   [4.225 sec/step, loss=0.08287, avg_loss=0.08474]
[2025-06-07 07:15:04.078]  Step 75136   [4.286 sec/step, loss=0.09315, avg_loss=0.08487]
[2025-06-07 07:15:07.388]  Step 75137   [4.282 sec/step, loss=0.08483, avg_loss=0.08483]
[2025-06-07 07:15:09.448]  Step 75138   [4.247 sec/step, loss=0.08097, avg_loss=0.08474]
[2025-06-07 07:15:14.958]  Step 75139   [4.278 sec/step, loss=0.09075, avg_loss=0.08479]
[2025-06-07 07:15:20.561]  Step 75140   [4.312 sec/step, loss=0.09056, avg_loss=0.08485]
[2025-06-07 07:15:29.795]  Step 75141   [4.384 sec/step, loss=0.09045, avg_loss=0.08492]
[2025-06-07 07:15:33.005]  Step 75142   [4.369 sec/step, loss=0.08494, avg_loss=0.08488]
[2025-06-07 07:15:35.924]  Step 75143   [4.375 sec/step, loss=0.08312, avg_loss=0.08487]
[2025-06-07 07:15:40.781]  Step 75144   [4.406 sec/step, loss=0.08772, avg_loss=0.08492]
[2025-06-07 07:15:42.769]  Step 75145   [4.401 sec/step, loss=0.07994, avg_loss=0.08486]
[2025-06-07 07:15:47.039]  Step 75146   [4.402 sec/step, loss=0.08857, avg_loss=0.08485]
[2025-06-07 07:15:48.369]  Step 75147   [4.399 sec/step, loss=0.07207, avg_loss=0.08476]
[2025-06-07 07:15:50.910]  Step 75148   [4.405 sec/step, loss=0.08397, avg_loss=0.08478]
[2025-06-07 07:15:55.291]  Step 75149   [4.430 sec/step, loss=0.08494, avg_loss=0.08481]
[2025-06-07 07:15:55.312]  Generated 32 batches of size 32 in 4.101 sec
[2025-06-07 07:16:00.603]  Step 75150   [4.467 sec/step, loss=0.08889, avg_loss=0.08491]
[2025-06-07 07:16:00.606]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75150
[2025-06-07 07:16:01.609]  Saving audio and alignment...
[2025-06-07 07:16:04.394]  Input: vikimiddiyaa shrennii prsstth~___
[2025-06-07 07:16:06.313]  Step 75151   [4.432 sec/step, loss=0.07867, avg_loss=0.08479]
[2025-06-07 07:16:33.337]  Step 75152   [4.688 sec/step, loss=0.08100, avg_loss=0.08482]
[2025-06-07 07:16:40.534]  Step 75153   [4.726 sec/step, loss=0.09031, avg_loss=0.08486]
[2025-06-07 07:16:45.274]  Step 75154   [4.761 sec/step, loss=0.08772, avg_loss=0.08499]
[2025-06-07 07:16:47.584]  Step 75155   [4.741 sec/step, loss=0.08071, avg_loss=0.08493]
[2025-06-07 07:16:50.581]  Step 75156   [4.527 sec/step, loss=0.08644, avg_loss=0.08499]
[2025-06-07 07:16:54.347]  Step 75157   [4.524 sec/step, loss=0.08590, avg_loss=0.08497]
[2025-06-07 07:16:58.022]  Step 75158   [4.536 sec/step, loss=0.08492, avg_loss=0.08497]
[2025-06-07 07:16:59.598]  Step 75159   [4.507 sec/step, loss=0.06903, avg_loss=0.08477]
[2025-06-07 07:17:01.523]  Step 75160   [4.446 sec/step, loss=0.07989, avg_loss=0.08466]
[2025-06-07 07:17:03.909]  Step 75161   [4.441 sec/step, loss=0.08110, avg_loss=0.08461]
[2025-06-07 07:17:09.974]  Step 75162   [4.434 sec/step, loss=0.08988, avg_loss=0.08461]
[2025-06-07 07:17:13.821]  Step 75163   [4.447 sec/step, loss=0.08610, avg_loss=0.08463]
[2025-06-07 07:17:18.239]  Step 75164   [4.469 sec/step, loss=0.08808, avg_loss=0.08471]
[2025-06-07 07:17:23.885]  Step 75165   [4.479 sec/step, loss=0.08973, avg_loss=0.08473]
[2025-06-07 07:17:25.937]  Step 75166   [4.472 sec/step, loss=0.08017, avg_loss=0.08469]
[2025-06-07 07:17:47.214]  Step 75167   [4.635 sec/step, loss=0.08274, avg_loss=0.08463]
[2025-06-07 07:17:51.336]  Step 75168   [4.648 sec/step, loss=0.08739, avg_loss=0.08466]
[2025-06-07 07:17:56.524]  Step 75169   [4.681 sec/step, loss=0.08911, avg_loss=0.08477]
[2025-06-07 07:18:03.084]  Step 75170   [4.712 sec/step, loss=0.09246, avg_loss=0.08484]
[2025-06-07 07:18:06.248]  Step 75171   [4.691 sec/step, loss=0.08414, avg_loss=0.08478]
[2025-06-07 07:18:08.936]  Step 75172   [4.657 sec/step, loss=0.08373, avg_loss=0.08471]
[2025-06-07 07:18:14.021]  Step 75173   [4.692 sec/step, loss=0.08899, avg_loss=0.08482]
[2025-06-07 07:18:17.345]  Step 75174   [4.687 sec/step, loss=0.08479, avg_loss=0.08481]
[2025-06-07 07:18:19.625]  Step 75175   [4.624 sec/step, loss=0.08254, avg_loss=0.08473]
[2025-06-07 07:18:21.632]  Step 75176   [4.612 sec/step, loss=0.08093, avg_loss=0.08467]
[2025-06-07 07:18:24.210]  Step 75177   [4.614 sec/step, loss=0.08329, avg_loss=0.08468]
[2025-06-07 07:18:26.624]  Step 75178   [4.620 sec/step, loss=0.08439, avg_loss=0.08475]
[2025-06-07 07:18:28.257]  Step 75179   [4.614 sec/step, loss=0.07779, avg_loss=0.08473]
[2025-06-07 07:18:32.735]  Generated 32 batches of size 32 in 4.141 sec
[2025-06-07 07:18:33.711]  Step 75180   [4.612 sec/step, loss=0.08700, avg_loss=0.08469]
[2025-06-07 07:18:35.268]  Step 75181   [4.598 sec/step, loss=0.07725, avg_loss=0.08462]
[2025-06-07 07:18:38.370]  Step 75182   [4.590 sec/step, loss=0.08479, avg_loss=0.08458]
[2025-06-07 07:18:41.395]  Step 75183   [4.596 sec/step, loss=0.08323, avg_loss=0.08459]
[2025-06-07 07:18:50.711]  Step 75184   [4.664 sec/step, loss=0.09319, avg_loss=0.08468]
[2025-06-07 07:18:53.242]  Step 75185   [4.651 sec/step, loss=0.08151, avg_loss=0.08463]
[2025-06-07 07:18:58.237]  Step 75186   [4.482 sec/step, loss=0.08851, avg_loss=0.08465]
[2025-06-07 07:19:05.910]  Step 75187   [4.533 sec/step, loss=0.09207, avg_loss=0.08476]
[2025-06-07 07:19:12.344]  Step 75188   [4.555 sec/step, loss=0.09167, avg_loss=0.08481]
[2025-06-07 07:19:15.754]  Step 75189   [4.556 sec/step, loss=0.08458, avg_loss=0.08481]
[2025-06-07 07:19:19.588]  Step 75190   [4.580 sec/step, loss=0.08625, avg_loss=0.08495]
[2025-06-07 07:19:21.268]  Step 75191   [4.547 sec/step, loss=0.07762, avg_loss=0.08484]
[2025-06-07 07:19:36.027]  Step 75192   [4.663 sec/step, loss=0.08229, avg_loss=0.08481]
[2025-06-07 07:19:40.104]  Step 75193   [4.634 sec/step, loss=0.08561, avg_loss=0.08476]
[2025-06-07 07:19:42.497]  Step 75194   [4.628 sec/step, loss=0.08147, avg_loss=0.08473]
[2025-06-07 07:19:45.025]  Step 75195   [4.577 sec/step, loss=0.08284, avg_loss=0.08462]
[2025-06-07 07:19:51.615]  Step 75196   [4.582 sec/step, loss=0.09117, avg_loss=0.08463]
[2025-06-07 07:19:55.148]  Step 75197   [4.583 sec/step, loss=0.08453, avg_loss=0.08463]
[2025-06-07 07:19:56.774]  Step 75198   [4.567 sec/step, loss=0.07518, avg_loss=0.08453]
[2025-06-07 07:19:59.492]  Step 75199   [4.232 sec/step, loss=0.08259, avg_loss=0.08454]
[2025-06-07 07:20:05.100]  Step 75200   [4.210 sec/step, loss=0.08839, avg_loss=0.08450]
[2025-06-07 07:20:05.101]  Writing summary at step: 75200
[2025-06-07 07:20:12.187]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75200
[2025-06-07 07:20:13.064]  Saving audio and alignment...
[2025-06-07 07:20:16.351]  Input: amerikii abhinetrii r gaaykgiitkaar~__________
[2025-06-07 07:20:26.800]  Step 75201   [4.276 sec/step, loss=0.09079, avg_loss=0.08454]
[2025-06-07 07:20:32.681]  Step 75202   [4.314 sec/step, loss=0.08865, avg_loss=0.08462]
[2025-06-07 07:20:35.552]  Step 75203   [4.327 sec/step, loss=0.08398, avg_loss=0.08468]
[2025-06-07 07:20:41.734]  Step 75204   [4.361 sec/step, loss=0.09028, avg_loss=0.08474]
[2025-06-07 07:20:44.245]  Step 75205   [4.359 sec/step, loss=0.08341, avg_loss=0.08472]
[2025-06-07 07:20:45.679]  Step 75206   [4.351 sec/step, loss=0.07110, avg_loss=0.08462]
[2025-06-07 07:20:48.571]  Step 75207   [4.333 sec/step, loss=0.08351, avg_loss=0.08456]
[2025-06-07 07:20:50.810]  Step 75208   [4.307 sec/step, loss=0.08044, avg_loss=0.08448]
[2025-06-07 07:20:52.935]  Step 75209   [4.309 sec/step, loss=0.08152, avg_loss=0.08449]
[2025-06-07 07:20:57.543]  Generated 32 batches of size 32 in 4.251 sec
[2025-06-07 07:20:59.723]  Step 75210   [4.313 sec/step, loss=0.08820, avg_loss=0.08446]
[2025-06-07 07:21:04.762]  Step 75211   [4.322 sec/step, loss=0.08933, avg_loss=0.08447]
[2025-06-07 07:21:09.696]  Step 75212   [4.306 sec/step, loss=0.08904, avg_loss=0.08444]
[2025-06-07 07:21:14.207]  Step 75213   [4.297 sec/step, loss=0.08719, avg_loss=0.08441]
[2025-06-07 07:21:17.387]  Step 75214   [4.314 sec/step, loss=0.08424, avg_loss=0.08455]
[2025-06-07 07:21:19.243]  Step 75215   [4.287 sec/step, loss=0.07949, avg_loss=0.08446]
[2025-06-07 07:21:23.082]  Step 75216   [4.307 sec/step, loss=0.08390, avg_loss=0.08450]
[2025-06-07 07:21:26.213]  Step 75217   [4.317 sec/step, loss=0.08408, avg_loss=0.08456]
[2025-06-07 07:21:35.014]  Step 75218   [4.362 sec/step, loss=0.09184, avg_loss=0.08462]
[2025-06-07 07:21:40.369]  Step 75219   [4.389 sec/step, loss=0.08859, avg_loss=0.08468]
[2025-06-07 07:21:42.103]  Step 75220   [4.380 sec/step, loss=0.07725, avg_loss=0.08463]
[2025-06-07 07:21:47.134]  Step 75221   [4.391 sec/step, loss=0.08768, avg_loss=0.08464]
[2025-06-07 07:21:49.235]  Step 75222   [4.378 sec/step, loss=0.07898, avg_loss=0.08457]
[2025-06-07 07:21:52.392]  Step 75223   [4.395 sec/step, loss=0.08416, avg_loss=0.08466]
[2025-06-07 07:21:54.678]  Step 75224   [4.392 sec/step, loss=0.08123, avg_loss=0.08464]
[2025-06-07 07:21:59.805]  Step 75225   [4.414 sec/step, loss=0.08855, avg_loss=0.08467]
[2025-06-07 07:22:02.614]  Step 75226   [4.417 sec/step, loss=0.08472, avg_loss=0.08468]
[2025-06-07 07:22:08.557]  Step 75227   [4.438 sec/step, loss=0.08996, avg_loss=0.08472]
[2025-06-07 07:22:12.456]  Step 75228   [4.436 sec/step, loss=0.08533, avg_loss=0.08470]
[2025-06-07 07:22:18.461]  Step 75229   [4.479 sec/step, loss=0.09048, avg_loss=0.08483]
[2025-06-07 07:22:20.360]  Step 75230   [4.464 sec/step, loss=0.07793, avg_loss=0.08476]
[2025-06-07 07:22:24.956]  Step 75231   [4.477 sec/step, loss=0.08834, avg_loss=0.08479]
[2025-06-07 07:22:31.976]  Step 75232   [4.518 sec/step, loss=0.09159, avg_loss=0.08487]
[2025-06-07 07:22:38.702]  Step 75233   [4.511 sec/step, loss=0.09094, avg_loss=0.08486]
[2025-06-07 07:22:42.769]  Step 75234   [4.535 sec/step, loss=0.08715, avg_loss=0.08495]
[2025-06-07 07:22:51.405]  Step 75235   [4.598 sec/step, loss=0.09177, avg_loss=0.08504]
[2025-06-07 07:22:53.045]  Step 75236   [4.538 sec/step, loss=0.07686, avg_loss=0.08488]
[2025-06-07 07:22:56.551]  Step 75237   [4.540 sec/step, loss=0.08374, avg_loss=0.08487]
[2025-06-07 07:23:03.891]  Step 75238   [4.593 sec/step, loss=0.09338, avg_loss=0.08499]
[2025-06-07 07:23:06.690]  Step 75239   [4.566 sec/step, loss=0.08321, avg_loss=0.08492]
[2025-06-07 07:23:09.969]  Step 75240   [4.543 sec/step, loss=0.08642, avg_loss=0.08488]
[2025-06-07 07:23:13.614]  Step 75241   [4.487 sec/step, loss=0.08514, avg_loss=0.08482]
[2025-06-07 07:23:18.974]  Generated 32 batches of size 32 in 4.927 sec
[2025-06-07 07:23:52.147]  Step 75242   [4.840 sec/step, loss=0.08036, avg_loss=0.08478]
[2025-06-07 07:23:55.031]  Step 75243   [4.839 sec/step, loss=0.08225, avg_loss=0.08477]
[2025-06-07 07:23:58.164]  Step 75244   [4.822 sec/step, loss=0.08517, avg_loss=0.08474]
[2025-06-07 07:24:00.431]  Step 75245   [4.825 sec/step, loss=0.08064, avg_loss=0.08475]
[2025-06-07 07:24:02.047]  Step 75246   [4.798 sec/step, loss=0.06934, avg_loss=0.08456]
[2025-06-07 07:24:04.730]  Step 75247   [4.812 sec/step, loss=0.08125, avg_loss=0.08465]
[2025-06-07 07:24:08.123]  Step 75248   [4.820 sec/step, loss=0.08549, avg_loss=0.08466]
[2025-06-07 07:24:12.748]  Step 75249   [4.823 sec/step, loss=0.08598, avg_loss=0.08467]
[2025-06-07 07:24:16.689]  Step 75250   [4.809 sec/step, loss=0.08512, avg_loss=0.08464]
[2025-06-07 07:24:16.689]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75250
[2025-06-07 07:24:18.006]  Saving audio and alignment...
[2025-06-07 07:24:26.135]  Input: mnovijnyaan vyvhaariktaa raajkaajkaa siddhaanthruulaaii srl lvjmaa prstutikrnn ysko muul vishesstaa~_____________________________________
[2025-06-07 07:24:30.102]  Step 75251   [4.830 sec/step, loss=0.08526, avg_loss=0.08470]
[2025-06-07 07:24:31.981]  Step 75252   [4.578 sec/step, loss=0.07740, avg_loss=0.08467]
[2025-06-07 07:24:37.623]  Step 75253   [4.563 sec/step, loss=0.08862, avg_loss=0.08465]
[2025-06-07 07:24:40.334]  Step 75254   [4.543 sec/step, loss=0.08190, avg_loss=0.08459]
[2025-06-07 07:24:43.920]  Step 75255   [4.555 sec/step, loss=0.08439, avg_loss=0.08463]
[2025-06-07 07:24:50.024]  Step 75256   [4.586 sec/step, loss=0.09015, avg_loss=0.08467]
[2025-06-07 07:24:55.609]  Step 75257   [4.605 sec/step, loss=0.08873, avg_loss=0.08469]
[2025-06-07 07:25:00.539]  Step 75258   [4.617 sec/step, loss=0.08757, avg_loss=0.08472]
[2025-06-07 07:25:03.655]  Step 75259   [4.633 sec/step, loss=0.08315, avg_loss=0.08486]
[2025-06-07 07:25:06.113]  Step 75260   [4.638 sec/step, loss=0.08023, avg_loss=0.08486]
[2025-06-07 07:25:10.656]  Step 75261   [4.659 sec/step, loss=0.08729, avg_loss=0.08493]
[2025-06-07 07:25:14.759]  Step 75262   [4.640 sec/step, loss=0.08710, avg_loss=0.08490]
[2025-06-07 07:25:21.223]  Step 75263   [4.666 sec/step, loss=0.09029, avg_loss=0.08494]
[2025-06-07 07:25:29.338]  Step 75264   [4.703 sec/step, loss=0.09261, avg_loss=0.08499]
[2025-06-07 07:25:32.666]  Step 75265   [4.680 sec/step, loss=0.08431, avg_loss=0.08493]
[2025-06-07 07:25:35.915]  Step 75266   [4.692 sec/step, loss=0.08396, avg_loss=0.08497]
[2025-06-07 07:25:40.990]  Step 75267   [4.530 sec/step, loss=0.08854, avg_loss=0.08503]
[2025-06-07 07:25:47.897]  Step 75268   [4.558 sec/step, loss=0.09221, avg_loss=0.08508]
[2025-06-07 07:25:51.774]  Step 75269   [4.545 sec/step, loss=0.08588, avg_loss=0.08504]
[2025-06-07 07:25:55.192]  Step 75270   [4.513 sec/step, loss=0.08545, avg_loss=0.08497]
[2025-06-07 07:25:56.879]  Step 75271   [4.498 sec/step, loss=0.07580, avg_loss=0.08489]
[2025-06-07 07:25:58.863]  Step 75272   [4.491 sec/step, loss=0.07809, avg_loss=0.08483]
[2025-06-07 07:26:01.224]  Step 75273   [4.464 sec/step, loss=0.08071, avg_loss=0.08475]
[2025-06-07 07:26:03.346]  Generated 32 batches of size 32 in 4.142 sec
[2025-06-07 07:26:05.839]  Step 75274   [4.477 sec/step, loss=0.08735, avg_loss=0.08478]
[2025-06-07 07:26:15.235]  Step 75275   [4.548 sec/step, loss=0.09208, avg_loss=0.08487]
[2025-06-07 07:26:17.303]  Step 75276   [4.549 sec/step, loss=0.08140, avg_loss=0.08488]
[2025-06-07 07:26:32.432]  Step 75277   [4.674 sec/step, loss=0.08205, avg_loss=0.08486]
[2025-06-07 07:26:35.123]  Step 75278   [4.677 sec/step, loss=0.08164, avg_loss=0.08484]
[2025-06-07 07:26:38.138]  Step 75279   [4.691 sec/step, loss=0.08379, avg_loss=0.08490]
[2025-06-07 07:26:40.847]  Step 75280   [4.663 sec/step, loss=0.08356, avg_loss=0.08486]
[2025-06-07 07:26:42.393]  Step 75281   [4.663 sec/step, loss=0.06965, avg_loss=0.08479]
[2025-06-07 07:26:44.259]  Step 75282   [4.651 sec/step, loss=0.07840, avg_loss=0.08472]
[2025-06-07 07:26:48.033]  Step 75283   [4.658 sec/step, loss=0.08496, avg_loss=0.08474]
[2025-06-07 07:26:50.357]  Step 75284   [4.588 sec/step, loss=0.08004, avg_loss=0.08461]
[2025-06-07 07:26:52.077]  Step 75285   [4.580 sec/step, loss=0.07645, avg_loss=0.08456]
[2025-06-07 07:26:56.972]  Step 75286   [4.579 sec/step, loss=0.08887, avg_loss=0.08456]
[2025-06-07 07:27:02.003]  Step 75287   [4.553 sec/step, loss=0.08872, avg_loss=0.08453]
[2025-06-07 07:27:08.949]  Step 75288   [4.558 sec/step, loss=0.08989, avg_loss=0.08451]
[2025-06-07 07:27:10.546]  Step 75289   [4.540 sec/step, loss=0.07690, avg_loss=0.08443]
[2025-06-07 07:27:13.200]  Step 75290   [4.528 sec/step, loss=0.08338, avg_loss=0.08440]
[2025-06-07 07:27:19.511]  Step 75291   [4.574 sec/step, loss=0.09101, avg_loss=0.08454]
[2025-06-07 07:27:22.615]  Step 75292   [4.458 sec/step, loss=0.08367, avg_loss=0.08455]
[2025-06-07 07:27:27.506]  Step 75293   [4.466 sec/step, loss=0.08792, avg_loss=0.08458]
[2025-06-07 07:27:31.662]  Step 75294   [4.484 sec/step, loss=0.08689, avg_loss=0.08463]
[2025-06-07 07:27:37.193]  Step 75295   [4.514 sec/step, loss=0.08924, avg_loss=0.08469]
[2025-06-07 07:27:42.675]  Step 75296   [4.503 sec/step, loss=0.08838, avg_loss=0.08467]
[2025-06-07 07:27:48.723]  Step 75297   [4.528 sec/step, loss=0.08965, avg_loss=0.08472]
[2025-06-07 07:27:56.767]  Step 75298   [4.592 sec/step, loss=0.09307, avg_loss=0.08490]
[2025-06-07 07:27:58.883]  Step 75299   [4.586 sec/step, loss=0.08116, avg_loss=0.08488]
[2025-06-07 07:28:00.840]  Step 75300   [4.549 sec/step, loss=0.07911, avg_loss=0.08479]
[2025-06-07 07:28:00.842]  Writing summary at step: 75300
[2025-06-07 07:28:23.026]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75300
[2025-06-07 07:28:24.160]  Saving audio and alignment...
[2025-06-07 07:28:29.233]  Input: ddelttaa eyr laains inkle hvaai kssetrmaa aaphno naam ythaavt raakheko ch~___________
[2025-06-07 07:28:30.880]  Step 75301   [4.462 sec/step, loss=0.07033, avg_loss=0.08458]
[2025-06-07 07:28:33.500]  Step 75302   [4.429 sec/step, loss=0.08173, avg_loss=0.08451]
[2025-06-07 07:28:38.404]  Generated 32 batches of size 32 in 4.478 sec
[2025-06-07 07:28:45.360]  Step 75303   [4.519 sec/step, loss=0.09136, avg_loss=0.08459]
[2025-06-07 07:28:48.994]  Step 75304   [4.493 sec/step, loss=0.08415, avg_loss=0.08453]
[2025-06-07 07:28:52.332]  Step 75305   [4.502 sec/step, loss=0.08282, avg_loss=0.08452]
[2025-06-07 07:28:55.040]  Step 75306   [4.514 sec/step, loss=0.08275, avg_loss=0.08464]
[2025-06-07 07:28:57.468]  Step 75307   [4.510 sec/step, loss=0.08139, avg_loss=0.08462]
[2025-06-07 07:29:01.208]  Step 75308   [4.525 sec/step, loss=0.08504, avg_loss=0.08466]
[2025-06-07 07:29:04.508]  Step 75309   [4.536 sec/step, loss=0.08478, avg_loss=0.08470]
[2025-06-07 07:29:08.875]  Step 75310   [4.512 sec/step, loss=0.08609, avg_loss=0.08467]
[2025-06-07 07:29:11.773]  Step 75311   [4.491 sec/step, loss=0.08366, avg_loss=0.08462]
[2025-06-07 07:29:14.017]  Step 75312   [4.464 sec/step, loss=0.07975, avg_loss=0.08452]
[2025-06-07 07:29:16.112]  Step 75313   [4.440 sec/step, loss=0.07959, avg_loss=0.08445]
[2025-06-07 07:29:20.683]  Step 75314   [4.454 sec/step, loss=0.08784, avg_loss=0.08448]
[2025-06-07 07:29:23.020]  Step 75315   [4.459 sec/step, loss=0.08058, avg_loss=0.08450]
[2025-06-07 07:29:29.682]  Step 75316   [4.487 sec/step, loss=0.08984, avg_loss=0.08455]
[2025-06-07 07:29:34.946]  Step 75317   [4.508 sec/step, loss=0.08840, avg_loss=0.08460]
[2025-06-07 07:29:37.639]  Step 75318   [4.447 sec/step, loss=0.08161, avg_loss=0.08450]
[2025-06-07 07:29:44.313]  Step 75319   [4.460 sec/step, loss=0.09099, avg_loss=0.08452]
[2025-06-07 07:29:47.792]  Step 75320   [4.478 sec/step, loss=0.08378, avg_loss=0.08458]
[2025-06-07 07:29:52.099]  Step 75321   [4.470 sec/step, loss=0.08535, avg_loss=0.08456]
[2025-06-07 07:30:28.482]  Step 75322   [4.813 sec/step, loss=0.08236, avg_loss=0.08460]
[2025-06-07 07:30:32.445]  Step 75323   [4.821 sec/step, loss=0.08517, avg_loss=0.08461]
[2025-06-07 07:30:35.211]  Step 75324   [4.826 sec/step, loss=0.08376, avg_loss=0.08463]
[2025-06-07 07:30:41.431]  Step 75325   [4.837 sec/step, loss=0.09022, avg_loss=0.08465]
[2025-06-07 07:30:46.441]  Step 75326   [4.859 sec/step, loss=0.08868, avg_loss=0.08469]
[2025-06-07 07:30:49.027]  Step 75327   [4.825 sec/step, loss=0.08069, avg_loss=0.08459]
[2025-06-07 07:30:52.208]  Step 75328   [4.818 sec/step, loss=0.08367, avg_loss=0.08458]
[2025-06-07 07:30:56.254]  Step 75329   [4.799 sec/step, loss=0.08478, avg_loss=0.08452]
[2025-06-07 07:31:04.556]  Step 75330   [4.863 sec/step, loss=0.09255, avg_loss=0.08467]
[2025-06-07 07:31:10.050]  Step 75331   [4.872 sec/step, loss=0.08796, avg_loss=0.08466]
[2025-06-07 07:31:19.563]  Step 75332   [4.897 sec/step, loss=0.09199, avg_loss=0.08467]
[2025-06-07 07:31:23.170]  Step 75333   [4.865 sec/step, loss=0.08529, avg_loss=0.08461]
[2025-06-07 07:31:26.331]  Step 75334   [4.856 sec/step, loss=0.08330, avg_loss=0.08457]
[2025-06-07 07:31:29.695]  Step 75335   [4.804 sec/step, loss=0.08227, avg_loss=0.08448]
[2025-06-07 07:31:30.942]  Generated 32 batches of size 32 in 4.235 sec
[2025-06-07 07:31:37.100]  Step 75336   [4.861 sec/step, loss=0.09185, avg_loss=0.08463]
[2025-06-07 07:31:38.848]  Step 75337   [4.844 sec/step, loss=0.07746, avg_loss=0.08456]
[2025-06-07 07:31:42.052]  Step 75338   [4.802 sec/step, loss=0.08477, avg_loss=0.08448]
[2025-06-07 07:31:44.355]  Step 75339   [4.797 sec/step, loss=0.08077, avg_loss=0.08445]
[2025-06-07 07:31:48.168]  Step 75340   [4.803 sec/step, loss=0.08632, avg_loss=0.08445]
[2025-06-07 07:31:53.008]  Step 75341   [4.815 sec/step, loss=0.08862, avg_loss=0.08449]
[2025-06-07 07:31:54.577]  Step 75342   [4.445 sec/step, loss=0.07593, avg_loss=0.08444]
[2025-06-07 07:31:56.040]  Step 75343   [4.431 sec/step, loss=0.06882, avg_loss=0.08431]
[2025-06-07 07:31:59.997]  Step 75344   [4.439 sec/step, loss=0.08620, avg_loss=0.08432]
[2025-06-07 07:32:02.167]  Step 75345   [4.438 sec/step, loss=0.07856, avg_loss=0.08430]
[2025-06-07 07:32:05.452]  Step 75346   [4.455 sec/step, loss=0.08530, avg_loss=0.08446]
[2025-06-07 07:32:08.563]  Step 75347   [4.459 sec/step, loss=0.08350, avg_loss=0.08448]
[2025-06-07 07:32:10.615]  Step 75348   [4.446 sec/step, loss=0.08073, avg_loss=0.08443]
[2025-06-07 07:32:14.920]  Step 75349   [4.443 sec/step, loss=0.08681, avg_loss=0.08444]
[2025-06-07 07:32:17.806]  Step 75350   [4.432 sec/step, loss=0.08284, avg_loss=0.08442]
[2025-06-07 07:32:17.806]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75350
[2025-06-07 07:32:18.885]  Saving audio and alignment...
[2025-06-07 07:32:23.180]  Input: ysko paaniiko kaarnn duvai raajyhruumaa vivaad~__________
[2025-06-07 07:32:26.622]  Step 75351   [4.427 sec/step, loss=0.08579, avg_loss=0.08442]
[2025-06-07 07:32:33.751]  Step 75352   [4.479 sec/step, loss=0.08967, avg_loss=0.08455]
[2025-06-07 07:32:35.348]  Step 75353   [4.439 sec/step, loss=0.07694, avg_loss=0.08443]
[2025-06-07 07:32:37.191]  Step 75354   [4.430 sec/step, loss=0.07885, avg_loss=0.08440]
[2025-06-07 07:32:41.785]  Step 75355   [4.440 sec/step, loss=0.08822, avg_loss=0.08444]
[2025-06-07 07:32:44.355]  Step 75356   [4.405 sec/step, loss=0.08075, avg_loss=0.08434]
[2025-06-07 07:32:47.724]  Step 75357   [4.383 sec/step, loss=0.08374, avg_loss=0.08429]
[2025-06-07 07:32:55.749]  Step 75358   [4.414 sec/step, loss=0.09155, avg_loss=0.08433]
[2025-06-07 07:33:00.819]  Step 75359   [4.433 sec/step, loss=0.08923, avg_loss=0.08439]
[2025-06-07 07:33:05.646]  Step 75360   [4.457 sec/step, loss=0.08780, avg_loss=0.08447]
[2025-06-07 07:33:08.239]  Step 75361   [4.437 sec/step, loss=0.08285, avg_loss=0.08443]
[2025-06-07 07:33:12.352]  Step 75362   [4.437 sec/step, loss=0.08742, avg_loss=0.08443]
[2025-06-07 07:33:17.930]  Step 75363   [4.429 sec/step, loss=0.08971, avg_loss=0.08442]
[2025-06-07 07:33:25.337]  Step 75364   [4.421 sec/step, loss=0.09205, avg_loss=0.08442]
[2025-06-07 07:33:27.668]  Step 75365   [4.411 sec/step, loss=0.08086, avg_loss=0.08438]
[2025-06-07 07:33:31.282]  Step 75366   [4.415 sec/step, loss=0.08292, avg_loss=0.08437]
[2025-06-07 07:33:32.006]  Generated 32 batches of size 32 in 3.979 sec
[2025-06-07 07:33:35.038]  Step 75367   [4.402 sec/step, loss=0.08443, avg_loss=0.08433]
[2025-06-07 07:33:38.965]  Step 75368   [4.372 sec/step, loss=0.08507, avg_loss=0.08426]
[2025-06-07 07:33:40.713]  Step 75369   [4.351 sec/step, loss=0.07552, avg_loss=0.08416]
[2025-06-07 07:33:46.120]  Step 75370   [4.371 sec/step, loss=0.08809, avg_loss=0.08418]
[2025-06-07 07:34:08.029]  Step 75371   [4.573 sec/step, loss=0.08694, avg_loss=0.08429]
[2025-06-07 07:34:09.548]  Step 75372   [4.568 sec/step, loss=0.07162, avg_loss=0.08423]
[2025-06-07 07:34:15.959]  Step 75373   [4.609 sec/step, loss=0.09156, avg_loss=0.08434]
[2025-06-07 07:34:24.368]  Step 75374   [4.647 sec/step, loss=0.09077, avg_loss=0.08437]
[2025-06-07 07:34:28.413]  Step 75375   [4.593 sec/step, loss=0.08653, avg_loss=0.08432]
[2025-06-07 07:34:33.444]  Step 75376   [4.623 sec/step, loss=0.08894, avg_loss=0.08439]
[2025-06-07 07:34:37.298]  Step 75377   [4.510 sec/step, loss=0.08549, avg_loss=0.08443]
[2025-06-07 07:34:38.746]  Step 75378   [4.498 sec/step, loss=0.07177, avg_loss=0.08433]
[2025-06-07 07:34:47.462]  Step 75379   [4.555 sec/step, loss=0.09089, avg_loss=0.08440]
[2025-06-07 07:34:50.863]  Step 75380   [4.562 sec/step, loss=0.08473, avg_loss=0.08441]
[2025-06-07 07:34:53.357]  Step 75381   [4.571 sec/step, loss=0.08131, avg_loss=0.08453]
[2025-06-07 07:34:59.503]  Step 75382   [4.614 sec/step, loss=0.09054, avg_loss=0.08465]
[2025-06-07 07:35:04.393]  Step 75383   [4.625 sec/step, loss=0.08795, avg_loss=0.08468]
[2025-06-07 07:35:07.340]  Step 75384   [4.631 sec/step, loss=0.08401, avg_loss=0.08472]
[2025-06-07 07:35:09.004]  Step 75385   [4.631 sec/step, loss=0.07756, avg_loss=0.08473]
[2025-06-07 07:35:12.393]  Step 75386   [4.616 sec/step, loss=0.08389, avg_loss=0.08468]
[2025-06-07 07:35:15.490]  Step 75387   [4.596 sec/step, loss=0.08313, avg_loss=0.08462]
[2025-06-07 07:35:28.253]  Step 75388   [4.655 sec/step, loss=0.08571, avg_loss=0.08458]
[2025-06-07 07:35:31.822]  Step 75389   [4.674 sec/step, loss=0.08632, avg_loss=0.08468]
[2025-06-07 07:35:36.441]  Step 75390   [4.694 sec/step, loss=0.08729, avg_loss=0.08472]
[2025-06-07 07:35:42.712]  Step 75391   [4.693 sec/step, loss=0.08957, avg_loss=0.08470]
[2025-06-07 07:35:48.148]  Step 75392   [4.717 sec/step, loss=0.08786, avg_loss=0.08474]
[2025-06-07 07:35:53.894]  Step 75393   [4.725 sec/step, loss=0.09028, avg_loss=0.08477]
[2025-06-07 07:35:58.024]  Step 75394   [4.725 sec/step, loss=0.08785, avg_loss=0.08478]
[2025-06-07 07:36:04.993]  Step 75395   [4.739 sec/step, loss=0.09043, avg_loss=0.08479]
[2025-06-07 07:36:07.660]  Step 75396   [4.711 sec/step, loss=0.08370, avg_loss=0.08474]
[2025-06-07 07:36:11.649]  Step 75397   [4.691 sec/step, loss=0.08563, avg_loss=0.08470]
[2025-06-07 07:36:14.445]  Step 75398   [4.638 sec/step, loss=0.08044, avg_loss=0.08457]
[2025-06-07 07:36:16.068]  Generated 32 batches of size 32 in 4.091 sec
[2025-06-07 07:36:17.726]  Step 75399   [4.650 sec/step, loss=0.08272, avg_loss=0.08459]
[2025-06-07 07:36:19.276]  Step 75400   [4.646 sec/step, loss=0.07587, avg_loss=0.08456]
[2025-06-07 07:36:19.277]  Writing summary at step: 75400
[2025-06-07 07:36:21.162]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75400
[2025-06-07 07:36:22.227]  Saving audio and alignment...
[2025-06-07 07:36:26.239]  Input: yuttisiiko caar sy tiis pttk aphsett suck~______________
[2025-06-07 07:36:28.354]  Step 75401   [4.651 sec/step, loss=0.07923, avg_loss=0.08465]
[2025-06-07 07:36:31.518]  Step 75402   [4.656 sec/step, loss=0.08585, avg_loss=0.08469]
[2025-06-07 07:36:33.649]  Step 75403   [4.559 sec/step, loss=0.08010, avg_loss=0.08458]
[2025-06-07 07:36:42.998]  Step 75404   [4.616 sec/step, loss=0.09196, avg_loss=0.08465]
[2025-06-07 07:36:44.812]  Step 75405   [4.601 sec/step, loss=0.07534, avg_loss=0.08458]
[2025-06-07 07:36:46.770]  Step 75406   [4.593 sec/step, loss=0.07908, avg_loss=0.08454]
[2025-06-07 07:36:49.376]  Step 75407   [4.595 sec/step, loss=0.08095, avg_loss=0.08454]
[2025-06-07 07:36:52.102]  Step 75408   [4.585 sec/step, loss=0.08321, avg_loss=0.08452]
[2025-06-07 07:36:54.240]  Step 75409   [4.573 sec/step, loss=0.08121, avg_loss=0.08448]
[2025-06-07 07:36:56.346]  Step 75410   [4.550 sec/step, loss=0.07984, avg_loss=0.08442]
[2025-06-07 07:37:02.046]  Step 75411   [4.578 sec/step, loss=0.08887, avg_loss=0.08447]
[2025-06-07 07:37:05.411]  Step 75412   [4.590 sec/step, loss=0.08426, avg_loss=0.08452]
[2025-06-07 07:37:09.344]  Step 75413   [4.608 sec/step, loss=0.08663, avg_loss=0.08459]
[2025-06-07 07:37:12.370]  Step 75414   [4.593 sec/step, loss=0.08425, avg_loss=0.08455]
[2025-06-07 07:37:28.097]  Step 75415   [4.726 sec/step, loss=0.08107, avg_loss=0.08456]
[2025-06-07 07:37:31.657]  Step 75416   [4.695 sec/step, loss=0.08546, avg_loss=0.08451]
[2025-06-07 07:37:36.855]  Step 75417   [4.695 sec/step, loss=0.08931, avg_loss=0.08452]
[2025-06-07 07:37:38.686]  Step 75418   [4.686 sec/step, loss=0.07656, avg_loss=0.08447]
[2025-06-07 07:37:41.798]  Step 75419   [4.650 sec/step, loss=0.08328, avg_loss=0.08440]
[2025-06-07 07:37:44.405]  Step 75420   [4.642 sec/step, loss=0.08330, avg_loss=0.08439]
[2025-06-07 07:37:46.888]  Step 75421   [4.623 sec/step, loss=0.08232, avg_loss=0.08436]
[2025-06-07 07:37:51.236]  Step 75422   [4.303 sec/step, loss=0.08658, avg_loss=0.08440]
[2025-06-07 07:37:55.827]  Step 75423   [4.310 sec/step, loss=0.08803, avg_loss=0.08443]
[2025-06-07 07:38:18.194]  Step 75424   [4.506 sec/step, loss=0.08716, avg_loss=0.08446]
[2025-06-07 07:38:22.418]  Step 75425   [4.486 sec/step, loss=0.08158, avg_loss=0.08438]
[2025-06-07 07:38:29.403]  Step 75426   [4.505 sec/step, loss=0.08579, avg_loss=0.08435]
[2025-06-07 07:38:41.909]  Step 75427   [4.604 sec/step, loss=0.09210, avg_loss=0.08446]
[2025-06-07 07:38:47.526]  Generated 32 batches of size 32 in 5.067 sec
[2025-06-07 07:38:47.776]  Step 75428   [4.631 sec/step, loss=0.08431, avg_loss=0.08447]
[2025-06-07 07:38:53.611]  Step 75429   [4.649 sec/step, loss=0.08358, avg_loss=0.08446]
[2025-06-07 07:38:55.858]  Step 75430   [4.589 sec/step, loss=0.06930, avg_loss=0.08423]
[2025-06-07 07:39:06.421]  Step 75431   [4.639 sec/step, loss=0.09203, avg_loss=0.08427]
[2025-06-07 07:39:16.393]  Step 75432   [4.644 sec/step, loss=0.09214, avg_loss=0.08427]
[2025-06-07 07:39:23.748]  Step 75433   [4.681 sec/step, loss=0.08848, avg_loss=0.08430]
[2025-06-07 07:39:31.923]  Step 75434   [4.731 sec/step, loss=0.09015, avg_loss=0.08437]
[2025-06-07 07:39:35.754]  Step 75435   [4.736 sec/step, loss=0.08447, avg_loss=0.08439]
[2025-06-07 07:39:48.483]  Step 75436   [4.789 sec/step, loss=0.09141, avg_loss=0.08439]
[2025-06-07 07:39:52.359]  Step 75437   [4.810 sec/step, loss=0.08469, avg_loss=0.08446]
[2025-06-07 07:39:53.889]  Step 75438   [4.794 sec/step, loss=0.06983, avg_loss=0.08431]
[2025-06-07 07:39:58.418]  Step 75439   [4.816 sec/step, loss=0.08741, avg_loss=0.08438]
[2025-06-07 07:40:03.621]  Step 75440   [4.830 sec/step, loss=0.08901, avg_loss=0.08440]
[2025-06-07 07:40:05.785]  Step 75441   [4.803 sec/step, loss=0.08011, avg_loss=0.08432]
[2025-06-07 07:40:11.205]  Step 75442   [4.842 sec/step, loss=0.08792, avg_loss=0.08444]
[2025-06-07 07:40:15.280]  Step 75443   [4.868 sec/step, loss=0.08682, avg_loss=0.08462]
[2025-06-07 07:40:21.888]  Step 75444   [4.894 sec/step, loss=0.08945, avg_loss=0.08465]
[2025-06-07 07:40:39.134]  Step 75445   [5.045 sec/step, loss=0.08062, avg_loss=0.08467]
[2025-06-07 07:40:46.130]  Step 75446   [5.082 sec/step, loss=0.09101, avg_loss=0.08473]
[2025-06-07 07:40:49.360]  Step 75447   [5.083 sec/step, loss=0.08476, avg_loss=0.08474]
[2025-06-07 07:40:54.920]  Step 75448   [5.118 sec/step, loss=0.08906, avg_loss=0.08482]
[2025-06-07 07:40:58.592]  Step 75449   [5.112 sec/step, loss=0.08472, avg_loss=0.08480]
[2025-06-07 07:41:00.320]  Step 75450   [5.100 sec/step, loss=0.07580, avg_loss=0.08473]
[2025-06-07 07:41:00.320]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75450
[2025-06-07 07:41:01.368]  Saving audio and alignment...
[2025-06-07 07:41:05.371]  Input: kaaliignnddkii ptrikaa euttaa nepaalii bhaassaako ptrikaa ho~_
[2025-06-07 07:41:08.119]  Step 75451   [5.093 sec/step, loss=0.08202, avg_loss=0.08469]
[2025-06-07 07:41:15.911]  Step 75452   [5.100 sec/step, loss=0.09200, avg_loss=0.08472]
[2025-06-07 07:41:24.697]  Step 75453   [5.172 sec/step, loss=0.08976, avg_loss=0.08485]
[2025-06-07 07:41:28.007]  Step 75454   [5.187 sec/step, loss=0.08457, avg_loss=0.08490]
[2025-06-07 07:41:29.995]  Step 75455   [5.160 sec/step, loss=0.07901, avg_loss=0.08481]
[2025-06-07 07:41:33.062]  Step 75456   [5.165 sec/step, loss=0.08469, avg_loss=0.08485]
[2025-06-07 07:41:38.963]  Step 75457   [5.191 sec/step, loss=0.09086, avg_loss=0.08492]
[2025-06-07 07:41:41.133]  Step 75458   [5.132 sec/step, loss=0.07858, avg_loss=0.08479]
[2025-06-07 07:41:45.724]  Generated 32 batches of size 32 in 4.156 sec
[2025-06-07 07:41:47.454]  Step 75459   [5.145 sec/step, loss=0.08777, avg_loss=0.08478]
[2025-06-07 07:41:49.401]  Step 75460   [5.116 sec/step, loss=0.07737, avg_loss=0.08467]
[2025-06-07 07:41:52.385]  Step 75461   [5.120 sec/step, loss=0.08491, avg_loss=0.08469]
[2025-06-07 07:41:56.311]  Step 75462   [5.118 sec/step, loss=0.08419, avg_loss=0.08466]
[2025-06-07 07:41:59.553]  Step 75463   [5.095 sec/step, loss=0.08397, avg_loss=0.08460]
[2025-06-07 07:42:03.881]  Step 75464   [5.064 sec/step, loss=0.08721, avg_loss=0.08456]
[2025-06-07 07:42:06.605]  Step 75465   [5.068 sec/step, loss=0.08318, avg_loss=0.08458]
[2025-06-07 07:42:08.580]  Step 75466   [5.051 sec/step, loss=0.08088, avg_loss=0.08456]
[2025-06-07 07:42:10.951]  Step 75467   [5.038 sec/step, loss=0.08063, avg_loss=0.08452]
[2025-06-07 07:42:16.207]  Step 75468   [5.051 sec/step, loss=0.08871, avg_loss=0.08456]
[2025-06-07 07:42:31.832]  Step 75469   [5.189 sec/step, loss=0.09155, avg_loss=0.08472]
[2025-06-07 07:42:34.673]  Step 75470   [5.164 sec/step, loss=0.08443, avg_loss=0.08468]
[2025-06-07 07:42:38.444]  Step 75471   [4.982 sec/step, loss=0.08441, avg_loss=0.08465]
[2025-06-07 07:42:52.473]  Step 75472   [5.108 sec/step, loss=0.08347, avg_loss=0.08477]
[2025-06-07 07:42:58.623]  Step 75473   [5.105 sec/step, loss=0.08977, avg_loss=0.08476]
[2025-06-07 07:43:01.749]  Step 75474   [5.052 sec/step, loss=0.08268, avg_loss=0.08467]
[2025-06-07 07:43:04.431]  Step 75475   [5.039 sec/step, loss=0.08292, avg_loss=0.08464]
[2025-06-07 07:43:07.773]  Step 75476   [5.022 sec/step, loss=0.08568, avg_loss=0.08461]
[2025-06-07 07:43:09.807]  Step 75477   [5.003 sec/step, loss=0.07865, avg_loss=0.08454]
[2025-06-07 07:43:15.582]  Step 75478   [5.047 sec/step, loss=0.08949, avg_loss=0.08471]
[2025-06-07 07:43:17.493]  Step 75479   [4.979 sec/step, loss=0.07685, avg_loss=0.08457]
[2025-06-07 07:43:19.764]  Step 75480   [4.967 sec/step, loss=0.07882, avg_loss=0.08452]
[2025-06-07 07:43:21.521]  Step 75481   [4.960 sec/step, loss=0.07585, avg_loss=0.08446]
[2025-06-07 07:43:23.778]  Step 75482   [4.921 sec/step, loss=0.08063, avg_loss=0.08436]
[2025-06-07 07:43:28.268]  Step 75483   [4.917 sec/step, loss=0.08638, avg_loss=0.08435]
[2025-06-07 07:43:32.308]  Step 75484   [4.928 sec/step, loss=0.08582, avg_loss=0.08436]
[2025-06-07 07:43:35.425]  Step 75485   [4.943 sec/step, loss=0.08383, avg_loss=0.08443]
[2025-06-07 07:43:39.866]  Step 75486   [4.953 sec/step, loss=0.08735, avg_loss=0.08446]
[2025-06-07 07:43:42.606]  Step 75487   [4.950 sec/step, loss=0.08422, avg_loss=0.08447]
[2025-06-07 07:43:49.396]  Step 75488   [4.890 sec/step, loss=0.09241, avg_loss=0.08454]
[2025-06-07 07:43:55.100]  Step 75489   [4.911 sec/step, loss=0.08931, avg_loss=0.08457]
[2025-06-07 07:43:58.685]  Step 75490   [4.901 sec/step, loss=0.08643, avg_loss=0.08456]
[2025-06-07 07:44:03.176]  Generated 32 batches of size 32 in 4.068 sec
[2025-06-07 07:44:04.488]  Step 75491   [4.896 sec/step, loss=0.08812, avg_loss=0.08455]
[2025-06-07 07:44:07.762]  Step 75492   [4.875 sec/step, loss=0.08329, avg_loss=0.08450]
[2025-06-07 07:44:10.157]  Step 75493   [4.841 sec/step, loss=0.08072, avg_loss=0.08440]
[2025-06-07 07:44:18.433]  Step 75494   [4.883 sec/step, loss=0.09082, avg_loss=0.08443]
[2025-06-07 07:44:23.154]  Step 75495   [4.860 sec/step, loss=0.08748, avg_loss=0.08440]
[2025-06-07 07:44:24.772]  Step 75496   [4.850 sec/step, loss=0.06982, avg_loss=0.08427]
[2025-06-07 07:44:28.267]  Step 75497   [4.845 sec/step, loss=0.08456, avg_loss=0.08426]
[2025-06-07 07:44:37.111]  Step 75498   [4.905 sec/step, loss=0.09251, avg_loss=0.08438]
[2025-06-07 07:44:43.817]  Step 75499   [4.939 sec/step, loss=0.08981, avg_loss=0.08445]
[2025-06-07 07:44:47.698]  Step 75500   [4.963 sec/step, loss=0.08565, avg_loss=0.08454]
[2025-06-07 07:44:47.699]  Writing summary at step: 75500
[2025-06-07 07:44:52.446]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75500
[2025-06-07 07:44:53.501]  Saving audio and alignment...
[2025-06-07 07:45:00.041]  Input: pnycknyaa shhiidsmrti paark dhnkuttaa jillaamaa avsthit euttaa smrti paark~________________________________
[2025-06-07 07:45:02.795]  Step 75501   [4.969 sec/step, loss=0.08185, avg_loss=0.08457]
[2025-06-07 07:45:05.217]  Step 75502   [4.962 sec/step, loss=0.08104, avg_loss=0.08452]
[2025-06-07 07:45:07.493]  Step 75503   [4.963 sec/step, loss=0.07910, avg_loss=0.08451]
[2025-06-07 07:45:09.054]  Step 75504   [4.885 sec/step, loss=0.07202, avg_loss=0.08431]
[2025-06-07 07:45:12.213]  Step 75505   [4.899 sec/step, loss=0.08226, avg_loss=0.08438]
[2025-06-07 07:45:19.207]  Step 75506   [4.949 sec/step, loss=0.08990, avg_loss=0.08449]
[2025-06-07 07:45:20.990]  Step 75507   [4.941 sec/step, loss=0.07474, avg_loss=0.08443]
[2025-06-07 07:45:24.958]  Step 75508   [4.953 sec/step, loss=0.08593, avg_loss=0.08446]
[2025-06-07 07:45:26.960]  Step 75509   [4.952 sec/step, loss=0.07970, avg_loss=0.08444]
[2025-06-07 07:45:32.572]  Step 75510   [4.987 sec/step, loss=0.08842, avg_loss=0.08453]
[2025-06-07 07:45:41.680]  Step 75511   [5.021 sec/step, loss=0.09208, avg_loss=0.08456]
[2025-06-07 07:45:45.355]  Step 75512   [5.024 sec/step, loss=0.08500, avg_loss=0.08457]
[2025-06-07 07:45:48.020]  Step 75513   [5.011 sec/step, loss=0.08099, avg_loss=0.08451]
[2025-06-07 07:45:54.406]  Step 75514   [5.045 sec/step, loss=0.08954, avg_loss=0.08456]
[2025-06-07 07:45:56.464]  Step 75515   [4.908 sec/step, loss=0.08086, avg_loss=0.08456]
[2025-06-07 07:46:04.056]  Step 75516   [4.949 sec/step, loss=0.09130, avg_loss=0.08462]
[2025-06-07 07:46:07.605]  Step 75517   [4.932 sec/step, loss=0.08397, avg_loss=0.08457]
[2025-06-07 07:46:14.296]  Step 75518   [4.981 sec/step, loss=0.09176, avg_loss=0.08472]
[2025-06-07 07:46:17.416]  Step 75519   [4.981 sec/step, loss=0.08360, avg_loss=0.08472]
[2025-06-07 07:46:22.469]  Step 75520   [5.005 sec/step, loss=0.08862, avg_loss=0.08477]
[2025-06-07 07:46:26.907]  Generated 32 batches of size 32 in 4.064 sec
[2025-06-07 07:46:29.249]  Step 75521   [5.048 sec/step, loss=0.08877, avg_loss=0.08484]
[2025-06-07 07:46:33.664]  Step 75522   [5.049 sec/step, loss=0.08737, avg_loss=0.08485]
[2025-06-07 07:46:35.542]  Step 75523   [5.022 sec/step, loss=0.07734, avg_loss=0.08474]
[2025-06-07 07:46:39.927]  Step 75524   [4.842 sec/step, loss=0.08671, avg_loss=0.08473]
[2025-06-07 07:46:43.377]  Step 75525   [4.834 sec/step, loss=0.08352, avg_loss=0.08475]
[2025-06-07 07:46:53.062]  Step 75526   [4.861 sec/step, loss=0.09292, avg_loss=0.08483]
[2025-06-07 07:46:55.845]  Step 75527   [4.764 sec/step, loss=0.08292, avg_loss=0.08473]
[2025-06-07 07:47:11.926]  Step 75528   [4.866 sec/step, loss=0.08112, avg_loss=0.08470]
[2025-06-07 07:47:15.373]  Step 75529   [4.842 sec/step, loss=0.08396, avg_loss=0.08471]
[2025-06-07 07:47:18.091]  Step 75530   [4.847 sec/step, loss=0.08394, avg_loss=0.08485]
[2025-06-07 07:47:20.477]  Step 75531   [4.765 sec/step, loss=0.08023, avg_loss=0.08473]
[2025-06-07 07:47:23.667]  Step 75532   [4.697 sec/step, loss=0.08397, avg_loss=0.08465]
[2025-06-07 07:47:31.087]  Step 75533   [4.698 sec/step, loss=0.09217, avg_loss=0.08469]
[2025-06-07 07:47:36.187]  Step 75534   [4.667 sec/step, loss=0.08922, avg_loss=0.08468]
[2025-06-07 07:47:39.301]  Step 75535   [4.660 sec/step, loss=0.08427, avg_loss=0.08468]
[2025-06-07 07:47:42.166]  Step 75536   [4.562 sec/step, loss=0.08314, avg_loss=0.08460]
[2025-06-07 07:47:45.484]  Step 75537   [4.556 sec/step, loss=0.08538, avg_loss=0.08460]
[2025-06-07 07:47:48.082]  Step 75538   [4.567 sec/step, loss=0.08197, avg_loss=0.08472]
[2025-06-07 07:47:52.405]  Step 75539   [4.565 sec/step, loss=0.08504, avg_loss=0.08470]
[2025-06-07 07:47:54.084]  Step 75540   [4.529 sec/step, loss=0.07630, avg_loss=0.08457]
[2025-06-07 07:47:56.564]  Step 75541   [4.533 sec/step, loss=0.08047, avg_loss=0.08458]
[2025-06-07 07:47:58.153]  Step 75542   [4.494 sec/step, loss=0.07062, avg_loss=0.08440]
[2025-06-07 07:48:06.412]  Step 75543   [4.536 sec/step, loss=0.09280, avg_loss=0.08446]
[2025-06-07 07:48:08.243]  Step 75544   [4.488 sec/step, loss=0.07687, avg_loss=0.08434]
[2025-06-07 07:48:10.352]  Step 75545   [4.337 sec/step, loss=0.07864, avg_loss=0.08432]
[2025-06-07 07:48:14.697]  Step 75546   [4.311 sec/step, loss=0.08657, avg_loss=0.08427]
[2025-06-07 07:48:16.883]  Step 75547   [4.300 sec/step, loss=0.08120, avg_loss=0.08424]
[2025-06-07 07:48:21.821]  Step 75548   [4.294 sec/step, loss=0.08732, avg_loss=0.08422]
[2025-06-07 07:48:25.327]  Step 75549   [4.292 sec/step, loss=0.08516, avg_loss=0.08422]
[2025-06-07 07:48:32.428]  Step 75550   [4.346 sec/step, loss=0.09110, avg_loss=0.08438]
[2025-06-07 07:48:32.428]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75550
[2025-06-07 07:48:33.513]  Saving audio and alignment...
[2025-06-07 07:48:39.470]  Input: iaai ddu pontt dde nimours endd kmpnii euttaa tthulo kmpnii ho bhnn mildch~_________________
[2025-06-07 07:48:43.271]  Step 75551   [4.357 sec/step, loss=0.08478, avg_loss=0.08440]
[2025-06-07 07:48:47.587]  Generated 32 batches of size 32 in 3.906 sec
[2025-06-07 07:48:50.094]  Step 75552   [4.347 sec/step, loss=0.08761, avg_loss=0.08436]
[2025-06-07 07:48:57.841]  Step 75553   [4.336 sec/step, loss=0.09081, avg_loss=0.08437]
[2025-06-07 07:48:59.882]  Step 75554   [4.324 sec/step, loss=0.07860, avg_loss=0.08431]
[2025-06-07 07:49:23.381]  Step 75555   [4.539 sec/step, loss=0.08050, avg_loss=0.08433]
[2025-06-07 07:49:33.465]  Step 75556   [4.609 sec/step, loss=0.09093, avg_loss=0.08439]
[2025-06-07 07:49:36.739]  Step 75557   [4.583 sec/step, loss=0.08419, avg_loss=0.08432]
[2025-06-07 07:49:42.907]  Step 75558   [4.623 sec/step, loss=0.08903, avg_loss=0.08443]
[2025-06-07 07:49:48.947]  Step 75559   [4.620 sec/step, loss=0.08916, avg_loss=0.08444]
[2025-06-07 07:49:53.020]  Step 75560   [4.641 sec/step, loss=0.08437, avg_loss=0.08451]
[2025-06-07 07:49:56.911]  Step 75561   [4.650 sec/step, loss=0.08452, avg_loss=0.08451]
[2025-06-07 07:50:01.532]  Step 75562   [4.657 sec/step, loss=0.08796, avg_loss=0.08454]
[2025-06-07 07:50:07.418]  Step 75563   [4.683 sec/step, loss=0.08742, avg_loss=0.08458]
[2025-06-07 07:50:13.327]  Step 75564   [4.699 sec/step, loss=0.08826, avg_loss=0.08459]
[2025-06-07 07:50:18.444]  Step 75565   [4.723 sec/step, loss=0.08781, avg_loss=0.08464]
[2025-06-07 07:50:20.642]  Step 75566   [4.725 sec/step, loss=0.07980, avg_loss=0.08462]
[2025-06-07 07:50:25.717]  Step 75567   [4.753 sec/step, loss=0.08782, avg_loss=0.08470]
[2025-06-07 07:50:28.755]  Step 75568   [4.730 sec/step, loss=0.08279, avg_loss=0.08464]
[2025-06-07 07:50:35.768]  Step 75569   [4.644 sec/step, loss=0.09142, avg_loss=0.08464]
[2025-06-07 07:50:38.933]  Step 75570   [4.648 sec/step, loss=0.08262, avg_loss=0.08462]
[2025-06-07 07:50:45.308]  Step 75571   [4.674 sec/step, loss=0.08990, avg_loss=0.08467]
[2025-06-07 07:50:48.259]  Step 75572   [4.563 sec/step, loss=0.08321, avg_loss=0.08467]
[2025-06-07 07:50:49.843]  Step 75573   [4.517 sec/step, loss=0.06939, avg_loss=0.08447]
[2025-06-07 07:50:54.257]  Step 75574   [4.530 sec/step, loss=0.08473, avg_loss=0.08449]
[2025-06-07 07:51:00.256]  Step 75575   [4.563 sec/step, loss=0.09018, avg_loss=0.08456]
[2025-06-07 07:51:04.614]  Step 75576   [4.573 sec/step, loss=0.08616, avg_loss=0.08456]
[2025-06-07 07:51:12.426]  Step 75577   [4.631 sec/step, loss=0.09271, avg_loss=0.08471]
[2025-06-07 07:51:14.729]  Step 75578   [4.597 sec/step, loss=0.08016, avg_loss=0.08461]
[2025-06-07 07:51:17.440]  Step 75579   [4.604 sec/step, loss=0.08244, avg_loss=0.08467]
[2025-06-07 07:51:20.940]  Step 75580   [4.617 sec/step, loss=0.08462, avg_loss=0.08473]
[2025-06-07 07:51:59.785]  Step 75581   [4.988 sec/step, loss=0.08186, avg_loss=0.08479]
[2025-06-07 07:52:02.479]  Step 75582   [4.992 sec/step, loss=0.08267, avg_loss=0.08481]
[2025-06-07 07:52:06.170]  Step 75583   [4.984 sec/step, loss=0.08408, avg_loss=0.08478]
[2025-06-07 07:52:09.596]  Step 75584   [4.978 sec/step, loss=0.08296, avg_loss=0.08475]
[2025-06-07 07:52:10.998]  Generated 32 batches of size 32 in 4.497 sec
[2025-06-07 07:52:11.468]  Step 75585   [4.965 sec/step, loss=0.07376, avg_loss=0.08465]
[2025-06-07 07:52:13.507]  Step 75586   [4.941 sec/step, loss=0.07845, avg_loss=0.08457]
[2025-06-07 07:52:20.929]  Step 75587   [4.988 sec/step, loss=0.09236, avg_loss=0.08465]
[2025-06-07 07:52:24.115]  Step 75588   [4.952 sec/step, loss=0.08522, avg_loss=0.08457]
[2025-06-07 07:52:32.633]  Step 75589   [4.980 sec/step, loss=0.09206, avg_loss=0.08460]
[2025-06-07 07:52:34.869]  Step 75590   [4.967 sec/step, loss=0.08072, avg_loss=0.08455]
[2025-06-07 07:52:38.499]  Step 75591   [4.945 sec/step, loss=0.08339, avg_loss=0.08450]
[2025-06-07 07:52:40.272]  Step 75592   [4.930 sec/step, loss=0.07715, avg_loss=0.08444]
[2025-06-07 07:52:46.074]  Step 75593   [4.964 sec/step, loss=0.08942, avg_loss=0.08452]
[2025-06-07 07:52:47.630]  Step 75594   [4.897 sec/step, loss=0.07020, avg_loss=0.08432]
[2025-06-07 07:52:51.106]  Step 75595   [4.884 sec/step, loss=0.08504, avg_loss=0.08429]
[2025-06-07 07:52:53.352]  Step 75596   [4.891 sec/step, loss=0.08160, avg_loss=0.08441]
[2025-06-07 07:52:58.786]  Step 75597   [4.910 sec/step, loss=0.08787, avg_loss=0.08444]
[2025-06-07 07:53:03.765]  Step 75598   [4.871 sec/step, loss=0.08920, avg_loss=0.08441]
[2025-06-07 07:53:08.732]  Step 75599   [4.854 sec/step, loss=0.08920, avg_loss=0.08440]
[2025-06-07 07:53:12.586]  Step 75600   [4.854 sec/step, loss=0.08490, avg_loss=0.08440]
[2025-06-07 07:53:12.586]  Writing summary at step: 75600
[2025-06-07 07:53:15.654]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75600
[2025-06-07 07:53:16.675]  Saving audio and alignment...
[2025-06-07 07:53:21.011]  Input: cubhaas gnntntrko raajdhaaniiko kendriiy rusmaa rheko shr~____________
[2025-06-07 07:53:22.879]  Step 75601   [4.845 sec/step, loss=0.07659, avg_loss=0.08434]
[2025-06-07 07:53:28.034]  Step 75602   [4.872 sec/step, loss=0.08807, avg_loss=0.08441]
[2025-06-07 07:53:32.035]  Step 75603   [4.889 sec/step, loss=0.08698, avg_loss=0.08449]
[2025-06-07 07:53:36.073]  Step 75604   [4.914 sec/step, loss=0.08718, avg_loss=0.08465]
[2025-06-07 07:53:42.490]  Step 75605   [4.947 sec/step, loss=0.09005, avg_loss=0.08472]
[2025-06-07 07:53:45.050]  Step 75606   [4.902 sec/step, loss=0.08303, avg_loss=0.08465]
[2025-06-07 07:53:54.100]  Step 75607   [4.975 sec/step, loss=0.09070, avg_loss=0.08481]
[2025-06-07 07:53:56.767]  Step 75608   [4.962 sec/step, loss=0.08354, avg_loss=0.08479]
[2025-06-07 07:54:04.675]  Step 75609   [5.021 sec/step, loss=0.09248, avg_loss=0.08492]
[2025-06-07 07:54:06.634]  Step 75610   [4.985 sec/step, loss=0.07849, avg_loss=0.08482]
[2025-06-07 07:54:08.746]  Step 75611   [4.915 sec/step, loss=0.07991, avg_loss=0.08470]
[2025-06-07 07:54:15.247]  Step 75612   [4.943 sec/step, loss=0.09113, avg_loss=0.08476]
[2025-06-07 07:54:17.647]  Step 75613   [4.940 sec/step, loss=0.08131, avg_loss=0.08476]
[2025-06-07 07:54:24.046]  Generated 32 batches of size 32 in 5.910 sec
[2025-06-07 07:54:51.810]  Step 75614   [5.218 sec/step, loss=0.08872, avg_loss=0.08475]
[2025-06-07 07:54:54.321]  Step 75615   [5.223 sec/step, loss=0.08026, avg_loss=0.08475]
[2025-06-07 07:54:57.946]  Step 75616   [5.183 sec/step, loss=0.08542, avg_loss=0.08469]
[2025-06-07 07:54:59.739]  Step 75617   [5.165 sec/step, loss=0.07851, avg_loss=0.08463]
[2025-06-07 07:55:03.271]  Step 75618   [5.134 sec/step, loss=0.08562, avg_loss=0.08457]
[2025-06-07 07:55:07.061]  Step 75619   [5.140 sec/step, loss=0.08473, avg_loss=0.08458]
[2025-06-07 07:55:09.974]  Step 75620   [5.119 sec/step, loss=0.08292, avg_loss=0.08453]
[2025-06-07 07:55:17.590]  Step 75621   [5.127 sec/step, loss=0.09150, avg_loss=0.08455]
[2025-06-07 07:55:22.389]  Step 75622   [5.131 sec/step, loss=0.08680, avg_loss=0.08455]
[2025-06-07 07:55:24.886]  Step 75623   [5.137 sec/step, loss=0.08210, avg_loss=0.08460]
[2025-06-07 07:55:27.008]  Step 75624   [5.115 sec/step, loss=0.07947, avg_loss=0.08452]
[2025-06-07 07:55:33.783]  Step 75625   [5.148 sec/step, loss=0.09033, avg_loss=0.08459]
[2025-06-07 07:55:36.164]  Step 75626   [5.075 sec/step, loss=0.08029, avg_loss=0.08446]
[2025-06-07 07:55:42.505]  Step 75627   [5.111 sec/step, loss=0.08950, avg_loss=0.08453]
[2025-06-07 07:55:45.727]  Step 75628   [4.982 sec/step, loss=0.08378, avg_loss=0.08456]
[2025-06-07 07:55:48.643]  Step 75629   [4.977 sec/step, loss=0.08231, avg_loss=0.08454]
[2025-06-07 07:55:51.757]  Step 75630   [4.981 sec/step, loss=0.08410, avg_loss=0.08454]
[2025-06-07 07:55:55.977]  Step 75631   [4.999 sec/step, loss=0.08560, avg_loss=0.08460]
[2025-06-07 07:55:59.409]  Step 75632   [5.002 sec/step, loss=0.08471, avg_loss=0.08460]
[2025-06-07 07:56:16.015]  Step 75633   [5.093 sec/step, loss=0.08193, avg_loss=0.08450]
[2025-06-07 07:56:17.892]  Step 75634   [5.061 sec/step, loss=0.07772, avg_loss=0.08439]
[2025-06-07 07:56:27.686]  Step 75635   [5.128 sec/step, loss=0.09109, avg_loss=0.08445]
[2025-06-07 07:56:31.295]  Step 75636   [5.135 sec/step, loss=0.08489, avg_loss=0.08447]
[2025-06-07 07:56:33.266]  Step 75637   [5.122 sec/step, loss=0.07642, avg_loss=0.08438]
[2025-06-07 07:56:37.480]  Step 75638   [5.138 sec/step, loss=0.08404, avg_loss=0.08440]
[2025-06-07 07:56:39.853]  Step 75639   [5.119 sec/step, loss=0.08006, avg_loss=0.08435]
[2025-06-07 07:56:42.625]  Step 75640   [5.130 sec/step, loss=0.08319, avg_loss=0.08442]
[2025-06-07 07:56:46.550]  Step 75641   [5.144 sec/step, loss=0.08533, avg_loss=0.08447]
[2025-06-07 07:56:51.319]  Step 75642   [5.176 sec/step, loss=0.08674, avg_loss=0.08463]
[2025-06-07 07:56:59.817]  Step 75643   [5.178 sec/step, loss=0.09377, avg_loss=0.08464]
[2025-06-07 07:57:05.423]  Step 75644   [5.216 sec/step, loss=0.08765, avg_loss=0.08475]
[2025-06-07 07:57:10.920]  Step 75645   [5.250 sec/step, loss=0.08875, avg_loss=0.08485]
[2025-06-07 07:57:15.839]  Generated 32 batches of size 32 in 4.515 sec
[2025-06-07 07:57:17.816]  Step 75646   [5.275 sec/step, loss=0.08708, avg_loss=0.08486]
[2025-06-07 07:57:25.310]  Step 75647   [5.328 sec/step, loss=0.09180, avg_loss=0.08496]
[2025-06-07 07:57:33.006]  Step 75648   [5.356 sec/step, loss=0.09189, avg_loss=0.08501]
[2025-06-07 07:57:36.618]  Step 75649   [5.357 sec/step, loss=0.08519, avg_loss=0.08501]
[2025-06-07 07:57:38.573]  Step 75650   [5.306 sec/step, loss=0.07910, avg_loss=0.08489]
[2025-06-07 07:57:38.573]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75650
[2025-06-07 07:57:39.653]  Saving audio and alignment...
[2025-06-07 07:57:47.655]  Input: aaienttiel ephstton inkle aaphnaa krmcaariihruulaaii raamro munaaph vitrnn greko ch~______________________________________
[2025-06-07 07:57:49.379]  Step 75651   [5.285 sec/step, loss=0.07051, avg_loss=0.08474]
[2025-06-07 07:57:53.705]  Step 75652   [5.260 sec/step, loss=0.08630, avg_loss=0.08473]
[2025-06-07 07:57:56.361]  Step 75653   [5.209 sec/step, loss=0.08279, avg_loss=0.08465]
[2025-06-07 07:57:58.205]  Step 75654   [5.207 sec/step, loss=0.07771, avg_loss=0.08464]
[2025-06-07 07:58:04.281]  Step 75655   [5.033 sec/step, loss=0.08919, avg_loss=0.08473]
[2025-06-07 07:58:07.846]  Step 75656   [4.968 sec/step, loss=0.08442, avg_loss=0.08466]
[2025-06-07 07:58:11.465]  Step 75657   [4.971 sec/step, loss=0.08507, avg_loss=0.08467]
[2025-06-07 07:58:14.087]  Step 75658   [4.936 sec/step, loss=0.08266, avg_loss=0.08461]
[2025-06-07 07:58:17.320]  Step 75659   [4.908 sec/step, loss=0.08544, avg_loss=0.08457]
[2025-06-07 07:58:20.543]  Step 75660   [4.899 sec/step, loss=0.08283, avg_loss=0.08456]
[2025-06-07 07:58:22.101]  Step 75661   [4.876 sec/step, loss=0.07332, avg_loss=0.08445]
[2025-06-07 07:58:24.342]  Step 75662   [4.852 sec/step, loss=0.08109, avg_loss=0.08438]
[2025-06-07 07:58:32.392]  Step 75663   [4.874 sec/step, loss=0.09113, avg_loss=0.08441]
[2025-06-07 07:58:34.570]  Step 75664   [4.836 sec/step, loss=0.07979, avg_loss=0.08433]
[2025-06-07 07:58:37.269]  Step 75665   [4.812 sec/step, loss=0.08147, avg_loss=0.08427]
[2025-06-07 07:58:39.631]  Step 75666   [4.814 sec/step, loss=0.08205, avg_loss=0.08429]
[2025-06-07 07:58:42.579]  Step 75667   [4.792 sec/step, loss=0.08416, avg_loss=0.08425]
[2025-06-07 07:58:47.500]  Step 75668   [4.811 sec/step, loss=0.08897, avg_loss=0.08431]
[2025-06-07 07:58:52.713]  Step 75669   [4.793 sec/step, loss=0.08788, avg_loss=0.08428]
[2025-06-07 07:58:58.218]  Step 75670   [4.817 sec/step, loss=0.08840, avg_loss=0.08434]
[2025-06-07 07:59:07.829]  Step 75671   [4.849 sec/step, loss=0.09127, avg_loss=0.08435]
[2025-06-07 07:59:22.839]  Step 75672   [4.970 sec/step, loss=0.08113, avg_loss=0.08433]
[2025-06-07 07:59:29.328]  Step 75673   [5.019 sec/step, loss=0.08994, avg_loss=0.08453]
[2025-06-07 07:59:34.774]  Step 75674   [5.029 sec/step, loss=0.08912, avg_loss=0.08458]
[2025-06-07 07:59:37.542]  Step 75675   [4.997 sec/step, loss=0.08381, avg_loss=0.08451]
[2025-06-07 07:59:41.888]  Step 75676   [4.996 sec/step, loss=0.08572, avg_loss=0.08451]
[2025-06-07 07:59:46.477]  Generated 32 batches of size 32 in 4.093 sec
[2025-06-07 07:59:47.075]  Step 75677   [4.970 sec/step, loss=0.08506, avg_loss=0.08443]
[2025-06-07 07:59:55.939]  Step 75678   [5.036 sec/step, loss=0.09189, avg_loss=0.08455]
[2025-06-07 07:59:57.969]  Step 75679   [5.029 sec/step, loss=0.07852, avg_loss=0.08451]
[2025-06-07 08:00:02.350]  Step 75680   [5.038 sec/step, loss=0.08668, avg_loss=0.08453]
[2025-06-07 08:00:06.262]  Step 75681   [4.689 sec/step, loss=0.08301, avg_loss=0.08454]
[2025-06-07 08:00:13.670]  Step 75682   [4.736 sec/step, loss=0.09027, avg_loss=0.08462]
[2025-06-07 08:00:18.273]  Step 75683   [4.745 sec/step, loss=0.08691, avg_loss=0.08465]
[2025-06-07 08:00:20.036]  Step 75684   [4.728 sec/step, loss=0.07702, avg_loss=0.08459]
[2025-06-07 08:00:22.921]  Step 75685   [4.738 sec/step, loss=0.08273, avg_loss=0.08468]
[2025-06-07 08:00:26.059]  Step 75686   [4.749 sec/step, loss=0.08342, avg_loss=0.08473]
[2025-06-07 08:00:27.990]  Step 75687   [4.695 sec/step, loss=0.07615, avg_loss=0.08457]
[2025-06-07 08:00:31.594]  Step 75688   [4.699 sec/step, loss=0.08516, avg_loss=0.08456]
[2025-06-07 08:00:37.748]  Step 75689   [4.675 sec/step, loss=0.08914, avg_loss=0.08454]
[2025-06-07 08:00:45.239]  Step 75690   [4.728 sec/step, loss=0.09227, avg_loss=0.08465]
[2025-06-07 08:00:52.820]  Step 75691   [4.767 sec/step, loss=0.09142, avg_loss=0.08473]
[2025-06-07 08:00:58.045]  Step 75692   [4.802 sec/step, loss=0.08801, avg_loss=0.08484]
[2025-06-07 08:01:00.439]  Step 75693   [4.768 sec/step, loss=0.08022, avg_loss=0.08475]
[2025-06-07 08:01:03.152]  Step 75694   [4.779 sec/step, loss=0.08197, avg_loss=0.08487]
[2025-06-07 08:01:08.993]  Step 75695   [4.803 sec/step, loss=0.08804, avg_loss=0.08490]
[2025-06-07 08:01:15.744]  Step 75696   [4.848 sec/step, loss=0.08982, avg_loss=0.08498]
[2025-06-07 08:01:17.514]  Step 75697   [4.811 sec/step, loss=0.07756, avg_loss=0.08487]
[2025-06-07 08:01:20.766]  Step 75698   [4.794 sec/step, loss=0.08405, avg_loss=0.08482]
[2025-06-07 08:01:24.289]  Step 75699   [4.780 sec/step, loss=0.08418, avg_loss=0.08477]
[2025-06-07 08:01:27.189]  Step 75700   [4.770 sec/step, loss=0.08216, avg_loss=0.08475]
[2025-06-07 08:01:27.191]  Writing summary at step: 75700
[2025-06-07 08:01:37.447]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75700
[2025-06-07 08:01:38.505]  Saving audio and alignment...
[2025-06-07 08:01:42.222]  Input: kim kulig jrmn phuttbl khelaaddii~_________
[2025-06-07 08:01:48.136]  Step 75701   [4.811 sec/step, loss=0.08955, avg_loss=0.08488]
[2025-06-07 08:01:53.144]  Step 75702   [4.809 sec/step, loss=0.08775, avg_loss=0.08487]
[2025-06-07 08:01:58.100]  Step 75703   [4.819 sec/step, loss=0.08704, avg_loss=0.08487]
[2025-06-07 08:02:00.824]  Step 75704   [4.805 sec/step, loss=0.08285, avg_loss=0.08483]
[2025-06-07 08:02:03.625]  Step 75705   [4.769 sec/step, loss=0.08424, avg_loss=0.08477]
[2025-06-07 08:02:18.198]  Step 75706   [4.889 sec/step, loss=0.08640, avg_loss=0.08481]
[2025-06-07 08:02:20.310]  Step 75707   [4.820 sec/step, loss=0.07031, avg_loss=0.08460]
[2025-06-07 08:02:22.859]  Generated 32 batches of size 32 in 4.197 sec
[2025-06-07 08:02:29.037]  Step 75708   [4.881 sec/step, loss=0.09063, avg_loss=0.08467]
[2025-06-07 08:02:31.315]  Step 75709   [4.824 sec/step, loss=0.08098, avg_loss=0.08456]
[2025-06-07 08:02:33.640]  Step 75710   [4.828 sec/step, loss=0.08002, avg_loss=0.08457]
[2025-06-07 08:02:36.958]  Step 75711   [4.840 sec/step, loss=0.08522, avg_loss=0.08463]
[2025-06-07 08:02:41.343]  Step 75712   [4.819 sec/step, loss=0.08685, avg_loss=0.08458]
[2025-06-07 08:02:45.156]  Step 75713   [4.833 sec/step, loss=0.08512, avg_loss=0.08462]
[2025-06-07 08:02:49.481]  Step 75714   [4.535 sec/step, loss=0.08632, avg_loss=0.08460]
[2025-06-07 08:02:53.420]  Step 75715   [4.549 sec/step, loss=0.08537, avg_loss=0.08465]
[2025-06-07 08:02:58.188]  Step 75716   [4.560 sec/step, loss=0.08807, avg_loss=0.08467]
[2025-06-07 08:03:03.916]  Step 75717   [4.600 sec/step, loss=0.08794, avg_loss=0.08477]
[2025-06-07 08:03:07.261]  Step 75718   [4.598 sec/step, loss=0.08493, avg_loss=0.08476]
[2025-06-07 08:03:08.847]  Step 75719   [4.576 sec/step, loss=0.06967, avg_loss=0.08461]
[2025-06-07 08:03:11.985]  Step 75720   [4.578 sec/step, loss=0.08402, avg_loss=0.08462]
[2025-06-07 08:03:14.366]  Step 75721   [4.526 sec/step, loss=0.08058, avg_loss=0.08451]
[2025-06-07 08:03:18.767]  Step 75722   [4.522 sec/step, loss=0.08700, avg_loss=0.08452]
[2025-06-07 08:03:55.156]  Step 75723   [4.861 sec/step, loss=0.08200, avg_loss=0.08451]
[2025-06-07 08:03:58.062]  Step 75724   [4.868 sec/step, loss=0.08356, avg_loss=0.08456]
[2025-06-07 08:04:01.579]  Step 75725   [4.836 sec/step, loss=0.08514, avg_loss=0.08450]
[2025-06-07 08:04:03.724]  Step 75726   [4.833 sec/step, loss=0.07840, avg_loss=0.08448]
[2025-06-07 08:04:05.468]  Step 75727   [4.787 sec/step, loss=0.07615, avg_loss=0.08435]
[2025-06-07 08:04:09.821]  Step 75728   [4.799 sec/step, loss=0.08614, avg_loss=0.08437]
[2025-06-07 08:04:14.148]  Step 75729   [4.813 sec/step, loss=0.08761, avg_loss=0.08443]
[2025-06-07 08:04:20.946]  Step 75730   [4.850 sec/step, loss=0.08967, avg_loss=0.08448]
[2025-06-07 08:04:30.333]  Step 75731   [4.901 sec/step, loss=0.08697, avg_loss=0.08450]
[2025-06-07 08:04:33.555]  Step 75732   [4.899 sec/step, loss=0.08338, avg_loss=0.08448]
[2025-06-07 08:04:41.279]  Step 75733   [4.811 sec/step, loss=0.09209, avg_loss=0.08458]
[2025-06-07 08:04:47.400]  Step 75734   [4.853 sec/step, loss=0.09144, avg_loss=0.08472]
[2025-06-07 08:04:49.268]  Step 75735   [4.774 sec/step, loss=0.07615, avg_loss=0.08457]
[2025-06-07 08:04:53.264]  Step 75736   [4.778 sec/step, loss=0.08508, avg_loss=0.08457]
[2025-06-07 08:04:56.033]  Step 75737   [4.786 sec/step, loss=0.08123, avg_loss=0.08462]
[2025-06-07 08:05:03.360]  Step 75738   [4.817 sec/step, loss=0.09212, avg_loss=0.08470]
[2025-06-07 08:05:07.878]  Generated 32 batches of size 32 in 4.060 sec
[2025-06-07 08:05:09.895]  Step 75739   [4.858 sec/step, loss=0.08822, avg_loss=0.08479]
[2025-06-07 08:05:12.219]  Step 75740   [4.854 sec/step, loss=0.08122, avg_loss=0.08477]
[2025-06-07 08:05:16.096]  Step 75741   [4.853 sec/step, loss=0.08533, avg_loss=0.08477]
[2025-06-07 08:05:18.611]  Step 75742   [4.831 sec/step, loss=0.08241, avg_loss=0.08472]
[2025-06-07 08:05:21.336]  Step 75743   [4.773 sec/step, loss=0.08458, avg_loss=0.08463]
[2025-06-07 08:05:23.427]  Step 75744   [4.738 sec/step, loss=0.07837, avg_loss=0.08454]
[2025-06-07 08:05:29.664]  Step 75745   [4.745 sec/step, loss=0.08943, avg_loss=0.08454]
[2025-06-07 08:05:33.304]  Step 75746   [4.713 sec/step, loss=0.08487, avg_loss=0.08452]
[2025-06-07 08:05:38.771]  Step 75747   [4.693 sec/step, loss=0.08900, avg_loss=0.08449]
[2025-06-07 08:05:43.207]  Step 75748   [4.660 sec/step, loss=0.08584, avg_loss=0.08443]
[2025-06-07 08:05:45.519]  Step 75749   [4.647 sec/step, loss=0.07960, avg_loss=0.08438]
[2025-06-07 08:05:51.294]  Step 75750   [4.685 sec/step, loss=0.08876, avg_loss=0.08447]
[2025-06-07 08:05:51.294]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75750
[2025-06-07 08:05:52.415]  Saving audio and alignment...
[2025-06-07 08:05:58.642]  Input: kyaampiyn klej llitpur jillaako kumaariipaattiimaa avsthit ek klej ho~_________________
[2025-06-07 08:06:04.279]  Step 75751   [4.724 sec/step, loss=0.08888, avg_loss=0.08466]
[2025-06-07 08:06:12.826]  Step 75752   [4.766 sec/step, loss=0.09085, avg_loss=0.08470]
[2025-06-07 08:06:19.882]  Step 75753   [4.810 sec/step, loss=0.09184, avg_loss=0.08479]
[2025-06-07 08:06:23.308]  Step 75754   [4.826 sec/step, loss=0.08517, avg_loss=0.08487]
[2025-06-07 08:06:25.271]  Step 75755   [4.785 sec/step, loss=0.07815, avg_loss=0.08476]
[2025-06-07 08:06:27.802]  Step 75756   [4.775 sec/step, loss=0.08115, avg_loss=0.08473]
[2025-06-07 08:06:29.974]  Step 75757   [4.760 sec/step, loss=0.08096, avg_loss=0.08468]
[2025-06-07 08:06:32.672]  Step 75758   [4.761 sec/step, loss=0.08404, avg_loss=0.08470]
[2025-06-07 08:06:36.344]  Step 75759   [4.765 sec/step, loss=0.08489, avg_loss=0.08469]
[2025-06-07 08:06:42.622]  Step 75760   [4.796 sec/step, loss=0.08968, avg_loss=0.08476]
[2025-06-07 08:06:44.974]  Step 75761   [4.804 sec/step, loss=0.08217, avg_loss=0.08485]
[2025-06-07 08:06:48.212]  Step 75762   [4.814 sec/step, loss=0.08360, avg_loss=0.08487]
[2025-06-07 08:06:50.289]  Step 75763   [4.754 sec/step, loss=0.08010, avg_loss=0.08476]
[2025-06-07 08:06:52.105]  Step 75764   [4.751 sec/step, loss=0.07640, avg_loss=0.08473]
[2025-06-07 08:06:53.783]  Step 75765   [4.740 sec/step, loss=0.06976, avg_loss=0.08461]
[2025-06-07 08:06:57.179]  Step 75766   [4.751 sec/step, loss=0.08324, avg_loss=0.08463]
[2025-06-07 08:06:59.978]  Step 75767   [4.749 sec/step, loss=0.08402, avg_loss=0.08462]
[2025-06-07 08:07:34.817]  Step 75768   [5.048 sec/step, loss=0.08276, avg_loss=0.08456]
[2025-06-07 08:07:39.008]  Step 75769   [5.038 sec/step, loss=0.08478, avg_loss=0.08453]
[2025-06-07 08:07:43.814]  Generated 32 batches of size 32 in 4.276 sec
[2025-06-07 08:07:49.803]  Step 75770   [5.091 sec/step, loss=0.09235, avg_loss=0.08457]
[2025-06-07 08:07:54.655]  Step 75771   [5.043 sec/step, loss=0.08776, avg_loss=0.08454]
[2025-06-07 08:08:03.252]  Step 75772   [4.979 sec/step, loss=0.09250, avg_loss=0.08465]
[2025-06-07 08:08:07.058]  Step 75773   [4.953 sec/step, loss=0.08534, avg_loss=0.08460]
[2025-06-07 08:08:12.427]  Step 75774   [4.952 sec/step, loss=0.08859, avg_loss=0.08460]
[2025-06-07 08:08:15.184]  Step 75775   [4.952 sec/step, loss=0.08305, avg_loss=0.08459]
[2025-06-07 08:08:21.141]  Step 75776   [4.968 sec/step, loss=0.08877, avg_loss=0.08462]
[2025-06-07 08:08:27.924]  Step 75777   [4.984 sec/step, loss=0.08951, avg_loss=0.08466]
[2025-06-07 08:08:31.008]  Step 75778   [4.926 sec/step, loss=0.08294, avg_loss=0.08458]
[2025-06-07 08:08:35.111]  Step 75779   [4.947 sec/step, loss=0.08649, avg_loss=0.08466]
[2025-06-07 08:08:37.705]  Step 75780   [4.929 sec/step, loss=0.08065, avg_loss=0.08459]
[2025-06-07 08:08:40.522]  Step 75781   [4.918 sec/step, loss=0.08425, avg_loss=0.08461]
[2025-06-07 08:08:44.106]  Step 75782   [4.880 sec/step, loss=0.08405, avg_loss=0.08454]
[2025-06-07 08:53:53.322]  Step 75783   [31.926 sec/step, loss=0.08514, avg_loss=0.08453]
[2025-06-07 08:53:59.711]  Step 75784   [31.972 sec/step, loss=0.08386, avg_loss=0.08460]
[2025-06-07 08:54:07.794]  Step 75785   [32.024 sec/step, loss=0.08417, avg_loss=0.08461]
[2025-06-07 08:54:13.168]  Step 75786   [32.046 sec/step, loss=0.08214, avg_loss=0.08460]
[2025-06-07 08:54:20.777]  Step 75787   [32.103 sec/step, loss=0.08531, avg_loss=0.08469]
[2025-06-07 08:54:37.535]  Step 75788   [32.235 sec/step, loss=0.09049, avg_loss=0.08474]
[2025-06-07 08:54:41.638]  Step 75789   [32.214 sec/step, loss=0.07059, avg_loss=0.08456]
[2025-06-07 08:54:48.441]  Step 75790   [32.207 sec/step, loss=0.08364, avg_loss=0.08447]
[2025-06-07 08:54:53.215]  Step 75791   [32.179 sec/step, loss=0.08165, avg_loss=0.08437]
[2025-06-07 08:55:05.495]  Step 75792   [32.250 sec/step, loss=0.09127, avg_loss=0.08441]
[2025-06-07 08:55:09.596]  Step 75793   [32.267 sec/step, loss=0.08038, avg_loss=0.08441]
[2025-06-07 08:55:12.892]  Step 75794   [32.273 sec/step, loss=0.07863, avg_loss=0.08437]
[2025-06-07 08:55:15.921]  Step 75795   [32.244 sec/step, loss=0.07605, avg_loss=0.08425]
[2025-06-07 08:55:29.616]  Step 75796   [32.314 sec/step, loss=0.09291, avg_loss=0.08428]
[2025-06-07 08:55:37.936]  Step 75797   [32.379 sec/step, loss=0.08734, avg_loss=0.08438]
[2025-06-07 08:56:03.517]  Step 75798   [32.602 sec/step, loss=0.07894, avg_loss=0.08433]
[2025-06-07 08:56:06.995]  Step 75799   [32.602 sec/step, loss=0.07970, avg_loss=0.08429]
[2025-06-07 08:56:17.512]  Step 75800   [32.678 sec/step, loss=0.09110, avg_loss=0.08438]
[2025-06-07 08:56:17.512]  Writing summary at step: 75800
[2025-06-07 08:56:26.559]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75800
[2025-06-07 08:56:28.307]  Saving audio and alignment...
[2025-06-07 08:56:35.497]  Generated 32 batches of size 32 in 4.806 sec
[2025-06-07 08:56:37.681]  Input: nesnvaaidd myucual insyorens kn euttaa raamro r tthulo bimaa kmpnii ho~____
[2025-06-07 08:56:43.901]  Step 75801   [32.681 sec/step, loss=0.08618, avg_loss=0.08434]
[2025-06-07 08:56:46.432]  Step 75802   [32.656 sec/step, loss=0.07623, avg_loss=0.08423]
[2025-06-07 08:56:52.779]  Step 75803   [32.670 sec/step, loss=0.08699, avg_loss=0.08423]
[2025-06-07 08:56:58.703]  Step 75804   [32.702 sec/step, loss=0.09125, avg_loss=0.08431]
[2025-06-07 08:57:01.815]  Step 75805   [32.705 sec/step, loss=0.08526, avg_loss=0.08432]
[2025-06-07 08:57:06.325]  Step 75806   [32.605 sec/step, loss=0.08724, avg_loss=0.08433]
[2025-06-07 08:57:14.827]  Step 75807   [32.669 sec/step, loss=0.09154, avg_loss=0.08454]
[2025-06-07 08:57:19.711]  Step 75808   [32.630 sec/step, loss=0.08696, avg_loss=0.08450]
[2025-06-07 08:57:24.775]  Step 75809   [32.658 sec/step, loss=0.08727, avg_loss=0.08457]
[2025-06-07 08:57:29.640]  Step 75810   [32.683 sec/step, loss=0.08798, avg_loss=0.08465]
[2025-06-07 08:57:35.243]  Step 75811   [32.706 sec/step, loss=0.08963, avg_loss=0.08469]
[2025-06-07 08:57:39.126]  Step 75812   [32.701 sec/step, loss=0.08635, avg_loss=0.08469]
[2025-06-07 08:57:40.741]  Step 75813   [32.679 sec/step, loss=0.07879, avg_loss=0.08462]
[2025-06-07 08:57:44.562]  Step 75814   [32.674 sec/step, loss=0.08550, avg_loss=0.08461]
[2025-06-07 08:57:46.748]  Step 75815   [32.657 sec/step, loss=0.07978, avg_loss=0.08456]
[2025-06-07 08:57:48.576]  Step 75816   [32.627 sec/step, loss=0.07737, avg_loss=0.08445]
[2025-06-07 08:57:52.370]  Step 75817   [32.608 sec/step, loss=0.08529, avg_loss=0.08443]
[2025-06-07 08:57:54.534]  Step 75818   [32.596 sec/step, loss=0.08102, avg_loss=0.08439]
[2025-06-07 08:57:56.428]  Step 75819   [32.599 sec/step, loss=0.07923, avg_loss=0.08448]
[2025-06-07 08:57:59.592]  Step 75820   [32.599 sec/step, loss=0.08436, avg_loss=0.08449]
[2025-06-07 08:58:04.690]  Step 75821   [32.627 sec/step, loss=0.08732, avg_loss=0.08455]
[2025-06-07 08:58:07.355]  Step 75822   [32.609 sec/step, loss=0.08443, avg_loss=0.08453]
[2025-06-07 08:58:17.371]  Step 75823   [32.346 sec/step, loss=0.09135, avg_loss=0.08462]
[2025-06-07 08:58:24.019]  Step 75824   [32.383 sec/step, loss=0.09100, avg_loss=0.08469]
[2025-06-07 08:58:31.811]  Step 75825   [32.426 sec/step, loss=0.09087, avg_loss=0.08475]
[2025-06-07 08:58:39.497]  Step 75826   [32.481 sec/step, loss=0.09312, avg_loss=0.08490]
[2025-06-07 08:58:41.965]  Step 75827   [32.488 sec/step, loss=0.08279, avg_loss=0.08497]
[2025-06-07 08:58:44.411]  Step 75828   [32.469 sec/step, loss=0.08247, avg_loss=0.08493]
[2025-06-07 08:58:47.169]  Step 75829   [32.454 sec/step, loss=0.08343, avg_loss=0.08489]
[2025-06-07 08:58:50.410]  Step 75830   [32.418 sec/step, loss=0.08544, avg_loss=0.08484]
[2025-06-07 08:58:53.747]  Step 75831   [32.357 sec/step, loss=0.08563, avg_loss=0.08483]
[2025-06-07 08:58:58.179]  Step 75832   [32.370 sec/step, loss=0.08479, avg_loss=0.08485]
[2025-06-07 08:58:58.553]  Generated 32 batches of size 32 in 4.421 sec
[2025-06-07 08:59:03.277]  Step 75833   [32.343 sec/step, loss=0.08638, avg_loss=0.08479]
[2025-06-07 08:59:22.575]  Step 75834   [32.475 sec/step, loss=0.08390, avg_loss=0.08471]
[2025-06-07 08:59:26.062]  Step 75835   [32.491 sec/step, loss=0.08280, avg_loss=0.08478]
[2025-06-07 08:59:27.638]  Step 75836   [32.467 sec/step, loss=0.07074, avg_loss=0.08464]
[2025-06-07 08:59:30.363]  Step 75837   [32.466 sec/step, loss=0.08263, avg_loss=0.08465]
[2025-06-07 08:59:37.184]  Step 75838   [32.461 sec/step, loss=0.08949, avg_loss=0.08462]
[2025-06-07 08:59:41.846]  Step 75839   [32.443 sec/step, loss=0.08862, avg_loss=0.08463]
[2025-06-07 08:59:43.620]  Step 75840   [32.437 sec/step, loss=0.07486, avg_loss=0.08456]
[2025-06-07 08:59:45.264]  Step 75841   [32.415 sec/step, loss=0.07105, avg_loss=0.08442]
[2025-06-07 08:59:50.244]  Step 75842   [32.439 sec/step, loss=0.08699, avg_loss=0.08447]
[2025-06-07 08:59:52.613]  Step 75843   [32.436 sec/step, loss=0.07992, avg_loss=0.08442]
[2025-06-07 08:59:56.096]  Step 75844   [32.450 sec/step, loss=0.08358, avg_loss=0.08447]
[2025-06-07 08:59:58.942]  Step 75845   [32.416 sec/step, loss=0.08314, avg_loss=0.08441]
[2025-06-07 09:00:05.144]  Step 75846   [32.442 sec/step, loss=0.09017, avg_loss=0.08446]
[2025-06-07 09:00:12.280]  Step 75847   [32.458 sec/step, loss=0.09050, avg_loss=0.08448]
[2025-06-07 09:00:18.166]  Step 75848   [32.473 sec/step, loss=0.08816, avg_loss=0.08450]
[2025-06-07 09:00:20.837]  Step 75849   [32.476 sec/step, loss=0.08157, avg_loss=0.08452]
[2025-06-07 09:00:27.576]  Step 75850   [32.486 sec/step, loss=0.09077, avg_loss=0.08454]
[2025-06-07 09:00:27.577]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75850
[2025-06-07 09:00:28.771]  Saving audio and alignment...
[2025-06-07 09:00:37.684]  Input: sindhupaalcok jillaa asptaalko bhvn bhtkekaa kaarnn sevaa prdaan grn nikai gaahro bheko kuraa asptaal prshaasnle jnaaeko ch~________
[2025-06-07 09:00:40.459]  Step 75851   [32.457 sec/step, loss=0.08226, avg_loss=0.08448]
[2025-06-07 09:00:44.363]  Step 75852   [32.411 sec/step, loss=0.08425, avg_loss=0.08441]
[2025-06-07 09:00:46.123]  Step 75853   [32.358 sec/step, loss=0.07709, avg_loss=0.08426]
[2025-06-07 09:00:51.448]  Step 75854   [32.377 sec/step, loss=0.08821, avg_loss=0.08429]
[2025-06-07 09:00:55.150]  Step 75855   [32.394 sec/step, loss=0.08437, avg_loss=0.08435]
[2025-06-07 09:00:57.201]  Step 75856   [32.390 sec/step, loss=0.07923, avg_loss=0.08434]
[2025-06-07 09:01:00.478]  Step 75857   [32.401 sec/step, loss=0.08463, avg_loss=0.08437]
[2025-06-07 09:01:02.730]  Step 75858   [32.396 sec/step, loss=0.08105, avg_loss=0.08434]
[2025-06-07 09:01:06.047]  Step 75859   [32.393 sec/step, loss=0.08425, avg_loss=0.08434]
[2025-06-07 09:01:09.195]  Step 75860   [32.361 sec/step, loss=0.08299, avg_loss=0.08427]
[2025-06-07 09:01:14.781]  Step 75861   [32.394 sec/step, loss=0.08846, avg_loss=0.08433]
[2025-06-07 09:01:17.122]  Step 75862   [32.385 sec/step, loss=0.08185, avg_loss=0.08431]
[2025-06-07 09:01:21.784]  Generated 32 batches of size 32 in 4.229 sec
[2025-06-07 09:01:22.722]  Step 75863   [32.420 sec/step, loss=0.08574, avg_loss=0.08437]
[2025-06-07 09:01:27.114]  Step 75864   [32.446 sec/step, loss=0.08595, avg_loss=0.08447]
[2025-06-07 09:01:56.113]  Step 75865   [32.719 sec/step, loss=0.07835, avg_loss=0.08455]
[2025-06-07 09:02:01.139]  Step 75866   [32.735 sec/step, loss=0.08731, avg_loss=0.08459]
[2025-06-07 09:02:10.865]  Step 75867   [32.804 sec/step, loss=0.09093, avg_loss=0.08466]
[2025-06-07 09:02:12.934]  Step 75868   [32.477 sec/step, loss=0.07683, avg_loss=0.08460]
[2025-06-07 09:02:15.097]  Step 75869   [32.457 sec/step, loss=0.07955, avg_loss=0.08455]
[2025-06-07 09:02:22.798]  Step 75870   [32.426 sec/step, loss=0.09223, avg_loss=0.08455]
[2025-06-07 09:02:25.823]  Step 75871   [32.407 sec/step, loss=0.08321, avg_loss=0.08450]
[2025-06-07 09:02:32.961]  Step 75872   [32.393 sec/step, loss=0.09020, avg_loss=0.08448]
[2025-06-07 09:02:34.648]  Step 75873   [32.372 sec/step, loss=0.07024, avg_loss=0.08433]
[2025-06-07 09:02:37.690]  Step 75874   [32.348 sec/step, loss=0.08361, avg_loss=0.08428]
[2025-06-07 09:02:41.209]  Step 75875   [32.356 sec/step, loss=0.08497, avg_loss=0.08430]
[2025-06-07 09:02:44.258]  Step 75876   [32.327 sec/step, loss=0.08206, avg_loss=0.08423]
[2025-06-07 09:02:52.312]  Step 75877   [32.339 sec/step, loss=0.09337, avg_loss=0.08427]
[2025-06-07 09:02:59.079]  Step 75878   [32.376 sec/step, loss=0.08952, avg_loss=0.08434]
[2025-06-07 09:03:07.619]  Step 75879   [32.421 sec/step, loss=0.09198, avg_loss=0.08439]
[2025-06-07 09:03:11.004]  Step 75880   [32.429 sec/step, loss=0.08568, avg_loss=0.08444]
[2025-06-07 09:03:13.810]  Step 75881   [32.428 sec/step, loss=0.08263, avg_loss=0.08442]
[2025-06-07 09:03:17.460]  Step 75882   [32.429 sec/step, loss=0.08492, avg_loss=0.08443]
[2025-06-07 09:03:20.677]  Step 75883   [5.369 sec/step, loss=0.08391, avg_loss=0.08442]
[2025-06-07 09:03:23.067]  Step 75884   [5.329 sec/step, loss=0.08041, avg_loss=0.08439]
[2025-06-07 09:03:28.588]  Step 75885   [5.304 sec/step, loss=0.08887, avg_loss=0.08443]
[2025-06-07 09:03:32.788]  Step 75886   [5.292 sec/step, loss=0.08385, avg_loss=0.08445]
[2025-06-07 09:03:38.790]  Step 75887   [5.276 sec/step, loss=0.08817, avg_loss=0.08448]
[2025-06-07 09:03:40.729]  Step 75888   [5.128 sec/step, loss=0.07715, avg_loss=0.08435]
[2025-06-07 09:03:45.988]  Step 75889   [5.139 sec/step, loss=0.08836, avg_loss=0.08452]
[2025-06-07 09:03:49.884]  Step 75890   [5.110 sec/step, loss=0.08592, avg_loss=0.08455]
[2025-06-07 09:03:54.262]  Step 75891   [5.106 sec/step, loss=0.08846, avg_loss=0.08461]
[2025-06-07 09:03:56.795]  Step 75892   [5.009 sec/step, loss=0.08183, avg_loss=0.08452]
[2025-06-07 09:03:59.611]  Step 75893   [4.996 sec/step, loss=0.08098, avg_loss=0.08453]
[2025-06-07 09:04:01.765]  Step 75894   [4.984 sec/step, loss=0.08049, avg_loss=0.08454]
[2025-06-07 09:04:04.225]  Step 75895   [4.979 sec/step, loss=0.07822, avg_loss=0.08457]
[2025-06-07 09:04:06.183]  Step 75896   [4.862 sec/step, loss=0.07535, avg_loss=0.08439]
[2025-06-07 09:04:06.593]  Generated 32 batches of size 32 in 4.421 sec
[2025-06-07 09:04:08.869]  Step 75897   [4.805 sec/step, loss=0.08067, avg_loss=0.08432]
[2025-06-07 09:04:16.129]  Step 75898   [4.622 sec/step, loss=0.09010, avg_loss=0.08444]
[2025-06-07 09:04:20.546]  Step 75899   [4.632 sec/step, loss=0.08703, avg_loss=0.08451]
[2025-06-07 09:04:25.125]  Step 75900   [4.572 sec/step, loss=0.08888, avg_loss=0.08449]
[2025-06-07 09:04:25.126]  Writing summary at step: 75900
[2025-06-07 09:04:38.544]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75900
[2025-06-07 09:04:39.723]  Saving audio and alignment...
[2025-06-07 09:04:50.070]  Input: surkhet vimaansthl nepaalko raajdhaanii kaatthmaaddaunbaatt saat sy kimii ttaaddhaa surkhet uptykaako viirendrngr shrsngai rheko ch~______________________
[2025-06-07 09:04:54.326]  Step 75901   [4.553 sec/step, loss=0.08777, avg_loss=0.08450]
[2025-06-07 09:04:59.482]  Step 75902   [4.579 sec/step, loss=0.08883, avg_loss=0.08463]
[2025-06-07 09:05:06.557]  Step 75903   [4.586 sec/step, loss=0.09123, avg_loss=0.08467]
[2025-06-07 09:05:10.055]  Step 75904   [4.562 sec/step, loss=0.08520, avg_loss=0.08461]
[2025-06-07 09:05:12.858]  Step 75905   [4.559 sec/step, loss=0.08334, avg_loss=0.08459]
[2025-06-07 09:05:14.567]  Step 75906   [4.531 sec/step, loss=0.07698, avg_loss=0.08449]
[2025-06-07 09:05:17.177]  Step 75907   [4.472 sec/step, loss=0.08183, avg_loss=0.08439]
[2025-06-07 09:05:19.864]  Step 75908   [4.450 sec/step, loss=0.08302, avg_loss=0.08435]
[2025-06-07 09:05:25.165]  Step 75909   [4.452 sec/step, loss=0.08803, avg_loss=0.08436]
[2025-06-07 09:05:30.684]  Step 75910   [4.459 sec/step, loss=0.08871, avg_loss=0.08437]
[2025-06-07 09:05:34.163]  Step 75911   [4.438 sec/step, loss=0.08466, avg_loss=0.08432]
[2025-06-07 09:05:35.950]  Step 75912   [4.417 sec/step, loss=0.07894, avg_loss=0.08424]
[2025-06-07 09:05:38.999]  Step 75913   [4.431 sec/step, loss=0.08387, avg_loss=0.08429]
[2025-06-07 09:05:41.188]  Step 75914   [4.415 sec/step, loss=0.08054, avg_loss=0.08424]
[2025-06-07 09:05:44.039]  Step 75915   [4.421 sec/step, loss=0.08448, avg_loss=0.08429]
[2025-06-07 09:05:47.874]  Step 75916   [4.441 sec/step, loss=0.08542, avg_loss=0.08437]
[2025-06-07 09:05:51.895]  Step 75917   [4.444 sec/step, loss=0.08575, avg_loss=0.08438]
[2025-06-07 09:06:15.876]  Step 75918   [4.662 sec/step, loss=0.07819, avg_loss=0.08435]
[2025-06-07 09:06:19.451]  Step 75919   [4.679 sec/step, loss=0.08410, avg_loss=0.08440]
[2025-06-07 09:06:25.857]  Step 75920   [4.711 sec/step, loss=0.08998, avg_loss=0.08445]
[2025-06-07 09:06:31.278]  Step 75921   [4.714 sec/step, loss=0.08836, avg_loss=0.08446]
[2025-06-07 09:06:37.980]  Step 75922   [4.755 sec/step, loss=0.09175, avg_loss=0.08454]
[2025-06-07 09:06:40.038]  Step 75923   [4.675 sec/step, loss=0.07836, avg_loss=0.08441]
[2025-06-07 09:06:48.712]  Step 75924   [4.695 sec/step, loss=0.09201, avg_loss=0.08442]
[2025-06-07 09:06:53.610]  Generated 32 batches of size 32 in 4.413 sec
[2025-06-07 09:06:54.679]  Step 75925   [4.677 sec/step, loss=0.08765, avg_loss=0.08439]
[2025-06-07 09:06:58.394]  Step 75926   [4.637 sec/step, loss=0.08432, avg_loss=0.08430]
[2025-06-07 09:07:01.043]  Step 75927   [4.639 sec/step, loss=0.08171, avg_loss=0.08429]
[2025-06-07 09:07:03.127]  Step 75928   [4.636 sec/step, loss=0.07871, avg_loss=0.08425]
[2025-06-07 09:07:05.661]  Step 75929   [4.633 sec/step, loss=0.08125, avg_loss=0.08423]
[2025-06-07 09:07:10.293]  Step 75930   [4.647 sec/step, loss=0.08696, avg_loss=0.08424]
[2025-06-07 09:07:16.497]  Step 75931   [4.676 sec/step, loss=0.09019, avg_loss=0.08429]
[2025-06-07 09:07:18.156]  Step 75932   [4.648 sec/step, loss=0.07027, avg_loss=0.08414]
[2025-06-07 09:07:28.228]  Step 75933   [4.698 sec/step, loss=0.09298, avg_loss=0.08421]
[2025-06-07 09:07:34.115]  Step 75934   [4.564 sec/step, loss=0.08846, avg_loss=0.08425]
[2025-06-07 09:07:36.555]  Step 75935   [4.554 sec/step, loss=0.08023, avg_loss=0.08423]
[2025-06-07 09:07:41.158]  Step 75936   [4.584 sec/step, loss=0.08571, avg_loss=0.08438]
[2025-06-07 09:07:50.998]  Step 75937   [4.655 sec/step, loss=0.09182, avg_loss=0.08447]
[2025-06-07 09:08:06.498]  Step 75938   [4.742 sec/step, loss=0.07948, avg_loss=0.08437]
[2025-06-07 09:08:08.671]  Step 75939   [4.717 sec/step, loss=0.07942, avg_loss=0.08428]
[2025-06-07 09:08:14.134]  Step 75940   [4.754 sec/step, loss=0.08746, avg_loss=0.08440]
[2025-06-07 09:08:22.660]  Step 75941   [4.822 sec/step, loss=0.09188, avg_loss=0.08461]
[2025-06-07 09:08:25.052]  Step 75942   [4.797 sec/step, loss=0.07994, avg_loss=0.08454]
[2025-06-07 09:08:27.952]  Step 75943   [4.802 sec/step, loss=0.08401, avg_loss=0.08458]
[2025-06-07 09:08:35.571]  Step 75944   [4.843 sec/step, loss=0.09174, avg_loss=0.08466]
[2025-06-07 09:08:39.354]  Step 75945   [4.853 sec/step, loss=0.08350, avg_loss=0.08467]
[2025-06-07 09:08:46.613]  Step 75946   [4.863 sec/step, loss=0.09109, avg_loss=0.08468]
[2025-06-07 09:08:52.533]  Step 75947   [4.851 sec/step, loss=0.08898, avg_loss=0.08466]
[2025-06-07 09:08:55.909]  Step 75948   [4.826 sec/step, loss=0.08374, avg_loss=0.08462]
[2025-06-07 09:08:59.970]  Step 75949   [4.840 sec/step, loss=0.08554, avg_loss=0.08466]
[2025-06-07 09:09:05.251]  Step 75950   [4.825 sec/step, loss=0.08837, avg_loss=0.08463]
[2025-06-07 09:09:05.251]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-75950
[2025-06-07 09:09:06.332]  Saving audio and alignment...
[2025-06-07 09:09:11.341]  Input: jrmniiko kolonko shr kvaattr nmbr caar sy tiin~_________________________
[2025-06-07 09:09:16.314]  Step 75951   [4.847 sec/step, loss=0.08879, avg_loss=0.08470]
[2025-06-07 09:09:19.869]  Step 75952   [4.844 sec/step, loss=0.08518, avg_loss=0.08471]
[2025-06-07 09:09:24.265]  Step 75953   [4.870 sec/step, loss=0.08614, avg_loss=0.08480]
[2025-06-07 09:09:27.934]  Step 75954   [4.853 sec/step, loss=0.08507, avg_loss=0.08477]
[2025-06-07 09:09:32.230]  Step 75955   [4.859 sec/step, loss=0.08481, avg_loss=0.08477]
[2025-06-07 09:09:36.862]  Generated 32 batches of size 32 in 4.133 sec
[2025-06-07 09:09:40.884]  Step 75956   [4.925 sec/step, loss=0.08973, avg_loss=0.08488]
[2025-06-07 09:09:42.958]  Step 75957   [4.913 sec/step, loss=0.07746, avg_loss=0.08480]
[2025-06-07 09:09:45.688]  Step 75958   [4.918 sec/step, loss=0.08208, avg_loss=0.08481]
[2025-06-07 09:09:48.161]  Step 75959   [4.910 sec/step, loss=0.07933, avg_loss=0.08477]
[2025-06-07 09:09:51.402]  Step 75960   [4.911 sec/step, loss=0.08362, avg_loss=0.08477]
[2025-06-07 09:09:58.177]  Step 75961   [4.923 sec/step, loss=0.09202, avg_loss=0.08481]
[2025-06-07 09:10:00.166]  Step 75962   [4.919 sec/step, loss=0.07652, avg_loss=0.08475]
[2025-06-07 09:10:02.987]  Step 75963   [4.891 sec/step, loss=0.08155, avg_loss=0.08471]
[2025-06-07 09:10:04.763]  Step 75964   [4.865 sec/step, loss=0.07290, avg_loss=0.08458]
[2025-06-07 09:10:11.939]  Step 75965   [4.647 sec/step, loss=0.08906, avg_loss=0.08469]
[2025-06-07 09:10:14.489]  Step 75966   [4.622 sec/step, loss=0.08076, avg_loss=0.08462]
[2025-06-07 09:10:16.759]  Step 75967   [4.548 sec/step, loss=0.07872, avg_loss=0.08450]
[2025-06-07 09:10:21.199]  Step 75968   [4.571 sec/step, loss=0.08677, avg_loss=0.08460]
[2025-06-07 09:10:22.901]  Step 75969   [4.567 sec/step, loss=0.06948, avg_loss=0.08450]
[2025-06-07 09:10:49.306]  Step 75970   [4.754 sec/step, loss=0.08398, avg_loss=0.08442]
[2025-06-07 09:10:51.297]  Step 75971   [4.743 sec/step, loss=0.07561, avg_loss=0.08434]
[2025-06-07 09:11:00.213]  Step 75972   [4.761 sec/step, loss=0.09300, avg_loss=0.08437]
[2025-06-07 09:11:07.584]  Step 75973   [4.818 sec/step, loss=0.09124, avg_loss=0.08458]
[2025-06-07 09:11:10.891]  Step 75974   [4.821 sec/step, loss=0.08333, avg_loss=0.08458]
[2025-06-07 09:11:13.636]  Step 75975   [4.813 sec/step, loss=0.08244, avg_loss=0.08455]
[2025-06-07 09:11:15.863]  Step 75976   [4.805 sec/step, loss=0.07855, avg_loss=0.08452]
[2025-06-07 09:11:24.122]  Step 75977   [4.807 sec/step, loss=0.09088, avg_loss=0.08449]
[2025-06-07 09:11:29.845]  Step 75978   [4.796 sec/step, loss=0.08808, avg_loss=0.08448]
[2025-06-07 09:11:40.141]  Step 75979   [4.814 sec/step, loss=0.09093, avg_loss=0.08447]
[2025-06-07 09:11:43.694]  Step 75980   [4.816 sec/step, loss=0.08483, avg_loss=0.08446]
[2025-06-07 09:11:49.505]  Step 75981   [4.846 sec/step, loss=0.08976, avg_loss=0.08453]
[2025-06-07 09:11:53.357]  Step 75982   [4.848 sec/step, loss=0.08420, avg_loss=0.08452]
[2025-06-07 09:11:58.739]  Step 75983   [4.869 sec/step, loss=0.08727, avg_loss=0.08456]
[2025-06-07 09:12:02.636]  Step 75984   [4.884 sec/step, loss=0.08454, avg_loss=0.08460]
[2025-06-07 09:12:05.787]  Step 75985   [4.861 sec/step, loss=0.08204, avg_loss=0.08453]
[2025-06-07 09:12:08.711]  Step 75986   [4.848 sec/step, loss=0.08385, avg_loss=0.08453]
[2025-06-07 09:12:13.623]  Step 75987   [4.837 sec/step, loss=0.08619, avg_loss=0.08451]
[2025-06-07 09:12:17.972]  Generated 32 batches of size 32 in 3.880 sec
[2025-06-07 09:12:21.112]  Step 75988   [4.892 sec/step, loss=0.08924, avg_loss=0.08463]
[2025-06-07 09:12:24.563]  Step 75989   [4.874 sec/step, loss=0.08610, avg_loss=0.08461]
[2025-06-07 09:12:30.588]  Step 75990   [4.896 sec/step, loss=0.08914, avg_loss=0.08464]
[2025-06-07 09:12:32.962]  Step 75991   [4.876 sec/step, loss=0.08075, avg_loss=0.08456]
[2025-06-07 09:12:37.044]  Step 75992   [4.891 sec/step, loss=0.08646, avg_loss=0.08461]
[2025-06-07 09:12:41.198]  Step 75993   [4.904 sec/step, loss=0.08480, avg_loss=0.08465]
[2025-06-07 09:12:43.904]  Step 75994   [4.910 sec/step, loss=0.08270, avg_loss=0.08467]
[2025-06-07 09:12:47.021]  Step 75995   [4.917 sec/step, loss=0.08353, avg_loss=0.08472]
[2025-06-07 09:12:49.041]  Step 75996   [4.917 sec/step, loss=0.07695, avg_loss=0.08474]
[2025-06-07 09:12:50.928]  Step 75997   [4.909 sec/step, loss=0.07673, avg_loss=0.08470]
[2025-06-07 09:12:56.134]  Step 75998   [4.889 sec/step, loss=0.08796, avg_loss=0.08468]
[2025-06-07 09:13:06.652]  Step 75999   [4.950 sec/step, loss=0.09174, avg_loss=0.08472]
[2025-06-07 09:13:09.836]  Step 76000   [4.936 sec/step, loss=0.08316, avg_loss=0.08467]
[2025-06-07 09:13:09.836]  Writing summary at step: 76000
[2025-06-07 09:13:17.619]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-76000
[2025-06-07 09:13:18.863]  Saving audio and alignment...
[2025-06-07 09:13:23.005]  Input: dkssinn amerikaako deshii bhaassaa~___________
[2025-06-07 09:13:28.615]  Step 76001   [4.949 sec/step, loss=0.08813, avg_loss=0.08467]
[2025-06-07 09:13:30.746]  Step 76002   [4.919 sec/step, loss=0.07769, avg_loss=0.08456]
[2025-06-07 09:13:33.073]  Step 76003   [4.871 sec/step, loss=0.08067, avg_loss=0.08445]
[2025-06-07 09:13:48.917]  Step 76004   [4.995 sec/step, loss=0.07856, avg_loss=0.08439]
[2025-06-07 09:13:55.023]  Step 76005   [5.028 sec/step, loss=0.08806, avg_loss=0.08443]
[2025-06-07 09:13:58.882]  Step 76006   [5.049 sec/step, loss=0.08454, avg_loss=0.08451]
[2025-06-07 09:14:02.327]  Step 76007   [5.058 sec/step, loss=0.08348, avg_loss=0.08453]
[2025-06-07 09:14:10.693]  Step 76008   [5.114 sec/step, loss=0.09212, avg_loss=0.08462]
[2025-06-07 09:14:15.009]  Step 76009   [5.105 sec/step, loss=0.08523, avg_loss=0.08459]
[2025-06-07 09:14:22.377]  Step 76010   [5.123 sec/step, loss=0.09033, avg_loss=0.08461]
[2025-06-07 09:14:24.248]  Step 76011   [5.107 sec/step, loss=0.06888, avg_loss=0.08445]
[2025-06-07 09:14:28.804]  Step 76012   [5.135 sec/step, loss=0.08704, avg_loss=0.08453]
[2025-06-07 09:14:31.283]  Step 76013   [5.129 sec/step, loss=0.08139, avg_loss=0.08450]
[2025-06-07 09:14:34.148]  Step 76014   [5.136 sec/step, loss=0.08203, avg_loss=0.08452]
[2025-06-07 09:14:37.711]  Step 76015   [5.143 sec/step, loss=0.08408, avg_loss=0.08452]
[2025-06-07 09:14:44.647]  Step 76016   [5.174 sec/step, loss=0.08902, avg_loss=0.08455]
[2025-06-07 09:14:47.492]  Step 76017   [5.162 sec/step, loss=0.08226, avg_loss=0.08452]
[2025-06-07 09:14:51.023]  Step 76018   [4.958 sec/step, loss=0.08244, avg_loss=0.08456]
[2025-06-07 09:14:51.991]  Generated 32 batches of size 32 in 4.070 sec
[2025-06-07 09:14:55.756]  Step 76019   [4.969 sec/step, loss=0.08677, avg_loss=0.08459]
[2025-06-07 09:15:01.821]  Step 76020   [4.966 sec/step, loss=0.08832, avg_loss=0.08457]
[2025-06-07 09:15:05.315]  Step 76021   [4.947 sec/step, loss=0.08519, avg_loss=0.08454]
[2025-06-07 09:15:08.558]  Step 76022   [4.912 sec/step, loss=0.08395, avg_loss=0.08446]
[2025-06-07 09:15:12.695]  Step 76023   [4.933 sec/step, loss=0.08493, avg_loss=0.08453]
[2025-06-07 09:15:19.122]  Step 76024   [4.911 sec/step, loss=0.08997, avg_loss=0.08450]
[2025-06-07 09:15:21.582]  Step 76025   [4.875 sec/step, loss=0.08232, avg_loss=0.08445]
[2025-06-07 09:15:24.122]  Step 76026   [4.864 sec/step, loss=0.08261, avg_loss=0.08443]
[2025-06-07 09:15:26.272]  Step 76027   [4.859 sec/step, loss=0.07729, avg_loss=0.08439]
[2025-06-07 09:15:29.625]  Step 76028   [4.871 sec/step, loss=0.08561, avg_loss=0.08446]
[2025-06-07 09:15:31.331]  Step 76029   [4.863 sec/step, loss=0.07100, avg_loss=0.08436]
[2025-06-07 09:15:34.136]  Step 76030   [4.845 sec/step, loss=0.08329, avg_loss=0.08432]
[2025-06-07 09:15:43.336]  Step 76031   [4.875 sec/step, loss=0.09326, avg_loss=0.08435]
[2025-06-07 09:15:47.138]  Step 76032   [4.896 sec/step, loss=0.08509, avg_loss=0.08450]
[2025-06-07 09:15:49.613]  Step 76033   [4.820 sec/step, loss=0.08082, avg_loss=0.08438]
[2025-06-07 09:15:55.811]  Step 76034   [4.823 sec/step, loss=0.08967, avg_loss=0.08439]
[2025-06-07 09:16:01.234]  Step 76035   [4.853 sec/step, loss=0.08799, avg_loss=0.08447]
[2025-06-07 09:16:04.581]  Step 76036   [4.841 sec/step, loss=0.08324, avg_loss=0.08444]
[2025-06-07 09:16:09.058]  Step 76037   [4.787 sec/step, loss=0.08637, avg_loss=0.08439]
[2025-06-07 09:16:11.746]  Step 76038   [4.659 sec/step, loss=0.08079, avg_loss=0.08440]
[2025-06-07 09:16:14.897]  Step 76039   [4.669 sec/step, loss=0.08379, avg_loss=0.08444]
[2025-06-07 09:16:20.040]  Step 76040   [4.666 sec/step, loss=0.08924, avg_loss=0.08446]
[2025-06-07 09:16:22.998]  Step 76041   [4.610 sec/step, loss=0.08432, avg_loss=0.08439]
[2025-06-07 09:16:27.818]  Step 76042   [4.634 sec/step, loss=0.08804, avg_loss=0.08447]
[2025-06-07 09:16:37.760]  Step 76043   [4.705 sec/step, loss=0.08985, avg_loss=0.08453]
[2025-06-07 09:16:41.749]  Step 76044   [4.668 sec/step, loss=0.08545, avg_loss=0.08446]
[2025-06-07 09:16:43.599]  Step 76045   [4.649 sec/step, loss=0.07649, avg_loss=0.08439]
[2025-06-07 09:16:46.398]  Step 76046   [4.604 sec/step, loss=0.08236, avg_loss=0.08431]
[2025-06-07 09:16:53.005]  Step 76047   [4.611 sec/step, loss=0.09004, avg_loss=0.08432]
[2025-06-07 09:16:55.434]  Step 76048   [4.602 sec/step, loss=0.07900, avg_loss=0.08427]
[2025-06-07 09:16:59.359]  Step 76049   [4.600 sec/step, loss=0.08485, avg_loss=0.08426]
[2025-06-07 09:17:03.765]  Generated 32 batches of size 32 in 3.905 sec
[2025-06-07 09:17:09.061]  Step 76050   [4.645 sec/step, loss=0.09056, avg_loss=0.08428]
[2025-06-07 09:17:09.062]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-76050
[2025-06-07 09:17:10.223]  Saving audio and alignment...
[2025-06-07 09:17:16.335]  Input: ptrikaako smpaadn kaary vissnnukumaarii limbudvaaraa bheko~__________________
[2025-06-07 09:17:22.971]  Step 76051   [4.661 sec/step, loss=0.08773, avg_loss=0.08427]
[2025-06-07 09:17:25.445]  Step 76052   [4.650 sec/step, loss=0.07982, avg_loss=0.08422]
[2025-06-07 09:17:27.594]  Step 76053   [4.628 sec/step, loss=0.07773, avg_loss=0.08414]
[2025-06-07 09:17:35.345]  Step 76054   [4.669 sec/step, loss=0.09135, avg_loss=0.08420]
[2025-06-07 09:18:04.950]  Step 76055   [4.922 sec/step, loss=0.08108, avg_loss=0.08416]
[2025-06-07 09:18:09.471]  Step 76056   [4.880 sec/step, loss=0.08719, avg_loss=0.08414]
[2025-06-07 09:18:15.957]  Step 76057   [4.925 sec/step, loss=0.08860, avg_loss=0.08425]
[2025-06-07 09:18:22.363]  Step 76058   [4.961 sec/step, loss=0.08865, avg_loss=0.08431]
[2025-06-07 09:18:25.187]  Step 76059   [4.965 sec/step, loss=0.08107, avg_loss=0.08433]
[2025-06-07 09:18:35.134]  Step 76060   [5.032 sec/step, loss=0.09073, avg_loss=0.08440]
[2025-06-07 09:18:37.081]  Step 76061   [4.984 sec/step, loss=0.07526, avg_loss=0.08423]
[2025-06-07 09:18:40.846]  Step 76062   [5.001 sec/step, loss=0.08348, avg_loss=0.08430]
[2025-06-07 09:18:43.818]  Step 76063   [5.003 sec/step, loss=0.08253, avg_loss=0.08431]
[2025-06-07 09:18:49.756]  Step 76064   [5.044 sec/step, loss=0.08811, avg_loss=0.08447]
[2025-06-07 09:18:58.246]  Step 76065   [5.058 sec/step, loss=0.09012, avg_loss=0.08448]
[2025-06-07 09:19:07.514]  Step 76066   [5.125 sec/step, loss=0.09187, avg_loss=0.08459]
[2025-06-07 09:19:14.998]  Step 76067   [5.177 sec/step, loss=0.08942, avg_loss=0.08469]
[2025-06-07 09:19:19.018]  Step 76068   [5.173 sec/step, loss=0.08454, avg_loss=0.08467]
[2025-06-07 09:19:21.265]  Step 76069   [5.178 sec/step, loss=0.07879, avg_loss=0.08477]
[2025-06-07 09:19:25.939]  Step 76070   [4.961 sec/step, loss=0.08645, avg_loss=0.08479]
[2025-06-07 09:19:46.988]  Step 76071   [5.151 sec/step, loss=0.07979, avg_loss=0.08483]
[2025-06-07 09:19:50.081]  Step 76072   [5.093 sec/step, loss=0.08275, avg_loss=0.08473]
[2025-06-07 09:19:51.909]  Step 76073   [5.038 sec/step, loss=0.07280, avg_loss=0.08454]
[2025-06-07 09:19:55.883]  Step 76074   [5.044 sec/step, loss=0.08431, avg_loss=0.08455]
[2025-06-07 09:19:57.963]  Step 76075   [5.038 sec/step, loss=0.07866, avg_loss=0.08452]
[2025-06-07 09:20:00.979]  Step 76076   [5.046 sec/step, loss=0.08412, avg_loss=0.08457]
[2025-06-07 09:20:06.464]  Step 76077   [5.018 sec/step, loss=0.08840, avg_loss=0.08455]
[2025-06-07 09:20:09.043]  Step 76078   [4.986 sec/step, loss=0.07994, avg_loss=0.08447]
[2025-06-07 09:20:13.312]  Step 76079   [4.926 sec/step, loss=0.08517, avg_loss=0.08441]
[2025-06-07 09:20:19.271]  Step 76080   [4.950 sec/step, loss=0.08755, avg_loss=0.08444]
[2025-06-07 09:20:23.958]  Generated 32 batches of size 32 in 4.123 sec
[2025-06-07 09:20:27.983]  Step 76081   [4.979 sec/step, loss=0.09224, avg_loss=0.08446]
[2025-06-07 09:20:31.495]  Step 76082   [4.976 sec/step, loss=0.08299, avg_loss=0.08445]
[2025-06-07 09:20:35.045]  Step 76083   [4.958 sec/step, loss=0.08451, avg_loss=0.08442]
[2025-06-07 09:20:39.956]  Step 76084   [4.968 sec/step, loss=0.08574, avg_loss=0.08443]
[2025-06-07 09:20:42.533]  Step 76085   [4.962 sec/step, loss=0.08103, avg_loss=0.08442]
[2025-06-07 09:20:45.905]  Step 76086   [4.966 sec/step, loss=0.08395, avg_loss=0.08442]
[2025-06-07 09:20:48.170]  Step 76087   [4.940 sec/step, loss=0.07989, avg_loss=0.08436]
[2025-06-07 09:20:55.303]  Step 76088   [4.936 sec/step, loss=0.08984, avg_loss=0.08437]
[2025-06-07 09:20:59.789]  Step 76089   [4.947 sec/step, loss=0.08571, avg_loss=0.08436]
[2025-06-07 09:21:01.735]  Step 76090   [4.906 sec/step, loss=0.07709, avg_loss=0.08424]
[2025-06-07 09:21:13.662]  Step 76091   [5.001 sec/step, loss=0.09099, avg_loss=0.08434]
[2025-06-07 09:21:18.347]  Step 76092   [5.007 sec/step, loss=0.08699, avg_loss=0.08435]
[2025-06-07 09:21:21.343]  Step 76093   [4.996 sec/step, loss=0.08297, avg_loss=0.08433]
[2025-06-07 09:21:25.217]  Step 76094   [5.008 sec/step, loss=0.08402, avg_loss=0.08434]
[2025-06-07 09:21:28.102]  Step 76095   [5.005 sec/step, loss=0.08213, avg_loss=0.08433]
[2025-06-07 09:21:36.810]  Step 76096   [5.072 sec/step, loss=0.09379, avg_loss=0.08450]
[2025-06-07 09:21:45.326]  Step 76097   [5.138 sec/step, loss=0.09140, avg_loss=0.08465]
[2025-06-07 09:21:50.705]  Step 76098   [5.140 sec/step, loss=0.08755, avg_loss=0.08464]
[2025-06-07 09:21:54.336]  Step 76099   [5.071 sec/step, loss=0.08574, avg_loss=0.08458]
[2025-06-07 09:22:00.533]  Step 76100   [5.101 sec/step, loss=0.08930, avg_loss=0.08464]
[2025-06-07 09:22:00.535]  Writing summary at step: 76100
[2025-06-07 09:22:04.010]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-76100
[2025-06-07 09:22:05.125]  Saving audio and alignment...
[2025-06-07 09:22:11.324]  Input: komkaasttle kunai bhedbhaav ngrikn utpaadnhruuko vitrnn grdch~_________________
[2025-06-07 09:22:15.361]  Step 76101   [5.086 sec/step, loss=0.08480, avg_loss=0.08461]
[2025-06-07 09:22:20.256]  Step 76102   [5.113 sec/step, loss=0.08701, avg_loss=0.08470]
[2025-06-07 09:22:22.771]  Step 76103   [5.115 sec/step, loss=0.07984, avg_loss=0.08470]
[2025-06-07 09:22:25.103]  Step 76104   [4.980 sec/step, loss=0.07981, avg_loss=0.08471]
[2025-06-07 09:22:32.386]  Step 76105   [4.992 sec/step, loss=0.09121, avg_loss=0.08474]
[2025-06-07 09:22:34.155]  Step 76106   [4.971 sec/step, loss=0.06925, avg_loss=0.08459]
[2025-06-07 09:22:38.552]  Step 76107   [4.981 sec/step, loss=0.08531, avg_loss=0.08460]
[2025-06-07 09:22:42.090]  Step 76108   [4.932 sec/step, loss=0.08384, avg_loss=0.08452]
[2025-06-07 09:22:45.546]  Step 76109   [4.924 sec/step, loss=0.08352, avg_loss=0.08450]
[2025-06-07 09:22:48.088]  Step 76110   [4.875 sec/step, loss=0.08140, avg_loss=0.08442]
[2025-06-07 09:22:53.242]  Generated 32 batches of size 32 in 4.527 sec
[2025-06-07 09:23:29.107]  Step 76111   [5.267 sec/step, loss=0.08130, avg_loss=0.08454]
[2025-06-07 09:23:32.147]  Step 76112   [5.252 sec/step, loss=0.08140, avg_loss=0.08448]
[2025-06-07 09:23:38.160]  Step 76113   [5.287 sec/step, loss=0.08863, avg_loss=0.08456]
[2025-06-07 09:23:44.841]  Step 76114   [5.325 sec/step, loss=0.09006, avg_loss=0.08464]
[2025-06-07 09:23:52.565]  Step 76115   [5.367 sec/step, loss=0.09106, avg_loss=0.08471]
[2025-06-07 09:23:54.935]  Step 76116   [5.321 sec/step, loss=0.07880, avg_loss=0.08460]
[2025-06-07 09:24:01.397]  Step 76117   [5.357 sec/step, loss=0.08741, avg_loss=0.08465]
[2025-06-07 09:24:03.584]  Step 76118   [5.344 sec/step, loss=0.07907, avg_loss=0.08462]
[2025-06-07 09:24:08.221]  Step 76119   [5.343 sec/step, loss=0.08609, avg_loss=0.08461]
[2025-06-07 09:24:10.473]  Step 76120   [5.305 sec/step, loss=0.07875, avg_loss=0.08452]
[2025-06-07 09:24:12.330]  Step 76121   [5.288 sec/step, loss=0.07144, avg_loss=0.08438]
[2025-06-07 09:24:16.278]  Step 76122   [5.295 sec/step, loss=0.08498, avg_loss=0.08439]
[2025-06-07 09:24:20.643]  Step 76123   [5.298 sec/step, loss=0.08603, avg_loss=0.08440]
[2025-06-07 09:24:24.069]  Step 76124   [5.268 sec/step, loss=0.08438, avg_loss=0.08435]
[2025-06-07 09:24:35.093]  Step 76125   [5.353 sec/step, loss=0.08939, avg_loss=0.08442]
[2025-06-07 09:24:39.270]  Step 76126   [5.370 sec/step, loss=0.08504, avg_loss=0.08444]
[2025-06-07 09:24:45.371]  Step 76127   [5.409 sec/step, loss=0.08829, avg_loss=0.08455]
[2025-06-07 09:24:48.278]  Step 76128   [5.405 sec/step, loss=0.08380, avg_loss=0.08453]
[2025-06-07 09:24:55.931]  Step 76129   [5.464 sec/step, loss=0.09290, avg_loss=0.08475]
[2025-06-07 09:24:59.502]  Step 76130   [5.472 sec/step, loss=0.08305, avg_loss=0.08475]
[2025-06-07 09:25:06.719]  Step 76131   [5.452 sec/step, loss=0.09123, avg_loss=0.08473]
[2025-06-07 09:25:10.643]  Step 76132   [5.453 sec/step, loss=0.08515, avg_loss=0.08473]
[2025-06-07 09:25:28.668]  Step 76133   [5.609 sec/step, loss=0.08036, avg_loss=0.08473]
[2025-06-07 09:25:31.656]  Step 76134   [5.577 sec/step, loss=0.08195, avg_loss=0.08465]
[2025-06-07 09:25:37.207]  Step 76135   [5.578 sec/step, loss=0.08894, avg_loss=0.08466]
[2025-06-07 09:25:39.578]  Step 76136   [5.568 sec/step, loss=0.07988, avg_loss=0.08462]
[2025-06-07 09:25:44.465]  Step 76137   [5.572 sec/step, loss=0.08739, avg_loss=0.08463]
[2025-06-07 09:25:47.969]  Step 76138   [5.580 sec/step, loss=0.08489, avg_loss=0.08468]
[2025-06-07 09:25:50.507]  Step 76139   [5.574 sec/step, loss=0.08036, avg_loss=0.08464]
[2025-06-07 09:25:52.693]  Step 76140   [5.545 sec/step, loss=0.07766, avg_loss=0.08453]
[2025-06-07 09:25:59.905]  Step 76141   [5.587 sec/step, loss=0.08898, avg_loss=0.08457]
[2025-06-07 09:26:01.858]  Step 76142   [5.559 sec/step, loss=0.07723, avg_loss=0.08446]
[2025-06-07 09:26:06.843]  Generated 32 batches of size 32 in 4.416 sec
[2025-06-07 09:26:12.756]  Step 76143   [5.568 sec/step, loss=0.09267, avg_loss=0.08449]
[2025-06-07 09:26:15.398]  Step 76144   [5.555 sec/step, loss=0.08061, avg_loss=0.08444]
[2025-06-07 09:26:18.525]  Step 76145   [5.567 sec/step, loss=0.08382, avg_loss=0.08452]
[2025-06-07 09:26:23.259]  Step 76146   [5.587 sec/step, loss=0.08537, avg_loss=0.08455]
[2025-06-07 09:26:29.160]  Step 76147   [5.580 sec/step, loss=0.08836, avg_loss=0.08453]
[2025-06-07 09:26:33.926]  Step 76148   [5.603 sec/step, loss=0.08702, avg_loss=0.08461]
[2025-06-07 09:26:40.404]  Step 76149   [5.629 sec/step, loss=0.08891, avg_loss=0.08465]
[2025-06-07 09:26:48.214]  Step 76150   [5.610 sec/step, loss=0.09172, avg_loss=0.08466]
[2025-06-07 09:26:48.214]  Saving checkpoint to: E:/newtacotron/tacotron/logs-tacotron/model/model.ckpt-76150
[2025-06-07 09:26:49.269]  Saving audio and alignment...
[2025-06-07 09:26:54.161]  Input: yo aaphuubhndaa saanaalaaii bolaaun pryog grinch~_________
[2025-06-07 09:26:58.706]  Step 76151   [5.589 sec/step, loss=0.08521, avg_loss=0.08464]
[2025-06-07 09:27:00.893]  Step 76152   [5.586 sec/step, loss=0.08040, avg_loss=0.08464]
[2025-06-07 09:27:05.736]  Step 76153   [5.613 sec/step, loss=0.08731, avg_loss=0.08474]
[2025-06-07 09:27:09.206]  Step 76154   [5.570 sec/step, loss=0.08423, avg_loss=0.08467]
[2025-06-07 09:27:16.759]  Step 76155   [5.350 sec/step, loss=0.08928, avg_loss=0.08475]
[2025-06-07 09:27:20.111]  Step 76156   [5.338 sec/step, loss=0.08447, avg_loss=0.08472]
[2025-06-07 09:27:23.249]  Step 76157   [5.304 sec/step, loss=0.08301, avg_loss=0.08467]
[2025-06-07 09:27:28.331]  Step 76158   [5.291 sec/step, loss=0.08714, avg_loss=0.08465]
[2025-06-07 09:27:32.031]  Step 76159   [5.300 sec/step, loss=0.08506, avg_loss=0.08469]
[2025-06-07 09:27:33.992]  Step 76160   [5.220 sec/step, loss=0.07553, avg_loss=0.08454]
[2025-06-07 09:27:42.676]  Step 76161   [5.288 sec/step, loss=0.09063, avg_loss=0.08469]
[2025-06-07 09:27:48.565]  Step 76162   [5.309 sec/step, loss=0.08789, avg_loss=0.08474]
[2025-06-07 09:27:56.556]  Step 76163   [5.359 sec/step, loss=0.08936, avg_loss=0.08481]
[2025-06-07 09:28:03.568]  Step 76164   [5.370 sec/step, loss=0.08829, avg_loss=0.08481]
[2025-06-07 09:28:07.467]  Step 76165   [5.324 sec/step, loss=0.08521, avg_loss=0.08476]
